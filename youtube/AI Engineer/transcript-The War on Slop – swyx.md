# The War on Slop â€“ swyx

**Video URL:** https://youtu.be/IoiHI7p12Ao

---

## Full Transcript

### [00:00 - 01:00]

**[00:23]** morning. How's everyone doing?

**[00:23]** morning. How's everyone doing? >> Good.

**[00:24]** >> Good.

**[00:24]** >> Good. >> I'm going to need a lot of energy for

**[00:25]** >> I'm going to need a lot of energy for

**[00:26]** >> I'm going to need a lot of energy for this talk, so please back me up. I'm

**[00:27]** this talk, so please back me up. I'm

**[00:27]** this talk, so please back me up. I'm very nervous. Uh but we'll get through

**[00:30]** very nervous. Uh but we'll get through

**[00:30]** very nervous. Uh but we'll get through this. I'm declaring war on slop today.

**[00:33]** this. I'm declaring war on slop today.

**[00:33]** this. I'm declaring war on slop today. Let's talk about this. Every AIE has a

**[00:36]** Let's talk about this. Every AIE has a

**[00:36]** Let's talk about this. Every AIE has a secret. I I've told this to uh some

**[00:38]** secret. I I've told this to uh some

**[00:38]** secret. I I've told this to uh some folks that are personal friends and I'll

**[00:41]** folks that are personal friends and I'll

**[00:41]** folks that are personal friends and I'll just show show the secret. Now the first

**[00:43]** just show show the secret. Now the first

**[00:43]** just show show the secret. Now the first summit we had the secret which was we

**[00:46]** summit we had the secret which was we

**[00:46]** summit we had the secret which was we knew that the AI engineer was going to

**[00:47]** knew that the AI engineer was going to

**[00:47]** knew that the AI engineer was going to be a thing. Second summit we extended it

**[00:49]** be a thing. Second summit we extended it

**[00:49]** be a thing. Second summit we extended it to leadership. Third summit we realized

**[00:51]** to leadership. Third summit we realized

**[00:52]** to leadership. Third summit we realized that basically we always needed to

**[00:53]** that basically we always needed to

**[00:54]** that basically we always needed to concentrate on model labs and that's why

**[00:55]** concentrate on model labs and that's why

**[00:55]** concentrate on model labs and that's why you see um all all the all the top tier

**[00:58]** you see um all all the all the top tier

**[00:58]** you see um all all the all the top tier labs here today um world's fair we


### [01:00 - 02:00]

**[01:00]** labs here today um world's fair we

**[01:00]** labs here today um world's fair we started expanding the TAM of of what AI

**[01:03]** started expanding the TAM of of what AI

**[01:03]** started expanding the TAM of of what AI engineering uh is is affiliated with

**[01:05]** engineering uh is is affiliated with

**[01:06]** engineering uh is is affiliated with with AIPMs and AI designers and with the

**[01:08]** with AIPMs and AI designers and with the

**[01:08]** with AIPMs and AI designers and with the code summit as Jed just talked about we

**[01:10]** code summit as Jed just talked about we

**[01:10]** code summit as Jed just talked about we really started focus on curation and

**[01:12]** really started focus on curation and

**[01:12]** really started focus on curation and focusing in on a theme and if there's

**[01:14]** focusing in on a theme and if there's

**[01:14]** focusing in on a theme and if there's one theme that's really matters this

**[01:16]** one theme that's really matters this

**[01:16]** one theme that's really matters this year is it's coding but I'm not here to

**[01:18]** year is it's coding but I'm not here to

**[01:18]** year is it's coding but I'm not here to talk about coding the rest of the day

**[01:19]** talk about coding the rest of the day

**[01:19]** talk about coding the rest of the day you're going to hear about coding. So

**[01:21]** you're going to hear about coding. So

**[01:21]** you're going to hear about coding. So just just indulge me 5 minutes to talk

**[01:23]** just just indulge me 5 minutes to talk

**[01:23]** just just indulge me 5 minutes to talk about slop.

**[01:25]** about slop.

**[01:25]** about slop. Um we we've done really well, right?

**[01:27]** Um we we've done really well, right?

**[01:27]** Um we we've done really well, right? Like so so like I think like slop is

**[01:29]** Like so so like I think like slop is

**[01:29]** Like so so like I think like slop is sort of associated with quantity and

**[01:31]** sort of associated with quantity and

**[01:31]** sort of associated with quantity and quality. And I think like that's

**[01:32]** quality. And I think like that's

**[01:32]** quality. And I think like that's something that I'm really trying to

**[01:33]** something that I'm really trying to

**[01:33]** something that I'm really trying to think about as well like how do we grow

**[01:35]** think about as well like how do we grow

**[01:35]** think about as well like how do we grow this community, grow this industry and

**[01:37]** this community, grow this industry and

**[01:37]** this community, grow this industry and grow this event uh with the the same

**[01:41]** grow this event uh with the the same

**[01:41]** grow this event uh with the the same kind of taste and high quality that

**[01:42]** kind of taste and high quality that

**[01:42]** kind of taste and high quality that you've come to expect. And this is

**[01:43]** you've come to expect. And this is

**[01:44]** you've come to expect. And this is something that, you know, I hope

**[01:45]** something that, you know, I hope

**[01:45]** something that, you know, I hope hopefully you guys can see that we care

**[01:47]** hopefully you guys can see that we care

**[01:47]** hopefully you guys can see that we care a lot about uh in curating all of you

**[01:49]** a lot about uh in curating all of you

**[01:49]** a lot about uh in curating all of you coming here and all of the speakers that

**[01:50]** coming here and all of the speakers that

**[01:50]** coming here and all of the speakers that you're about to see. Um we're in a war

**[01:53]** you're about to see. Um we're in a war

**[01:53]** you're about to see. Um we're in a war against slop. Um this is actually uh the

**[01:56]** against slop. Um this is actually uh the

**[01:56]** against slop. Um this is actually uh the Oxford English dictionary. Uh this is a

**[01:58]** Oxford English dictionary. Uh this is a

**[01:58]** Oxford English dictionary. Uh this is a a candidate for the 2024 word of the


### [02:00 - 03:00]

**[02:01]** a candidate for the 2024 word of the

**[02:01]** a candidate for the 2024 word of the year. It lost to brain rot. [laughter]

**[02:04]** year. It lost to brain rot. [laughter]

**[02:04]** year. It lost to brain rot. [laughter] But um but slop is slop is pretty good.

**[02:07]** But um but slop is slop is pretty good.

**[02:07]** But um but slop is slop is pretty good. And I think it's it's probably gone even

**[02:09]** And I think it's it's probably gone even

**[02:09]** And I think it's it's probably gone even more of an issue this year than last

**[02:11]** more of an issue this year than last

**[02:11]** more of an issue this year than last year. Maybe it will win this year. I

**[02:13]** year. Maybe it will win this year. I

**[02:13]** year. Maybe it will win this year. I have an issue with Oxford though because

**[02:15]** have an issue with Oxford though because

**[02:15]** have an issue with Oxford though because they did us dirty by saying slop is is

**[02:20]** they did us dirty by saying slop is is

**[02:20]** they did us dirty by saying slop is is generated using artificial intelligence.

**[02:22]** generated using artificial intelligence.

**[02:22]** generated using artificial intelligence. The other part I I agree with. It's

**[02:23]** The other part I I agree with. It's

**[02:23]** The other part I I agree with. It's lowquality, inauthentic or inaccurate.

**[02:26]** lowquality, inauthentic or inaccurate.

**[02:26]** lowquality, inauthentic or inaccurate. But it doesn't take AI to be lowquality,

**[02:28]** But it doesn't take AI to be lowquality,

**[02:28]** But it doesn't take AI to be lowquality, inauthentic or inaccurate.

**[02:31]** inauthentic or inaccurate.

**[02:31]** inauthentic or inaccurate. Any human or AI can be an agent of slop,

**[02:33]** Any human or AI can be an agent of slop,

**[02:33]** Any human or AI can be an agent of slop, right? You've seen this yourself. I'm

**[02:35]** right? You've seen this yourself. I'm

**[02:36]** right? You've seen this yourself. I'm going to indulge me over a few examples.

**[02:37]** going to indulge me over a few examples.

**[02:37]** going to indulge me over a few examples. By the way, I got this uh if you're not

**[02:38]** By the way, I got this uh if you're not

**[02:38]** By the way, I got this uh if you're not familiar with like sort of internet

**[02:40]** familiar with like sort of internet

**[02:40]** familiar with like sort of internet slang, the opposite of slop is kino. Um

**[02:43]** slang, the opposite of slop is kino. Um

**[02:43]** slang, the opposite of slop is kino. Um and I got this idea from Paul Rambles

**[02:45]** and I got this idea from Paul Rambles

**[02:45]** and I got this idea from Paul Rambles who uh like you know when I do Sora

**[02:49]** who uh like you know when I do Sora

**[02:49]** who uh like you know when I do Sora videos, I do really boring Sora videos

**[02:51]** videos, I do really boring Sora videos

**[02:51]** videos, I do really boring Sora videos with me and Sam Holman. When other

**[02:53]** with me and Sam Holman. When other

**[02:53]** with me and Sam Holman. When other people who are actually creative and

**[02:54]** people who are actually creative and

**[02:54]** people who are actually creative and good at their job do Sora videos, they

**[02:56]** good at their job do Sora videos, they

**[02:56]** good at their job do Sora videos, they do cats playing digs.

**[02:59]** do cats playing digs.

**[02:59]** do cats playing digs. Uh slot can be produced by the same


### [03:00 - 04:00]

**[03:02]** Uh slot can be produced by the same

**[03:02]** Uh slot can be produced by the same studio. There's K-pop demon hunters by

**[03:04]** studio. There's K-pop demon hunters by

**[03:04]** studio. There's K-pop demon hunters by Netflix and there's electric st by

**[03:05]** Netflix and there's electric st by

**[03:05]** Netflix and there's electric st by Netflix.

**[03:08]** Netflix.

**[03:08]** Netflix. Slav can be produced in terms of

**[03:10]** Slav can be produced in terms of

**[03:10]** Slav can be produced in terms of different models. No comment.

**[03:18]** Slav can be SLO can something that's

**[03:18]** Slav can be SLO can something that's keyno can degenerate into SLO, right? If

**[03:20]** keyno can degenerate into SLO, right? If

**[03:20]** keyno can degenerate into SLO, right? If you're early on the trend and you're and

**[03:22]** you're early on the trend and you're and

**[03:22]** you're early on the trend and you're and you you're starting that and it's and

**[03:24]** you you're starting that and it's and

**[03:24]** you you're starting that and it's and it's fresh and new and that's great. U

**[03:25]** it's fresh and new and that's great. U

**[03:26]** it's fresh and new and that's great. U if you're if you recognize the other

**[03:27]** if you're if you recognize the other

**[03:27]** if you're if you recognize the other image, you're too online.

**[03:30]** image, you're too online.

**[03:30]** image, you're too online. [clears throat] Okay, not enough people

**[03:31]** [clears throat] Okay, not enough people

**[03:31]** [clears throat] Okay, not enough people recognize that image. Um go do your

**[03:35]** recognize that image. Um go do your

**[03:35]** recognize that image. Um go do your homework. Um yeah, and obviously I'm

**[03:37]** homework. Um yeah, and obviously I'm

**[03:37]** homework. Um yeah, and obviously I'm just going to throw in a dig at Game of

**[03:38]** just going to throw in a dig at Game of

**[03:38]** just going to throw in a dig at Game of Thrones because this is the same same

**[03:39]** Thrones because this is the same same

**[03:40]** Thrones because this is the same same thing, right? Like slop is everywhere.

**[03:41]** thing, right? Like slop is everywhere.

**[03:42]** thing, right? Like slop is everywhere. It's generated by humans and AI. You get

**[03:43]** It's generated by humans and AI. You get

**[03:43]** It's generated by humans and AI. You get it? [clears throat]

**[03:45]** it? [clears throat]

**[03:45]** it? [clears throat] Okay. Um the same startup idea can be

**[03:47]** Okay. Um the same startup idea can be

**[03:47]** Okay. Um the same startup idea can be keen versus slop. When I first presented

**[03:49]** keen versus slop. When I first presented

**[03:49]** keen versus slop. When I first presented the my first keynote at AI engineer

**[03:50]** the my first keynote at AI engineer

**[03:50]** the my first keynote at AI engineer summit, we actually used to uh which is

**[03:53]** summit, we actually used to uh which is

**[03:53]** summit, we actually used to uh which is sort of like an AI slides company. Uh I

**[03:55]** sort of like an AI slides company. Uh I

**[03:55]** sort of like an AI slides company. Uh I loaded I loaded up the same slide deck

**[03:57]** loaded I loaded up the same slide deck

**[03:57]** loaded I loaded up the same slide deck and it was gone uh recently because uh


### [04:00 - 05:00]

**[04:00]** and it was gone uh recently because uh

**[04:00]** and it was gone uh recently because uh it was it was actually uh sort of uh

**[04:03]** it was it was actually uh sort of uh

**[04:03]** it was it was actually uh sort of uh closed as a company. Um there's there's

**[04:05]** closed as a company. Um there's there's

**[04:05]** closed as a company. Um there's there's you know different takes on vibe coding

**[04:07]** you know different takes on vibe coding

**[04:07]** you know different takes on vibe coding and I think one of them uh is much

**[04:09]** and I think one of them uh is much

**[04:09]** and I think one of them uh is much better than the other and I think like

**[04:10]** better than the other and I think like

**[04:10]** better than the other and I think like this these are just like the tensions

**[04:11]** this these are just like the tensions

**[04:11]** this these are just like the tensions that we have to navigate. um one of our

**[04:13]** that we have to navigate. um one of our

**[04:13]** that we have to navigate. um one of our speakers later on as well meter. Um I

**[04:16]** speakers later on as well meter. Um I

**[04:16]** speakers later on as well meter. Um I think it's really interesting that both

**[04:17]** think it's really interesting that both

**[04:18]** think it's really interesting that both of them are exponential charts but one

**[04:19]** of them are exponential charts but one

**[04:19]** of them are exponential charts but one of them feels more keeno and the other

**[04:20]** of them feels more keeno and the other

**[04:20]** of them feels more keeno and the other is more slops and I think like I would

**[04:22]** is more slops and I think like I would

**[04:22]** is more slops and I think like I would really like to have people investigate

**[04:24]** really like to have people investigate

**[04:24]** really like to have people investigate why um so let let me let me just skip

**[04:27]** why um so let let me let me just skip

**[04:28]** why um so let let me let me just skip through basically we're in an asymmetric

**[04:30]** through basically we're in an asymmetric

**[04:30]** through basically we're in an asymmetric war and slop um I think u the closest

**[04:33]** war and slop um I think u the closest

**[04:33]** war and slop um I think u the closest law that I found that matches this is

**[04:35]** law that I found that matches this is

**[04:35]** law that I found that matches this is Brandolini's law which actually states

**[04:37]** Brandolini's law which actually states

**[04:37]** Brandolini's law which actually states the amount of energy needed to refuel

**[04:38]** the amount of energy needed to refuel

**[04:38]** the amount of energy needed to refuel is an order of magnitude bigger

**[04:40]** is an order of magnitude bigger

**[04:40]** is an order of magnitude bigger than needed to produce it. Right. So we

**[04:43]** than needed to produce it. Right. So we

**[04:43]** than needed to produce it. Right. So we need to co coin an appropriate law as

**[04:45]** need to co coin an appropriate law as

**[04:45]** need to co coin an appropriate law as well. Um because you know like the the

**[04:48]** well. Um because you know like the the

**[04:48]** well. Um because you know like the the the cost of generating tokens is is

**[04:50]** the cost of generating tokens is is

**[04:50]** the cost of generating tokens is is dropping by 100 to a thousand times

**[04:52]** dropping by 100 to a thousand times

**[04:52]** dropping by 100 to a thousand times every single year.

**[04:54]** every single year.

**[04:54]** every single year. Um so this is I guess Fix's law of

**[04:57]** Um so this is I guess Fix's law of

**[04:57]** Um so this is I guess Fix's law of anti-slav the amount of taste needed to

**[04:59]** anti-slav the amount of taste needed to

**[04:59]** anti-slav the amount of taste needed to fight SLO is in order manually bigger


### [05:00 - 06:00]

**[05:01]** fight SLO is in order manually bigger

**[05:01]** fight SLO is in order manually bigger than that needed to produce it. Right?

**[05:02]** than that needed to produce it. Right?

**[05:02]** than that needed to produce it. Right? There's so much low taste out there. We

**[05:04]** There's so much low taste out there. We

**[05:04]** There's so much low taste out there. We need to elevate uh what's out there in

**[05:06]** need to elevate uh what's out there in

**[05:06]** need to elevate uh what's out there in the world because that's what we stand

**[05:08]** the world because that's what we stand

**[05:08]** the world because that's what we stand for as humans. Um, I think there's

**[05:11]** for as humans. Um, I think there's

**[05:11]** for as humans. Um, I think there's there's a positive message. You can use

**[05:12]** there's a positive message. You can use

**[05:12]** there's a positive message. You can use AI to fight slop. Um, I'm proud I'm

**[05:15]** AI to fight slop. Um, I'm proud I'm

**[05:15]** AI to fight slop. Um, I'm proud I'm proud to run as a side project AI news,

**[05:17]** proud to run as a side project AI news,

**[05:18]** proud to run as a side project AI news, which is the only newsletter that tells

**[05:19]** which is the only newsletter that tells

**[05:19]** which is the only newsletter that tells you not to read it when there's nothing

**[05:20]** you not to read it when there's nothing

**[05:20]** you not to read it when there's nothing going on. Thank [laughter] you. Oh,

**[05:24]** going on. Thank [laughter] you. Oh,

**[05:24]** going on. Thank [laughter] you. Oh, appreciate that. Um, you can also prompt

**[05:28]** appreciate that. Um, you can also prompt

**[05:28]** appreciate that. Um, you can also prompt SLO. The next speaker is um Mahash and

**[05:30]** SLO. The next speaker is um Mahash and

**[05:30]** SLO. The next speaker is um Mahash and Barry. Um I found this in the in the

**[05:32]** Barry. Um I found this in the in the

**[05:32]** Barry. Um I found this in the in the sort of prompt in the in the skill set

**[05:34]** sort of prompt in the in the skill set

**[05:34]** sort of prompt in the in the skill set that they that they put they put where

**[05:36]** that they that they put they put where

**[05:36]** that they that they put they put where they actually acknowledge slop and tell

**[05:38]** they actually acknowledge slop and tell

**[05:38]** they actually acknowledge slop and tell cloud not to produce slop and it

**[05:39]** cloud not to produce slop and it

**[05:39]** cloud not to produce slop and it actually improves significantly from

**[05:41]** actually improves significantly from

**[05:41]** actually improves significantly from left to right. Um what about code slop

**[05:44]** left to right. Um what about code slop

**[05:44]** left to right. Um what about code slop right we hear about code um creating

**[05:46]** right we hear about code um creating

**[05:46]** right we hear about code um creating tech where you can sort of two engineers

**[05:48]** tech where you can sort of two engineers

**[05:48]** tech where you can sort of two engineers can create a tech debt of 50 engineers

**[05:50]** can create a tech debt of 50 engineers

**[05:50]** can create a tech debt of 50 engineers or you know on a more serious note you

**[05:52]** or you know on a more serious note you

**[05:52]** or you know on a more serious note you can start exposing private data of

**[05:54]** can start exposing private data of

**[05:54]** can start exposing private data of millions of users and this this all

**[05:56]** millions of users and this this all

**[05:56]** millions of users and this this all happened this year. Everything I'm

**[05:57]** happened this year. Everything I'm

**[05:57]** happened this year. Everything I'm mentioning all happened this year. I'm

**[05:59]** mentioning all happened this year. I'm

**[05:59]** mentioning all happened this year. I'm kind of using this keynote as a as a way


### [06:00 - 07:00]

**[06:00]** kind of using this keynote as a as a way

**[06:00]** kind of using this keynote as a as a way of recapping. Um, and it, you know, just

**[06:03]** of recapping. Um, and it, you know, just

**[06:03]** of recapping. Um, and it, you know, just to be spicy a little bit, even people

**[06:05]** to be spicy a little bit, even people

**[06:05]** to be spicy a little bit, even people who are saying things like, "Oh, my

**[06:07]** who are saying things like, "Oh, my

**[06:07]** who are saying things like, "Oh, my model can go up to 30 to 60 hours uh

**[06:10]** model can go up to 30 to 60 hours uh

**[06:10]** model can go up to 30 to 60 hours uh autonomously." Well, it feels a bit

**[06:12]** autonomously." Well, it feels a bit

**[06:12]** autonomously." Well, it feels a bit sloppy because you're also not saying,

**[06:14]** sloppy because you're also not saying,

**[06:14]** sloppy because you're also not saying, "Well, was the code good or not?" You're

**[06:15]** "Well, was the code good or not?" You're

**[06:16]** "Well, was the code good or not?" You're just saying how long it went. So, in the

**[06:18]** just saying how long it went. So, in the

**[06:18]** just saying how long it went. So, in the same way that you have no taxation

**[06:19]** same way that you have no taxation

**[06:19]** same way that you have no taxation without representation, you don't want

**[06:21]** without representation, you don't want

**[06:21]** without representation, you don't want autonomy without accountability.

**[06:24]** autonomy without accountability.

**[06:24]** autonomy without accountability. Um something I've been working on more

**[06:26]** Um something I've been working on more

**[06:26]** Um something I've been working on more recently is that using AI to fight code

**[06:28]** recently is that using AI to fight code

**[06:28]** recently is that using AI to fight code slop as well. So uh this is from the a

**[06:31]** slop as well. So uh this is from the a

**[06:31]** slop as well. So uh this is from the a bunch of people quoted this yesterday of

**[06:33]** bunch of people quoted this yesterday of

**[06:33]** bunch of people quoted this yesterday of the semi-ync value of death where you

**[06:35]** the semi-ync value of death where you

**[06:35]** the semi-ync value of death where you can sort of keep human attention and

**[06:37]** can sort of keep human attention and

**[06:37]** can sort of keep human attention and mind meld with the machine in order to

**[06:39]** mind meld with the machine in order to

**[06:39]** mind meld with the machine in order to work on the hardest problems whereas the

**[06:41]** work on the hardest problems whereas the

**[06:41]** work on the hardest problems whereas the stuff that's commoditized you can make

**[06:42]** stuff that's commoditized you can make

**[06:42]** stuff that's commoditized you can make it more async. So you can check out more

**[06:44]** it more async. So you can check out more

**[06:44]** it more async. So you can check out more on that details. What seems to be less

**[06:46]** on that details. What seems to be less

**[06:46]** on that details. What seems to be less appreciated is my is the other work on

**[06:48]** appreciated is my is the other work on

**[06:48]** appreciated is my is the other work on code maps uh which I which I more

**[06:50]** code maps uh which I which I more

**[06:50]** code maps uh which I which I more recently done where we actually use AI

**[06:52]** recently done where we actually use AI

**[06:52]** recently done where we actually use AI to scale codebased understanding which

**[06:53]** to scale codebased understanding which

**[06:54]** to scale codebased understanding which is also a a way to fight slop and you

**[06:57]** is also a a way to fight slop and you

**[06:57]** is also a a way to fight slop and you can uh talk to the cognition folks uh

**[06:58]** can uh talk to the cognition folks uh

**[06:58]** can uh talk to the cognition folks uh downstairs uh um who who can who can


### [07:00 - 08:00]

**[07:01]** downstairs uh um who who can who can

**[07:02]** downstairs uh um who who can who can show you more in detail. Um the the last

**[07:04]** show you more in detail. Um the the last

**[07:04]** show you more in detail. Um the the last thing I always want to shout out as well

**[07:06]** thing I always want to shout out as well

**[07:06]** thing I always want to shout out as well is is this trend of uh computer use. I

**[07:08]** is is this trend of uh computer use. I

**[07:08]** is is this trend of uh computer use. I think computer use kind of debuted it

**[07:10]** think computer use kind of debuted it

**[07:10]** think computer use kind of debuted it this time last year uh with Enthropic.

**[07:13]** this time last year uh with Enthropic.

**[07:13]** this time last year uh with Enthropic. But uh it's it's getting really really

**[07:15]** But uh it's it's getting really really

**[07:15]** But uh it's it's getting really really good now guys. It can really

**[07:16]** good now guys. It can really

**[07:16]** good now guys. It can really autonomously operate the most complex

**[07:17]** autonomously operate the most complex

**[07:17]** autonomously operate the most complex apps including an ID. So I think that's

**[07:19]** apps including an ID. So I think that's

**[07:19]** apps including an ID. So I think that's really uh exciting and you should

**[07:21]** really uh exciting and you should

**[07:21]** really uh exciting and you should probably use that to fight slot. We use

**[07:23]** probably use that to fight slot. We use

**[07:23]** probably use that to fight slot. We use it for the website and here's an example

**[07:25]** it for the website and here's an example

**[07:25]** it for the website and here's an example of us using Devon to automate the the

**[07:28]** of us using Devon to automate the the

**[07:28]** of us using Devon to automate the the sort of website up website updates. Um

**[07:31]** sort of website up website updates. Um

**[07:31]** sort of website up website updates. Um and finally something I learned from

**[07:32]** and finally something I learned from

**[07:32]** and finally something I learned from this conference yesterday is that you

**[07:34]** this conference yesterday is that you

**[07:34]** this conference yesterday is that you can also use sub agents to fight context

**[07:36]** can also use sub agents to fight context

**[07:36]** can also use sub agents to fight context rot. Um and I think that is one of the

**[07:38]** rot. Um and I think that is one of the

**[07:38]** rot. Um and I think that is one of the biggest themes of of uh that I'm

**[07:39]** biggest themes of of uh that I'm

**[07:39]** biggest themes of of uh that I'm observing as well. If you want to take

**[07:40]** observing as well. If you want to take

**[07:40]** observing as well. If you want to take away something from this conference

**[07:43]** away something from this conference

**[07:43]** away something from this conference um and I also one of the biggest

**[07:45]** um and I also one of the biggest

**[07:46]** um and I also one of the biggest highlights of the year for us as AIE and

**[07:47]** highlights of the year for us as AIE and

**[07:47]** highlights of the year for us as AIE and myself personally was chatting with Greg

**[07:49]** myself personally was chatting with Greg

**[07:49]** myself personally was chatting with Greg Brockman who always uh preaches the

**[07:51]** Brockman who always uh preaches the

**[07:52]** Brockman who always uh preaches the concept of modularity where you can sort

**[07:53]** concept of modularity where you can sort

**[07:53]** concept of modularity where you can sort of keep clear boundaries on what is

**[07:56]** of keep clear boundaries on what is

**[07:56]** of keep clear boundaries on what is human designed and let the AI code

**[07:58]** human designed and let the AI code

**[07:58]** human designed and let the AI code everything in between. Um, so these are


### [08:00 - 09:00]

**[08:01]** everything in between. Um, so these are

**[08:01]** everything in between. Um, so these are all ideas, but I just have this one

**[08:03]** all ideas, but I just have this one

**[08:03]** all ideas, but I just have this one message that I want to comp compress

**[08:05]** message that I want to comp compress

**[08:05]** message that I want to comp compress down to you today that I want you to say

**[08:06]** down to you today that I want you to say

**[08:06]** down to you today that I want you to say with me. No more slop. Yeah.

**[08:15]** Your boss tells you, "I want more lines

**[08:15]** Your boss tells you, "I want more lines of code in by the end of the quarter."

**[08:18]** of code in by the end of the quarter."

**[08:18]** of code in by the end of the quarter." What do you say to that? Say it with me.

**[08:20]** What do you say to that? Say it with me.

**[08:20]** What do you say to that? Say it with me. No more slop.

**[08:23]** No more slop.

**[08:23]** No more slop. >> You're fighting an asymmetric war. This

**[08:25]** >> You're fighting an asymmetric war. This

**[08:25]** >> You're fighting an asymmetric war. This is how bad it is, right? You have an

**[08:27]** is how bad it is, right? You have an

**[08:28]** is how bad it is, right? You have an insufficiently tested release that that

**[08:29]** insufficiently tested release that that

**[08:29]** insufficiently tested release that that is potentially embarrassing to your

**[08:31]** is potentially embarrassing to your

**[08:31]** is potentially embarrassing to your company. What do you say to people who

**[08:32]** company. What do you say to people who

**[08:32]** company. What do you say to people who really want to push it?

**[08:34]** really want to push it?

**[08:34]** really want to push it? >> No more slop. Exactly. [laughter]

**[08:38]** >> No more slop. Exactly. [laughter]

**[08:38]** >> No more slop. Exactly. [laughter] Uh your your Twitter algorithm wants

**[08:40]** Uh your your Twitter algorithm wants

**[08:40]** Uh your your Twitter algorithm wants engagement bait uh and is sort of you

**[08:42]** engagement bait uh and is sort of you

**[08:42]** engagement bait uh and is sort of you know forced and telling you to to to lie

**[08:45]** know forced and telling you to to to lie

**[08:45]** know forced and telling you to to to lie basically to the to the broad public.

**[08:47]** basically to the to the broad public.

**[08:47]** basically to the to the broad public. What do you say to that?

**[08:49]** What do you say to that?

**[08:49]** What do you say to that? >> Exactly. That's it. Uh I hope you have a

**[08:51]** >> Exactly. That's it. Uh I hope you have a

**[08:51]** >> Exactly. That's it. Uh I hope you have a great conference and let's let's hear it

**[08:54]** great conference and let's let's hear it

**[08:54]** great conference and let's let's hear it for uh not having any more stuff. Thank

**[08:56]** for uh not having any more stuff. Thank

**[08:56]** for uh not having any more stuff. Thank you. Heat. Heat. [applause]


