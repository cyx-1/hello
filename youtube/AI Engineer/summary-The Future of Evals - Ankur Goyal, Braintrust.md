# The Future of Evals - Ankur Goyal, Braintrust

**Video URL:** https://www.youtube.com/watch?v=MC55hdWLq4o

---

## Executive Summary

Ankur Goyal from Braintrust presents the evolution of AI evaluations (evals) and introduces "Loop," an AI agent that automatically optimizes prompts, datasets, and scorers. He highlights how Braintrust customers run thousands of evals daily, spending hours refining their AI products. The talk emphasizes a major shift from manual evaluation processes to automated optimization, made possible by breakthrough improvements in frontier models like Claude 4, which performs six times better than previous models at improving prompts and evals. Loop is now available to Braintrust users and represents the future of automated AI product optimization.

---

## Main Topics

### 1. **Introduction and Braintrust's Journey**
[https://www.youtube.com/watch?v=MC55hdWLq4o&t=24s](https://www.youtube.com/watch?v=MC55hdWLq4o&t=24s)

- Almost two-year journey at Braintrust working with top AI product companies
- Impressive usage statistics: average org runs ~13 evals per day
- Some customers run over 3,000 evals daily
- Advanced companies spend 2+ hours daily working through evals
- Despite automation in AI products, eval processes remain largely manual

**Key points:**
- Evals are critical for building best-in-class AI products
- Current state: developers look at dashboards and manually adjust code/prompts
- This manual process is about to change dramatically

### 2. **Introducing Loop: AI-Powered Eval Optimization**
[https://www.youtube.com/watch?v=MC55hdWLq4o&t=122s](https://www.youtube.com/watch?v=MC55hdWLq4o&t=122s)

- Loop is a built-in agent within Braintrust for automatic optimization
- Made possible through continuous eval testing over two years
- Quarterly evals tested frontier models' ability to improve prompts, datasets, and scorers
- Claude 4 was a breakthrough: performs 6x better than previous leading models
- Loop optimizes everything from simple prompts to complex agents

**Key capabilities:**
- Automatically optimizes prompts
- Helps build better datasets
- Improves scorers
- Combination of these three elements creates truly great evals

### 3. **Using Loop: Features and Accessibility**
[https://www.youtube.com/watch?v=MC55hdWLq4o&t=183s](https://www.youtube.com/watch?v=MC55hdWLq4o&t=183s)

- Available today for existing and new Braintrust users
- Accessible via feature flag in the product
- Uses Claude 4 by default but supports any model (OpenAI, Gemini, custom LLMs)
- Runs directly inside Braintrust platform
- UI shows side-by-side comparisons of suggested changes
- Preserves ability to review data and prompts during optimization

**Key features:**
- Transparent suggestions for edits to prompts, data, and scoring
- Manual review mode for cautious users
- "Auto-pilot" toggle for autonomous optimization
- Maintains human oversight while automating optimization

### 4. **The Future of Evals and Call to Action**
[https://www.youtube.com/watch?v=MC55hdWLq4o&t=253s](https://www.youtube.com/watch?v=MC55hdWLq4o&t=253s)

- Evals have been critical but incredibly manual until now
- Next year will revolutionize eval processes through frontier models
- Invitation to try Braintrust and Loop
- Team is hiring across UI, AI, and infrastructure roles

**Key message:**
- Shift from manual to automated eval optimization
- Frontier models enabling new capabilities
- Open invitation for feedback and collaboration

---

**Video Duration:** ~5 minutes

**Speaker:** Ankur Goyal, Braintrust
