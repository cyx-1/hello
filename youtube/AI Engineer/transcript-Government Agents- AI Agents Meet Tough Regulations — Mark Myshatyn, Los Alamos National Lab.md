# Government Agents- AI Agents Meet Tough Regulations — Mark Myshatyn, Los Alamos National Lab

**Video URL:** https://www.youtube.com/watch?v=TnSGx36Ly0Q

---

## Full Transcript

### [00:00 - 01:00]

**[00:14]** All right. So, good morning. My name is

**[00:14]** All right. So, good morning. My name is Mark Mashottton. I'm our enterprise AI

**[00:16]** Mark Mashottton. I'm our enterprise AI

**[00:16]** Mark Mashottton. I'm our enterprise AI architect at Los Alamos National

**[00:18]** architect at Los Alamos National

**[00:18]** architect at Los Alamos National Laboratory. Uh, today, you know, this is

**[00:21]** Laboratory. Uh, today, you know, this is

**[00:21]** Laboratory. Uh, today, you know, this is an AI conference. What What's a nuclear

**[00:23]** an AI conference. What What's a nuclear

**[00:23]** an AI conference. What What's a nuclear science lab doing here? The reality is

**[00:25]** science lab doing here? The reality is

**[00:25]** science lab doing here? The reality is we've actually been doing applied a IML

**[00:27]** we've actually been doing applied a IML

**[00:27]** we've actually been doing applied a IML for almost 70 years. Uh this is actually

**[00:29]** for almost 70 years. Uh this is actually

**[00:30]** for almost 70 years. Uh this is actually one of our scientists in 1956

**[00:33]** one of our scientists in 1956

**[00:33]** one of our scientists in 1956 uh playing Los Alamos chess uh in front

**[00:35]** uh playing Los Alamos chess uh in front

**[00:35]** uh playing Los Alamos chess uh in front of one of our first supercomputers,

**[00:37]** of one of our first supercomputers,

**[00:37]** of one of our first supercomputers, Maniac 1. And what's unique about this

**[00:39]** Maniac 1. And what's unique about this

**[00:39]** Maniac 1. And what's unique about this is we if you look at it, there's

**[00:42]** is we if you look at it, there's

**[00:42]** is we if you look at it, there's actually no bishops on the chessboard.

**[00:44]** actually no bishops on the chessboard.

**[00:44]** actually no bishops on the chessboard. You know, we we've been doing applied

**[00:45]** You know, we we've been doing applied

**[00:45]** You know, we we've been doing applied statistics and applied machine learning

**[00:47]** statistics and applied machine learning

**[00:47]** statistics and applied machine learning since we didn't have the memory needed

**[00:49]** since we didn't have the memory needed

**[00:49]** since we didn't have the memory needed to hold an entire chessboard in a

**[00:51]** to hold an entire chessboard in a

**[00:51]** to hold an entire chessboard in a computer at once. And that's fascinating

**[00:54]** computer at once. And that's fascinating

**[00:54]** computer at once. And that's fascinating to to say back when this photo was

**[00:56]** to to say back when this photo was

**[00:56]** to to say back when this photo was taken, it was after the Manhattan

**[00:58]** taken, it was after the Manhattan

**[00:58]** taken, it was after the Manhattan project, we were pushing the edge of


### [01:00 - 02:00]

**[01:01]** project, we were pushing the edge of

**[01:01]** project, we were pushing the edge of developing Monte Carlo methods that we

**[01:03]** developing Monte Carlo methods that we

**[01:03]** developing Monte Carlo methods that we still use today. And for us, you know,

**[01:06]** still use today. And for us, you know,

**[01:06]** still use today. And for us, you know, AI didn't come as a complete surprise,

**[01:09]** AI didn't come as a complete surprise,

**[01:09]** AI didn't come as a complete surprise, but the opportunity that's come with

**[01:11]** but the opportunity that's come with

**[01:11]** but the opportunity that's come with agents, with things we can do has been

**[01:14]** agents, with things we can do has been

**[01:14]** agents, with things we can do has been incredible even to to us that have been

**[01:16]** incredible even to to us that have been

**[01:16]** incredible even to to us that have been along the right the ride for quite some

**[01:19]** along the right the ride for quite some

**[01:19]** along the right the ride for quite some time.

**[01:20]** time.

**[01:20]** time. Uh, let's see if I can make this full

**[01:22]** Uh, let's see if I can make this full

**[01:22]** Uh, let's see if I can make this full screen.

**[01:23]** screen.

**[01:24]** screen. So, what we have going on here, this is

**[01:26]** So, what we have going on here, this is

**[01:26]** So, what we have going on here, this is actually a demonstration. You can find

**[01:29]** actually a demonstration. You can find

**[01:29]** actually a demonstration. You can find it on our YouTube channel if you can't

**[01:31]** it on our YouTube channel if you can't

**[01:31]** it on our YouTube channel if you can't see it on the screen here, but we've

**[01:34]** see it on the screen here, but we've

**[01:34]** see it on the screen here, but we've looked at generative AI, not only from a

**[01:37]** looked at generative AI, not only from a

**[01:37]** looked at generative AI, not only from a strict model standpoint, but also from

**[01:39]** strict model standpoint, but also from

**[01:39]** strict model standpoint, but also from an agentic standpoint as a way for us to

**[01:41]** an agentic standpoint as a way for us to

**[01:41]** an agentic standpoint as a way for us to move science faster. You know, we we

**[01:44]** move science faster. You know, we we

**[01:44]** move science faster. You know, we we like much of the federal government are

**[01:46]** like much of the federal government are

**[01:46]** like much of the federal government are under a squeeze to do better, faster,

**[01:48]** under a squeeze to do better, faster,

**[01:48]** under a squeeze to do better, faster, cheaper, and more to protect our

**[01:49]** cheaper, and more to protect our

**[01:50]** cheaper, and more to protect our country. And in this case, you going

**[01:52]** country. And in this case, you going

**[01:52]** country. And in this case, you going from not just what a model knows, but

**[01:55]** from not just what a model knows, but

**[01:55]** from not just what a model knows, but what we can let a model know was really

**[01:58]** what we can let a model know was really

**[01:58]** what we can let a model know was really the the change that happened here. We


### [02:00 - 03:00]

**[02:00]** the the change that happened here. We

**[02:00]** the the change that happened here. We started with a problem of go design an

**[02:04]** started with a problem of go design an

**[02:04]** started with a problem of go design an ICF, an inertial confinement fusion

**[02:06]** ICF, an inertial confinement fusion

**[02:06]** ICF, an inertial confinement fusion capsule for our sister lab at Liverour

**[02:09]** capsule for our sister lab at Liverour

**[02:09]** capsule for our sister lab at Liverour across the bay here. and we said, "Read

**[02:11]** across the bay here. and we said, "Read

**[02:12]** across the bay here. and we said, "Read a paper. Go read lots of papers that you

**[02:14]** a paper. Go read lots of papers that you

**[02:14]** a paper. Go read lots of papers that you think are tangential to this first paper

**[02:16]** think are tangential to this first paper

**[02:16]** think are tangential to this first paper and then come up with a design for a

**[02:18]** and then come up with a design for a

**[02:18]** and then come up with a design for a fusion capsule." Uh, it created a

**[02:21]** fusion capsule." Uh, it created a

**[02:21]** fusion capsule." Uh, it created a hypothesis. And the thing that's kind of

**[02:22]** hypothesis. And the thing that's kind of

**[02:22]** hypothesis. And the thing that's kind of uniquely ours is this isn't a generic,

**[02:26]** uniquely ours is this isn't a generic,

**[02:26]** uniquely ours is this isn't a generic, you know, chatbot that spits back a

**[02:27]** you know, chatbot that spits back a

**[02:27]** you know, chatbot that spits back a bunch of code. What you'll see here in a

**[02:29]** bunch of code. What you'll see here in a

**[02:29]** bunch of code. What you'll see here in a second, we're actually executing that

**[02:31]** second, we're actually executing that

**[02:31]** second, we're actually executing that code on our high performance computing

**[02:33]** code on our high performance computing

**[02:33]** code on our high performance computing assets. And we are actually running, you

**[02:36]** assets. And we are actually running, you

**[02:36]** assets. And we are actually running, you know, thermodynamic hydrodnamic tests on

**[02:38]** know, thermodynamic hydrodnamic tests on

**[02:38]** know, thermodynamic hydrodnamic tests on some of these types of problems where

**[02:42]** some of these types of problems where

**[02:42]** some of these types of problems where our model, you know, isn't just an LLM.

**[02:45]** our model, you know, isn't just an LLM.

**[02:46]** our model, you know, isn't just an LLM. It's all of the, you know, 50 60 plus

**[02:48]** It's all of the, you know, 50 60 plus

**[02:48]** It's all of the, you know, 50 60 plus years of math and science that we've

**[02:50]** years of math and science that we've

**[02:50]** years of math and science that we've done to to bring the the management and

**[02:54]** done to to bring the the management and

**[02:54]** done to to bring the the management and the development of our nuclear stockpile

**[02:56]** the development of our nuclear stockpile

**[02:56]** the development of our nuclear stockpile and stewardship of that stockpile, bring

**[02:58]** and stewardship of that stockpile, bring

**[02:58]** and stewardship of that stockpile, bring those tools into an agentic era. So,


### [03:00 - 04:00]

**[03:01]** those tools into an agentic era. So,

**[03:01]** those tools into an agentic era. So, we're looking at this as a chance for

**[03:03]** we're looking at this as a chance for

**[03:03]** we're looking at this as a chance for agents to move faster uh and for for

**[03:06]** agents to move faster uh and for for

**[03:06]** agents to move faster uh and for for science to move faster because the risk

**[03:08]** science to move faster because the risk

**[03:08]** science to move faster because the risk at the same time is starting to move

**[03:10]** at the same time is starting to move

**[03:10]** at the same time is starting to move faster. You can see here it actually did

**[03:12]** faster. You can see here it actually did

**[03:12]** faster. You can see here it actually did come up with a design that it thought

**[03:14]** come up with a design that it thought

**[03:14]** come up with a design that it thought optimize that yield and we were

**[03:15]** optimize that yield and we were

**[03:15]** optimize that yield and we were simulating a slice through an ICF

**[03:17]** simulating a slice through an ICF

**[03:17]** simulating a slice through an ICF capsule.

**[03:19]** capsule.

**[03:20]** capsule. But, okay, that's one nice toy problem.

**[03:23]** But, okay, that's one nice toy problem.

**[03:23]** But, okay, that's one nice toy problem. What does that mean for the other 20,000

**[03:25]** What does that mean for the other 20,000

**[03:25]** What does that mean for the other 20,000 researchers that we have at our

**[03:27]** researchers that we have at our

**[03:27]** researchers that we have at our laboratory? For those of you not

**[03:28]** laboratory? For those of you not

**[03:28]** laboratory? For those of you not familiar, we're 40 square miles of labs,

**[03:32]** familiar, we're 40 square miles of labs,

**[03:32]** familiar, we're 40 square miles of labs, test sites, uh, test plants. We have 13

**[03:36]** test sites, uh, test plants. We have 13

**[03:36]** test sites, uh, test plants. We have 13 nuclear facilities. And so, we're huge.

**[03:38]** nuclear facilities. And so, we're huge.

**[03:38]** nuclear facilities. And so, we're huge. We have a huge breath of what we're

**[03:40]** We have a huge breath of what we're

**[03:40]** We have a huge breath of what we're trying to accomplish with AI, uh, and

**[03:43]** trying to accomplish with AI, uh, and

**[03:43]** trying to accomplish with AI, uh, and getting our mission moving faster. For

**[03:45]** getting our mission moving faster. For

**[03:45]** getting our mission moving faster. For our national security AI office, you

**[03:47]** our national security AI office, you

**[03:47]** our national security AI office, you know what you just saw, that's the first

**[03:49]** know what you just saw, that's the first

**[03:49]** know what you just saw, that's the first thing of that we're charged with. Push

**[03:50]** thing of that we're charged with. Push

**[03:50]** thing of that we're charged with. Push the science of AI faster. Don't just sit

**[03:53]** the science of AI faster. Don't just sit

**[03:53]** the science of AI faster. Don't just sit there and consume commercial tools or

**[03:55]** there and consume commercial tools or

**[03:55]** there and consume commercial tools or open source tools. We write our stuff.

**[03:57]** open source tools. We write our stuff.

**[03:57]** open source tools. We write our stuff. We write our own models. Uh we also


### [04:00 - 05:00]

**[04:00]** We write our own models. Uh we also

**[04:00]** We write our own models. Uh we also realize that we can't do everything. We

**[04:01]** realize that we can't do everything. We

**[04:01]** realize that we can't do everything. We don't have the hubris to understand or

**[04:03]** don't have the hubris to understand or

**[04:03]** don't have the hubris to understand or to say here and oh we understand

**[04:05]** to say here and oh we understand

**[04:05]** to say here and oh we understand everything. We don't need anyone's help.

**[04:06]** everything. We don't need anyone's help.

**[04:06]** everything. We don't need anyone's help. We absolutely need those partnerships

**[04:08]** We absolutely need those partnerships

**[04:08]** We absolutely need those partnerships from commercial industry from academia.

**[04:11]** from commercial industry from academia.

**[04:11]** from commercial industry from academia. And then just like the rest of you all

**[04:13]** And then just like the rest of you all

**[04:13]** And then just like the rest of you all here, we're looking at how do we bring

**[04:15]** here, we're looking at how do we bring

**[04:15]** here, we're looking at how do we bring AI and Gen AI tools into our workflows.

**[04:17]** AI and Gen AI tools into our workflows.

**[04:17]** AI and Gen AI tools into our workflows. You know, we have a huge footprint. We

**[04:20]** You know, we have a huge footprint. We

**[04:20]** You know, we have a huge footprint. We have to do payroll. We have to do

**[04:23]** have to do payroll. We have to do

**[04:23]** have to do payroll. We have to do procurement. We have to do cyber

**[04:24]** procurement. We have to do cyber

**[04:24]** procurement. We have to do cyber security. And so our office is kind of

**[04:26]** security. And so our office is kind of

**[04:26]** security. And so our office is kind of in there. How do we do that? And it

**[04:29]** in there. How do we do that? And it

**[04:29]** in there. How do we do that? And it really does come down some to some of

**[04:31]** really does come down some to some of

**[04:31]** really does come down some to some of what we're doing with our partners. We

**[04:32]** what we're doing with our partners. We

**[04:32]** what we're doing with our partners. We have some great academic partners. We

**[04:34]** have some great academic partners. We

**[04:34]** have some great academic partners. We couldn't at the time these slides were

**[04:36]** couldn't at the time these slides were

**[04:36]** couldn't at the time these slides were released for uh public review, we didn't

**[04:38]** released for uh public review, we didn't

**[04:38]** released for uh public review, we didn't get the screenshot on there. We also

**[04:40]** get the screenshot on there. We also

**[04:40]** get the screenshot on there. We also announced a partnership with the UC

**[04:42]** announced a partnership with the UC

**[04:42]** announced a partnership with the UC family of schools uh on the academic

**[04:44]** family of schools uh on the academic

**[04:44]** family of schools uh on the academic side of developing, you know, the future

**[04:46]** side of developing, you know, the future

**[04:46]** side of developing, you know, the future of AI. But we're also working with all

**[04:48]** of AI. But we're also working with all

**[04:48]** of AI. But we're also working with all the frontier labs. you know, here's a

**[04:49]** the frontier labs. you know, here's a

**[04:49]** the frontier labs. you know, here's a couple press releases where we've

**[04:51]** couple press releases where we've

**[04:51]** couple press releases where we've actually done chem biosafety work with

**[04:54]** actually done chem biosafety work with

**[04:54]** actually done chem biosafety work with open AAI and we we've been able to

**[04:57]** open AAI and we we've been able to

**[04:57]** open AAI and we we've been able to acknowledge that work that we've done

**[04:58]** acknowledge that work that we've done

**[04:58]** acknowledge that work that we've done with them, but we have a place where


### [05:00 - 06:00]

**[05:00]** with them, but we have a place where

**[05:00]** with them, but we have a place where we've been doing we're a safe place to

**[05:02]** we've been doing we're a safe place to

**[05:02]** we've been doing we're a safe place to do dangerous things and we've been doing

**[05:03]** do dangerous things and we've been doing

**[05:03]** do dangerous things and we've been doing that for decades. So, it's a neat

**[05:05]** that for decades. So, it's a neat

**[05:05]** that for decades. So, it's a neat partnership to have these frontier labs

**[05:07]** partnership to have these frontier labs

**[05:07]** partnership to have these frontier labs that really can't afford to hire anyone

**[05:09]** that really can't afford to hire anyone

**[05:09]** that really can't afford to hire anyone they want still come to us as a source

**[05:11]** they want still come to us as a source

**[05:11]** they want still come to us as a source of data and a source of partnership.

**[05:14]** of data and a source of partnership.

**[05:14]** of data and a source of partnership. There in the middle of that last

**[05:15]** There in the middle of that last

**[05:15]** There in the middle of that last picture, we actually have science of AI

**[05:18]** picture, we actually have science of AI

**[05:18]** picture, we actually have science of AI in the hardware space. Uh that's our

**[05:21]** in the hardware space. Uh that's our

**[05:21]** in the hardware space. Uh that's our Venado supercomputer. It's over 2500

**[05:23]** Venado supercomputer. It's over 2500

**[05:23]** Venado supercomputer. It's over 2500 nodes of GraceHopper super chips and we

**[05:27]** nodes of GraceHopper super chips and we

**[05:27]** nodes of GraceHopper super chips and we we brought it um through a partnership

**[05:29]** we brought it um through a partnership

**[05:29]** we brought it um through a partnership with open or with um Nvidia and uh HPE

**[05:34]** with open or with um Nvidia and uh HPE

**[05:34]** with open or with um Nvidia and uh HPE to build a supercomput that can help us

**[05:37]** to build a supercomput that can help us

**[05:37]** to build a supercomput that can help us push the boundaries of what does it mean

**[05:38]** push the boundaries of what does it mean

**[05:38]** push the boundaries of what does it mean to do AI research. And then more

**[05:39]** to do AI research. And then more

**[05:39]** to do AI research. And then more recently, we've also brought OpenAI's

**[05:42]** recently, we've also brought OpenAI's

**[05:42]** recently, we've also brought OpenAI's models onto this system, brought it up

**[05:45]** models onto this system, brought it up

**[05:45]** models onto this system, brought it up to our classified networks, and we're

**[05:47]** to our classified networks, and we're

**[05:47]** to our classified networks, and we're getting to work on the really hard

**[05:48]** getting to work on the really hard

**[05:48]** getting to work on the really hard problems that are unique to our data and

**[05:51]** problems that are unique to our data and

**[05:51]** problems that are unique to our data and our mission space.

**[05:53]** our mission space.

**[05:53]** our mission space. When we talk about agents, you know,

**[05:54]** When we talk about agents, you know,

**[05:54]** When we talk about agents, you know, partnerships take trust, you know,

**[05:56]** partnerships take trust, you know,

**[05:56]** partnerships take trust, you know, certainly having labs trust you with

**[05:58]** certainly having labs trust you with

**[05:58]** certainly having labs trust you with early access to their models or model


### [06:00 - 07:00]

**[06:00]** early access to their models or model

**[06:00]** early access to their models or model weights. As we talk about sharing

**[06:01]** weights. As we talk about sharing

**[06:01]** weights. As we talk about sharing responsibility with our partners,

**[06:03]** responsibility with our partners,

**[06:03]** responsibility with our partners, certainly the responsibility of what our

**[06:06]** certainly the responsibility of what our

**[06:06]** certainly the responsibility of what our AI tools and services do starts to

**[06:09]** AI tools and services do starts to

**[06:09]** AI tools and services do starts to matter. Uh there were previous

**[06:10]** matter. Uh there were previous

**[06:10]** matter. Uh there were previous administration had certain executive

**[06:12]** administration had certain executive

**[06:12]** administration had certain executive orders out. Those were replaced largely

**[06:14]** orders out. Those were replaced largely

**[06:14]** orders out. Those were replaced largely in January when the new administration

**[06:16]** in January when the new administration

**[06:16]** in January when the new administration took change. But this piece of OM

**[06:18]** took change. But this piece of OM

**[06:18]** took change. But this piece of OM memorandum just came out in April. Uh

**[06:20]** memorandum just came out in April. Uh

**[06:20]** memorandum just came out in April. Uh M2521 and there's M2522.

**[06:24]** M2521 and there's M2522.

**[06:24]** M2521 and there's M2522. And it starts to codify like what things

**[06:27]** And it starts to codify like what things

**[06:27]** And it starts to codify like what things should the US government start to worry

**[06:29]** should the US government start to worry

**[06:29]** should the US government start to worry about when we're fielding these AI

**[06:31]** about when we're fielding these AI

**[06:31]** about when we're fielding these AI systems. It tells the government to go

**[06:33]** systems. It tells the government to go

**[06:33]** systems. It tells the government to go faster. That's important. But it also

**[06:35]** faster. That's important. But it also

**[06:35]** faster. That's important. But it also says these government type workloads,

**[06:38]** says these government type workloads,

**[06:38]** says these government type workloads, they have real world impacts. You know,

**[06:40]** they have real world impacts. You know,

**[06:40]** they have real world impacts. You know, for us, we are not a t-shirt company. If

**[06:42]** for us, we are not a t-shirt company. If

**[06:42]** for us, we are not a t-shirt company. If our data gets out, that's, you know,

**[06:44]** our data gets out, that's, you know,

**[06:44]** our data gets out, that's, you know, geopolitical challenges show up. Uh

**[06:47]** geopolitical challenges show up. Uh

**[06:47]** geopolitical challenges show up. Uh kinetic challenges show up. People can

**[06:49]** kinetic challenges show up. People can

**[06:49]** kinetic challenges show up. People can die if we do this wrong. And this I

**[06:52]** die if we do this wrong. And this I

**[06:52]** die if we do this wrong. And this I won't bore you. It's like 25 pages,

**[06:54]** won't bore you. It's like 25 pages,

**[06:54]** won't bore you. It's like 25 pages, reasonably well written for an OMB

**[06:56]** reasonably well written for an OMB

**[06:56]** reasonably well written for an OMB memorandum as far as readability and

**[06:58]** memorandum as far as readability and

**[06:58]** memorandum as far as readability and comprehensiveness, but it says we as the


### [07:00 - 08:00]

**[07:01]** comprehensiveness, but it says we as the

**[07:01]** comprehensiveness, but it says we as the US government need to move faster into

**[07:03]** US government need to move faster into

**[07:03]** US government need to move faster into bringing this into everything we do.

**[07:05]** bringing this into everything we do.

**[07:05]** bringing this into everything we do. It's not enough to just buy, you know,

**[07:07]** It's not enough to just buy, you know,

**[07:07]** It's not enough to just buy, you know, pick your favorite office addin tool and

**[07:10]** pick your favorite office addin tool and

**[07:10]** pick your favorite office addin tool and say we can type powerpoints faster or

**[07:13]** say we can type powerpoints faster or

**[07:13]** say we can type powerpoints faster or summarize our emails faster. We got to

**[07:14]** summarize our emails faster. We got to

**[07:14]** summarize our emails faster. We got to go deeper into our mission and that

**[07:17]** go deeper into our mission and that

**[07:17]** go deeper into our mission and that comes with trust. So, who here is part

**[07:19]** comes with trust. So, who here is part

**[07:19]** comes with trust. So, who here is part of a software as a service uh company or

**[07:22]** of a software as a service uh company or

**[07:22]** of a software as a service uh company or startup?

**[07:24]** startup?

**[07:24]** startup? Okay, handful of hands here. So, you've

**[07:26]** Okay, handful of hands here. So, you've

**[07:26]** Okay, handful of hands here. So, you've probably seen something similar to this,

**[07:28]** probably seen something similar to this,

**[07:28]** probably seen something similar to this, especially if you've been in the cloud

**[07:29]** especially if you've been in the cloud

**[07:29]** especially if you've been in the cloud space recently, that as us as customers

**[07:32]** space recently, that as us as customers

**[07:32]** space recently, that as us as customers start to trust you with our data, your

**[07:35]** start to trust you with our data, your

**[07:35]** start to trust you with our data, your responsibility also comes up. Uh that's

**[07:37]** responsibility also comes up. Uh that's

**[07:37]** responsibility also comes up. Uh that's easy to do for our open public

**[07:39]** easy to do for our open public

**[07:39]** easy to do for our open public unrestricted data like the open science

**[07:41]** unrestricted data like the open science

**[07:41]** unrestricted data like the open science work like I showed off of our ICF

**[07:43]** work like I showed off of our ICF

**[07:43]** work like I showed off of our ICF capsule agent. But as we get into

**[07:45]** capsule agent. But as we get into

**[07:45]** capsule agent. But as we get into controlled and classified, as we get

**[07:47]** controlled and classified, as we get

**[07:47]** controlled and classified, as we get into classified and the DOE space, as we

**[07:49]** into classified and the DOE space, as we

**[07:49]** into classified and the DOE space, as we get into restricted and formerly

**[07:51]** get into restricted and formerly

**[07:51]** get into restricted and formerly restricted data, where the physics of

**[07:53]** restricted data, where the physics of

**[07:53]** restricted data, where the physics of how nuclear weapons work don't expire,

**[07:56]** how nuclear weapons work don't expire,

**[07:56]** how nuclear weapons work don't expire, that that will forever be classified.

**[07:57]** that that will forever be classified.

**[07:58]** that that will forever be classified. It's born, classified, and stays

**[07:59]** It's born, classified, and stays

**[07:59]** It's born, classified, and stays classified. It takes an element of trust


### [08:00 - 09:00]

**[08:01]** classified. It takes an element of trust

**[08:01]** classified. It takes an element of trust in you all as our builders, as our

**[08:03]** in you all as our builders, as our

**[08:04]** in you all as our builders, as our providers. And this is really some of

**[08:05]** providers. And this is really some of

**[08:05]** providers. And this is really some of the most interesting and unfrusting

**[08:07]** the most interesting and unfrusting

**[08:07]** the most interesting and unfrusting conversations we have with companies

**[08:09]** conversations we have with companies

**[08:09]** conversations we have with companies trying to sell us tools and services is

**[08:13]** trying to sell us tools and services is

**[08:13]** trying to sell us tools and services is great. You have your sock 2 report. I

**[08:16]** great. You have your sock 2 report. I

**[08:16]** great. You have your sock 2 report. I have NIST 853. This is actually rev 4.

**[08:19]** have NIST 853. This is actually rev 4.

**[08:20]** have NIST 853. This is actually rev 4. It's over a,000 different security

**[08:22]** It's over a,000 different security

**[08:22]** It's over a,000 different security controls and enhancements. And the the

**[08:25]** controls and enhancements. And the the

**[08:25]** controls and enhancements. And the the US government has put a lot of

**[08:26]** US government has put a lot of

**[08:26]** US government has put a lot of legislation in place to do traditional

**[08:28]** legislation in place to do traditional

**[08:28]** legislation in place to do traditional cyber security work. Fed Ramp certainly

**[08:31]** cyber security work. Fed Ramp certainly

**[08:31]** cyber security work. Fed Ramp certainly tried to make this easier by coming in

**[08:33]** tried to make this easier by coming in

**[08:34]** tried to make this easier by coming in and saying, you know, 200 your security

**[08:35]** and saying, you know, 200 your security

**[08:36]** and saying, you know, 200 your security controls, 300, 400 have been vetted with

**[08:39]** controls, 300, 400 have been vetted with

**[08:39]** controls, 300, 400 have been vetted with a third party authorizer. You have some

**[08:41]** a third party authorizer. You have some

**[08:41]** a third party authorizer. You have some continuous monitoring. Has anyone here

**[08:43]** continuous monitoring. Has anyone here

**[08:43]** continuous monitoring. Has anyone here been downstream of the Fed ramp process?

**[08:46]** been downstream of the Fed ramp process?

**[08:46]** been downstream of the Fed ramp process? Yeah, I see a couple smiles. So, you

**[08:48]** Yeah, I see a couple smiles. So, you

**[08:48]** Yeah, I see a couple smiles. So, you know how much of a pain this has been.

**[08:50]** know how much of a pain this has been.

**[08:50]** know how much of a pain this has been. And much like everything else in the

**[08:52]** And much like everything else in the

**[08:52]** And much like everything else in the government right now, it is changing.

**[08:53]** government right now, it is changing.

**[08:53]** government right now, it is changing. There's a new Fed ramp program out there

**[08:55]** There's a new Fed ramp program out there

**[08:55]** There's a new Fed ramp program out there saying if we're going to trust you with

**[08:58]** saying if we're going to trust you with

**[08:58]** saying if we're going to trust you with our data, if we're going to trust trust


### [09:00 - 10:00]

**[09:00]** our data, if we're going to trust trust

**[09:00]** our data, if we're going to trust trust you with the outcomes of our agents, you

**[09:02]** you with the outcomes of our agents, you

**[09:02]** you with the outcomes of our agents, you have to start thinking about your

**[09:04]** have to start thinking about your

**[09:04]** have to start thinking about your continuous monitoring, your continuous

**[09:05]** continuous monitoring, your continuous

**[09:05]** continuous monitoring, your continuous security posture. Uh if you work with

**[09:08]** security posture. Uh if you work with

**[09:08]** security posture. Uh if you work with the DoD, that gets even harder. Uh DoD

**[09:11]** the DoD, that gets even harder. Uh DoD

**[09:11]** the DoD, that gets even harder. Uh DoD has what they call their security

**[09:12]** has what they call their security

**[09:12]** has what they call their security requirements guide or CCSRG. Um it talks

**[09:16]** requirements guide or CCSRG. Um it talks

**[09:16]** requirements guide or CCSRG. Um it talks about if you're touching this type of

**[09:18]** about if you're touching this type of

**[09:18]** about if you're touching this type of data level. So it takes that three types

**[09:20]** data level. So it takes that three types

**[09:20]** data level. So it takes that three types or three types of Fed ramp. It layers on

**[09:22]** or three types of Fed ramp. It layers on

**[09:22]** or three types of Fed ramp. It layers on two more uh impact levels as the DoD

**[09:24]** two more uh impact levels as the DoD

**[09:24]** two more uh impact levels as the DoD calls them and says this is how you're

**[09:26]** calls them and says this is how you're

**[09:26]** calls them and says this is how you're going to access that service if you have

**[09:29]** going to access that service if you have

**[09:29]** going to access that service if you have PII or mission data or operational data

**[09:32]** PII or mission data or operational data

**[09:32]** PII or mission data or operational data or finance data. And then they add

**[09:35]** or finance data. And then they add

**[09:35]** or finance data. And then they add another copy of this book, you know,

**[09:37]** another copy of this book, you know,

**[09:37]** another copy of this book, you know, CNSSI 1253 on top of that. So if if

**[09:41]** CNSSI 1253 on top of that. So if if

**[09:41]** CNSSI 1253 on top of that. So if if you're looking at this saying it's a lot

**[09:43]** you're looking at this saying it's a lot

**[09:43]** you're looking at this saying it's a lot of governance, it is. Um but the fun

**[09:46]** of governance, it is. Um but the fun

**[09:46]** of governance, it is. Um but the fun part is right now where we are today

**[09:48]** part is right now where we are today

**[09:48]** part is right now where we are today from those uh April 3rd memorandums is

**[09:53]** from those uh April 3rd memorandums is

**[09:53]** from those uh April 3rd memorandums is AI use cases, AI governance is still on

**[09:55]** AI use cases, AI governance is still on

**[09:56]** AI use cases, AI governance is still on the drawing board. Like we are in that

**[09:58]** the drawing board. Like we are in that

**[09:58]** the drawing board. Like we are in that 180day rulemaking period that these uh


### [10:00 - 11:00]

**[10:01]** 180day rulemaking period that these uh

**[10:01]** 180day rulemaking period that these uh pieces of OM memoranda put out saying

**[10:05]** pieces of OM memoranda put out saying

**[10:05]** pieces of OM memoranda put out saying agent or agencies have to go develop

**[10:07]** agent or agencies have to go develop

**[10:07]** agent or agencies have to go develop their strategies, their plans for

**[10:10]** their strategies, their plans for

**[10:10]** their strategies, their plans for developing you know AI implementations.

**[10:13]** developing you know AI implementations.

**[10:13]** developing you know AI implementations. How do you govern pilots? What's

**[10:14]** How do you govern pilots? What's

**[10:14]** How do you govern pilots? What's considered high-risisk, lowrisisk in

**[10:16]** considered high-risisk, lowrisisk in

**[10:16]** considered high-risisk, lowrisisk in your context? And there's some

**[10:19]** your context? And there's some

**[10:19]** your context? And there's some prescriptive guidance out there. NIST

**[10:20]** prescriptive guidance out there. NIST

**[10:20]** prescriptive guidance out there. NIST back in 2023 released their AI risk

**[10:23]** back in 2023 released their AI risk

**[10:23]** back in 2023 released their AI risk management framework.

**[10:24]** management framework.

**[10:24]** management framework. >> Breakout sessions will begin in 5

**[10:26]** >> Breakout sessions will begin in 5

**[10:26]** >> Breakout sessions will begin in 5 minutes.

**[10:26]** minutes.

**[10:26]** minutes. >> Five minutes for morning breakout

**[10:27]** >> Five minutes for morning breakout

**[10:27]** >> Five minutes for morning breakout sessions. [laughter]

**[10:29]** sessions. [laughter]

**[10:29]** sessions. [laughter] >> Your choice.

**[10:29]** >> Your choice.

**[10:30]** >> Your choice. >> But the fun part is you can develop the

**[10:32]** >> But the fun part is you can develop the

**[10:32]** >> But the fun part is you can develop the future with your customers right now.

**[10:34]** future with your customers right now.

**[10:34]** future with your customers right now. Now, this is a clean sheet of paper from

**[10:37]** Now, this is a clean sheet of paper from

**[10:37]** Now, this is a clean sheet of paper from a technology perspective that we largely

**[10:40]** a technology perspective that we largely

**[10:40]** a technology perspective that we largely haven't had to tackle. Uh, and it's it's

**[10:43]** haven't had to tackle. Uh, and it's it's

**[10:43]** haven't had to tackle. Uh, and it's it's fun in a US government space to say we

**[10:45]** fun in a US government space to say we

**[10:45]** fun in a US government space to say we can invent part of the future together

**[10:47]** can invent part of the future together

**[10:47]** can invent part of the future together with commercial industry. Um, make

**[10:50]** with commercial industry. Um, make

**[10:50]** with commercial industry. Um, make hopefully better, less obnoxious, less

**[10:53]** hopefully better, less obnoxious, less

**[10:53]** hopefully better, less obnoxious, less obstructive decisions so we can keep

**[10:54]** obstructive decisions so we can keep

**[10:54]** obstructive decisions so we can keep moving mission faster. And and if it

**[10:57]** moving mission faster. And and if it

**[10:57]** moving mission faster. And and if it sounds like this is a lot of lawyers and

**[10:58]** sounds like this is a lot of lawyers and

**[10:58]** sounds like this is a lot of lawyers and paperwork, it probably is. Um, there


### [11:00 - 12:00]

**[11:01]** paperwork, it probably is. Um, there

**[11:01]** paperwork, it probably is. Um, there there's no getting around. Some of these

**[11:02]** there's no getting around. Some of these

**[11:02]** there's no getting around. Some of these records and artifacts do have to exist.

**[11:05]** records and artifacts do have to exist.

**[11:05]** records and artifacts do have to exist. But the the reason you'd want to

**[11:06]** But the the reason you'd want to

**[11:06]** But the the reason you'd want to collaborate with us is we're doing

**[11:08]** collaborate with us is we're doing

**[11:08]** collaborate with us is we're doing things that are either incredibly hard

**[11:10]** things that are either incredibly hard

**[11:10]** things that are either incredibly hard or can't be done in commercial industry.

**[11:13]** or can't be done in commercial industry.

**[11:13]** or can't be done in commercial industry. Um, at least at Los Alamos, we are

**[11:15]** Um, at least at Los Alamos, we are

**[11:15]** Um, at least at Los Alamos, we are sitting on pabytes of data that has

**[11:18]** sitting on pabytes of data that has

**[11:18]** sitting on pabytes of data that has never seen the internet, will never see

**[11:19]** never seen the internet, will never see

**[11:19]** never seen the internet, will never see the internet. Uh we have subject matter

**[11:22]** the internet. Uh we have subject matter

**[11:22]** the internet. Uh we have subject matter expertise in chem uh bio materials

**[11:25]** expertise in chem uh bio materials

**[11:25]** expertise in chem uh bio materials physics um materials composites um

**[11:29]** physics um materials composites um

**[11:29]** physics um materials composites um certainly cyber security and the design

**[11:30]** certainly cyber security and the design

**[11:30]** certainly cyber security and the design of high performance computing that some

**[11:33]** of high performance computing that some

**[11:33]** of high performance computing that some of the partnerships I mentioned earlier

**[11:35]** of the partnerships I mentioned earlier

**[11:35]** of the partnerships I mentioned earlier and they can be your partnerships too.

**[11:37]** and they can be your partnerships too.

**[11:37]** and they can be your partnerships too. You know we we firmly believe that if

**[11:40]** You know we we firmly believe that if

**[11:40]** You know we we firmly believe that if we're talking about taking care of the

**[11:42]** we're talking about taking care of the

**[11:42]** we're talking about taking care of the country taking care of our national

**[11:43]** country taking care of our national

**[11:43]** country taking care of our national competitive advantage that's not just a

**[11:46]** competitive advantage that's not just a

**[11:46]** competitive advantage that's not just a bunch of scientists sitting on a

**[11:47]** bunch of scientists sitting on a

**[11:47]** bunch of scientists sitting on a mountain side in Los Alamos that are

**[11:48]** mountain side in Los Alamos that are

**[11:48]** mountain side in Los Alamos that are going to figure that out. We really do

**[11:50]** going to figure that out. We really do

**[11:50]** going to figure that out. We really do want your help and your uh engagement

**[11:52]** want your help and your uh engagement

**[11:52]** want your help and your uh engagement with us to you know push the boundaries

**[11:54]** with us to you know push the boundaries

**[11:54]** with us to you know push the boundaries of what we know. This was originally

**[11:56]** of what we know. This was originally

**[11:56]** of what we know. This was originally meant to be an architecture talk. So

**[11:57]** meant to be an architecture talk. So

**[11:58]** meant to be an architecture talk. So finishing up with an architecture slide.


### [12:00 - 13:00]

**[12:00]** finishing up with an architecture slide.

**[12:00]** finishing up with an architecture slide. If you are interested in bringing a

**[12:02]** If you are interested in bringing a

**[12:02]** If you are interested in bringing a agentic tools, agentic services to the

**[12:05]** agentic tools, agentic services to the

**[12:05]** agentic tools, agentic services to the federal government. There's really four

**[12:06]** federal government. There's really four

**[12:06]** federal government. There's really four things to think about. You know, we want

**[12:08]** things to think about. You know, we want

**[12:08]** things to think about. You know, we want to see that you've built for

**[12:10]** to see that you've built for

**[12:10]** to see that you've built for explanability. Our keynote this morning

**[12:11]** explanability. Our keynote this morning

**[12:11]** explanability. Our keynote this morning touched on that a little bit of how did

**[12:14]** touched on that a little bit of how did

**[12:14]** touched on that a little bit of how did you get to that decision? you know, if

**[12:16]** you get to that decision? you know, if

**[12:16]** you get to that decision? you know, if if something goes wrong or if we have a

**[12:17]** if something goes wrong or if we have a

**[12:17]** if something goes wrong or if we have a bad day, we don't have shareholders that

**[12:20]** bad day, we don't have shareholders that

**[12:20]** bad day, we don't have shareholders that we're responsible to. We have the US

**[12:22]** we're responsible to. We have the US

**[12:22]** we're responsible to. We have the US citizens to be responsible to. Um, we

**[12:25]** citizens to be responsible to. Um, we

**[12:25]** citizens to be responsible to. Um, we have whatever that outcome was that, you

**[12:27]** have whatever that outcome was that, you

**[12:27]** have whatever that outcome was that, you know, caused some press briefing. We

**[12:29]** know, caused some press briefing. We

**[12:29]** know, caused some press briefing. We need to be able to trust our agents the

**[12:31]** need to be able to trust our agents the

**[12:31]** need to be able to trust our agents the same way we trust our staff. Uh, when we

**[12:34]** same way we trust our staff. Uh, when we

**[12:34]** same way we trust our staff. Uh, when we talk about fielding things, again, we we

**[12:36]** talk about fielding things, again, we we

**[12:36]** talk about fielding things, again, we we are not a t-shirt company. Building for

**[12:38]** are not a t-shirt company. Building for

**[12:38]** are not a t-shirt company. Building for isolation matters. And um I was looking

**[12:41]** isolation matters. And um I was looking

**[12:41]** isolation matters. And um I was looking forward to seeing Microsoft's demo on

**[12:43]** forward to seeing Microsoft's demo on

**[12:43]** forward to seeing Microsoft's demo on the uh

**[12:45]** the uh

**[12:45]** the uh self-hosted uh AI foundry pieces, but

**[12:49]** self-hosted uh AI foundry pieces, but

**[12:49]** self-hosted uh AI foundry pieces, but for us, we do that anyways. We look and

**[12:51]** for us, we do that anyways. We look and

**[12:51]** for us, we do that anyways. We look and leverage heavily open-source tools and

**[12:53]** leverage heavily open-source tools and

**[12:53]** leverage heavily open-source tools and services and models to do some of this

**[12:55]** services and models to do some of this

**[12:55]** services and models to do some of this work because we can't get it from a

**[12:57]** work because we can't get it from a

**[12:57]** work because we can't get it from a hyperscaler cloud provider. Uh so as

**[12:59]** hyperscaler cloud provider. Uh so as

**[12:59]** hyperscaler cloud provider. Uh so as you're building your tools and services,


### [13:00 - 14:00]

**[13:01]** you're building your tools and services,

**[13:01]** you're building your tools and services, take a look at some of those services in

**[13:02]** take a look at some of those services in

**[13:02]** take a look at some of those services in scope page. Even if you are a SAS

**[13:04]** scope page. Even if you are a SAS

**[13:04]** scope page. Even if you are a SAS startup, um if you can build in a DoD

**[13:07]** startup, um if you can build in a DoD

**[13:07]** startup, um if you can build in a DoD impact level 5 environment with that

**[13:09]** impact level 5 environment with that

**[13:09]** impact level 5 environment with that limited number of services from your

**[13:11]** limited number of services from your

**[13:11]** limited number of services from your cloud vendor, you can deploy anywhere.

**[13:14]** cloud vendor, you can deploy anywhere.

**[13:14]** cloud vendor, you can deploy anywhere. You know, you you have the least common

**[13:16]** You know, you you have the least common

**[13:16]** You know, you you have the least common denominator uh out of that entire tech

**[13:18]** denominator uh out of that entire tech

**[13:18]** denominator uh out of that entire tech stack. If you can deploy your, you know,

**[13:20]** stack. If you can deploy your, you know,

**[13:20]** stack. If you can deploy your, you know, your tool, your application there, that

**[13:22]** your tool, your application there, that

**[13:22]** your tool, your application there, that makes our job easier. That makes you

**[13:24]** makes our job easier. That makes you

**[13:24]** makes our job easier. That makes you more portable.

**[13:26]** more portable.

**[13:26]** more portable. And as along with that comes build for

**[13:28]** And as along with that comes build for

**[13:28]** And as along with that comes build for governance. We also have some awkward

**[13:31]** governance. We also have some awkward

**[13:31]** governance. We also have some awkward conversations with customers where it's

**[13:33]** conversations with customers where it's

**[13:33]** conversations with customers where it's well we need a software bill of

**[13:35]** well we need a software bill of

**[13:35]** well we need a software bill of materials as we're doing this

**[13:36]** materials as we're doing this

**[13:36]** materials as we're doing this procurement with you and yeah [laughter]

**[13:39]** procurement with you and yeah [laughter]

**[13:39]** procurement with you and yeah [laughter] uh people look at us like I mean I guess

**[13:41]** uh people look at us like I mean I guess

**[13:41]** uh people look at us like I mean I guess we can dump you know what we had in our

**[13:43]** we can dump you know what we had in our

**[13:44]** we can dump you know what we had in our build script and it's it's a little bit

**[13:45]** build script and it's it's a little bit

**[13:45]** build script and it's it's a little bit of an awkward conversation but that's

**[13:47]** of an awkward conversation but that's

**[13:47]** of an awkward conversation but that's required per our regs you know AI stuff

**[13:49]** required per our regs you know AI stuff

**[13:49]** required per our regs you know AI stuff is moving a mile a minute the

**[13:51]** is moving a mile a minute the

**[13:51]** is moving a mile a minute the traditional cyber security stuff is

**[13:53]** traditional cyber security stuff is

**[13:53]** traditional cyber security stuff is moving faster but not quite there yet so

**[13:56]** moving faster but not quite there yet so

**[13:56]** moving faster but not quite there yet so if you can plan to have those

**[13:57]** if you can plan to have those

**[13:57]** if you can plan to have those conversations of how did you handle open

**[13:59]** conversations of how did you handle open

**[13:59]** conversations of how did you handle open source dependencies. What are your


### [14:00 - 15:00]

**[14:01]** source dependencies. What are your

**[14:01]** source dependencies. What are your patching plans? What you know, help us

**[14:04]** patching plans? What you know, help us

**[14:04]** patching plans? What you know, help us fill this paperwork out if we're buying

**[14:05]** fill this paperwork out if we're buying

**[14:05]** fill this paperwork out if we're buying from you as a software as a service or

**[14:07]** from you as a software as a service or

**[14:07]** from you as a software as a service or platform as a service. That makes that

**[14:09]** platform as a service. That makes that

**[14:10]** platform as a service. That makes that entire partnership that much faster,

**[14:13]** entire partnership that much faster,

**[14:13]** entire partnership that much faster, that much more friendly. And lastly,

**[14:15]** that much more friendly. And lastly,

**[14:15]** that much more friendly. And lastly, keep up the speed.

**[14:17]** keep up the speed.

**[14:17]** keep up the speed. We have also had some awkward

**[14:18]** We have also had some awkward

**[14:18]** We have also had some awkward conversations with some of our service

**[14:20]** conversations with some of our service

**[14:20]** conversations with some of our service providers saying, why is your federal

**[14:22]** providers saying, why is your federal

**[14:22]** providers saying, why is your federal stuff a year out of date? you know, why

**[14:25]** stuff a year out of date? you know, why

**[14:25]** stuff a year out of date? you know, why is that service par not happening a

**[14:28]** is that service par not happening a

**[14:28]** is that service par not happening a year, three years, five years uh from

**[14:30]** year, three years, five years uh from

**[14:30]** year, three years, five years uh from when you launched it in a commercial

**[14:32]** when you launched it in a commercial

**[14:32]** when you launched it in a commercial region? And that's not us just liking

**[14:35]** region? And that's not us just liking

**[14:35]** region? And that's not us just liking ourselves and wanting to have bravado

**[14:37]** ourselves and wanting to have bravado

**[14:37]** ourselves and wanting to have bravado that oh, we're the government, we we're

**[14:38]** that oh, we're the government, we we're

**[14:38]** that oh, we're the government, we we're a quasi federal agency, we we care about

**[14:41]** a quasi federal agency, we we care about

**[14:41]** a quasi federal agency, we we care about our data. No, this is rooted in export

**[14:43]** our data. No, this is rooted in export

**[14:43]** our data. No, this is rooted in export compliance law. This is things like we

**[14:45]** compliance law. This is things like we

**[14:45]** compliance law. This is things like we can't buy from you unless you're in the

**[14:47]** can't buy from you unless you're in the

**[14:47]** can't buy from you unless you're in the right places. Um so it's if you can

**[14:51]** right places. Um so it's if you can

**[14:51]** right places. Um so it's if you can design for speed in your hard corners

**[14:53]** design for speed in your hard corners

**[14:53]** design for speed in your hard corners that optimizes your chances of uh

**[14:57]** that optimizes your chances of uh

**[14:57]** that optimizes your chances of uh fielding your tools and services with us

**[14:59]** fielding your tools and services with us

**[14:59]** fielding your tools and services with us uh in different places that we have to


### [15:00 - 16:00]

**[15:01]** uh in different places that we have to

**[15:01]** uh in different places that we have to operate to meet our mission

**[15:04]** operate to meet our mission

**[15:04]** operate to meet our mission and and with that I lo Alamos we were

**[15:07]** and and with that I lo Alamos we were

**[15:07]** and and with that I lo Alamos we were founded on the idea that the right

**[15:09]** founded on the idea that the right

**[15:09]** founded on the idea that the right application of math and science can

**[15:11]** application of math and science can

**[15:11]** application of math and science can change the world overnight. Um we we've

**[15:13]** change the world overnight. Um we we've

**[15:13]** change the world overnight. Um we we've done that. We're not a stranger to how

**[15:15]** done that. We're not a stranger to how

**[15:15]** done that. We're not a stranger to how that feels to show up and the world is

**[15:17]** that feels to show up and the world is

**[15:17]** that feels to show up and the world is now different. Uh that's what we were

**[15:19]** now different. Uh that's what we were

**[15:19]** now different. Uh that's what we were founded to do. And when we look at AI,

**[15:23]** founded to do. And when we look at AI,

**[15:23]** founded to do. And when we look at AI, uh Aentic tools, what we can do with

**[15:26]** uh Aentic tools, what we can do with

**[15:26]** uh Aentic tools, what we can do with frontier models, any of the above, um we

**[15:29]** frontier models, any of the above, um we

**[15:29]** frontier models, any of the above, um we see it as the greatest opportunity and

**[15:31]** see it as the greatest opportunity and

**[15:31]** see it as the greatest opportunity and the greatest threat to national

**[15:33]** the greatest threat to national

**[15:33]** the greatest threat to national security, but the opportunity is what

**[15:35]** security, but the opportunity is what

**[15:35]** security, but the opportunity is what keeps us showing up. We're not scared of

**[15:37]** keeps us showing up. We're not scared of

**[15:37]** keeps us showing up. We're not scared of the the downside risk. We have to be

**[15:39]** the the downside risk. We have to be

**[15:39]** the the downside risk. We have to be here to help develop the future. Uh, one

**[15:41]** here to help develop the future. Uh, one

**[15:41]** here to help develop the future. Uh, one of my favorite anecdotes, uh, because we

**[15:43]** of my favorite anecdotes, uh, because we

**[15:43]** of my favorite anecdotes, uh, because we are a nuclear science lab, uh, we do a

**[15:46]** are a nuclear science lab, uh, we do a

**[15:46]** are a nuclear science lab, uh, we do a lot of nuclear non-prololiferation work.

**[15:48]** lot of nuclear non-prololiferation work.

**[15:48]** lot of nuclear non-prololiferation work. And because we do that type of work,

**[15:50]** And because we do that type of work,

**[15:50]** And because we do that type of work, we've gotten really good at specialty

**[15:51]** we've gotten really good at specialty

**[15:51]** we've gotten really good at specialty sensors. And what have we been able to

**[15:53]** sensors. And what have we been able to

**[15:53]** sensors. And what have we been able to do with that specialty sensor? We have a

**[15:55]** do with that specialty sensor? We have a

**[15:55]** do with that specialty sensor? We have a laser strapped to a car on Mars zapping

**[15:58]** laser strapped to a car on Mars zapping

**[15:58]** laser strapped to a car on Mars zapping rocks. You know, we built the ChemCam


### [16:00 - 17:00]

**[16:00]** rocks. You know, we built the ChemCam

**[16:00]** rocks. You know, we built the ChemCam sensor. So even if you're a little bit

**[16:03]** sensor. So even if you're a little bit

**[16:03]** sensor. So even if you're a little bit on the fence about should we engage

**[16:05]** on the fence about should we engage

**[16:05]** on the fence about should we engage with, you know, the nuclear enterprise

**[16:06]** with, you know, the nuclear enterprise

**[16:06]** with, you know, the nuclear enterprise of the US, there's other fundamental

**[16:09]** of the US, there's other fundamental

**[16:09]** of the US, there's other fundamental science that we do that's just pushing

**[16:11]** science that we do that's just pushing

**[16:11]** science that we do that's just pushing the boundaries that we as a human

**[16:13]** the boundaries that we as a human

**[16:13]** the boundaries that we as a human species know and can do and can can grow

**[16:17]** species know and can do and can can grow

**[16:17]** species know and can do and can can grow into. So with that, thank you so much

**[16:19]** into. So with that, thank you so much

**[16:19]** into. So with that, thank you so much for your time today. I really appreciate

**[16:21]** for your time today. I really appreciate

**[16:21]** for your time today. I really appreciate it and I'll be available on the side for

**[16:22]** it and I'll be available on the side for

**[16:22]** it and I'll be available on the side for questions. Thank you.


