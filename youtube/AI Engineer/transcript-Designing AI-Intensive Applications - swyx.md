# Designing AI-Intensive Applications - swyx

**Video URL:** https://www.youtube.com/watch?v=IHkyFhU6JEY

---

## Full Transcript

### [00:00 - 01:00]

**[00:19]** Okay. Hi everyone. Welcome to the

**[00:19]** Okay. Hi everyone. Welcome to the conference. How you doing?

**[00:22]** conference. How you doing?

**[00:22]** conference. How you doing? Excellent. Usually I open these

**[00:25]** Excellent. Usually I open these

**[00:25]** Excellent. Usually I open these conferences with a small little talk to

**[00:26]** conferences with a small little talk to

**[00:26]** conferences with a small little talk to introduce uh you know what's going on

**[00:28]** introduce uh you know what's going on

**[00:28]** introduce uh you know what's going on and then give you a little update on

**[00:30]** and then give you a little update on

**[00:30]** and then give you a little update on where the state of AI engineering is and

**[00:32]** where the state of AI engineering is and

**[00:32]** where the state of AI engineering is and how we put together the conference for

**[00:33]** how we put together the conference for

**[00:33]** how we put together the conference for you. Uh this is a this is one of those

**[00:36]** you. Uh this is a this is one of those

**[00:36]** you. Uh this is a this is one of those combined talks. I'm trying to answer

**[00:38]** combined talks. I'm trying to answer

**[00:38]** combined talks. I'm trying to answer every single question you have about the

**[00:39]** every single question you have about the

**[00:39]** every single question you have about the conference about AI news about where

**[00:43]** conference about AI news about where

**[00:43]** conference about AI news about where this is all going and we'll just dive

**[00:46]** this is all going and we'll just dive

**[00:46]** this is all going and we'll just dive right in. Okay. So um 3,000 of you all

**[00:50]** right in. Okay. So um 3,000 of you all

**[00:50]** right in. Okay. So um 3,000 of you all of you registered last minute. Uh thank

**[00:51]** of you registered last minute. Uh thank

**[00:51]** of you registered last minute. Uh thank you for that stress. Um I actually can

**[00:54]** you for that stress. Um I actually can

**[00:54]** you for that stress. Um I actually can quantify this. I call this the genie

**[00:56]** quantify this. I call this the genie

**[00:56]** quantify this. I call this the genie coefficient for uh the AI AIE organizer


### [01:00 - 02:00]

**[01:00]** coefficient for uh the AI AIE organizer

**[01:00]** coefficient for uh the AI AIE organizer stress. Uh this is compared to last

**[01:02]** stress. Uh this is compared to last

**[01:02]** stress. Uh this is compared to last year. Uh it is please just buy tickets

**[01:04]** year. Uh it is please just buy tickets

**[01:04]** year. Uh it is please just buy tickets earlier like I mean you know you're

**[01:06]** earlier like I mean you know you're

**[01:06]** earlier like I mean you know you're going to come just just do it. Okay. Um

**[01:09]** going to come just just do it. Okay. Um

**[01:09]** going to come just just do it. Okay. Um we also uh like to use this conference

**[01:11]** we also uh like to use this conference

**[01:11]** we also uh like to use this conference as a way to track the evolution of AI

**[01:13]** as a way to track the evolution of AI

**[01:13]** as a way to track the evolution of AI engineering. Uh that's those are the

**[01:15]** engineering. Uh that's those are the

**[01:15]** engineering. Uh that's those are the tracks for last year. We've just doubled

**[01:17]** tracks for last year. We've just doubled

**[01:17]** tracks for last year. We've just doubled every single track for you. Um so

**[01:19]** every single track for you. Um so

**[01:19]** every single track for you. Um so basically it's basically you know like

**[01:21]** basically it's basically you know like

**[01:21]** basically it's basically you know like double the value for whatever you uh get

**[01:24]** double the value for whatever you uh get

**[01:24]** double the value for whatever you uh get here and I think like uh I think this is

**[01:27]** here and I think like uh I think this is

**[01:27]** here and I think like uh I think this is as much concurrency as we want to do

**[01:29]** as much concurrency as we want to do

**[01:29]** as much concurrency as we want to do like I know I I hear that people have

**[01:31]** like I know I I hear that people have

**[01:31]** like I know I I hear that people have decision fatigue and all that uh totally

**[01:33]** decision fatigue and all that uh totally

**[01:33]** decision fatigue and all that uh totally but also we try to cover all of AI so

**[01:35]** but also we try to cover all of AI so

**[01:35]** but also we try to cover all of AI so deal with it.

**[01:38]** deal with it.

**[01:38]** deal with it. Um we also pride ourselves in doing well

**[01:41]** Um we also pride ourselves in doing well

**[01:41]** Um we also pride ourselves in doing well by being more responsive than other

**[01:43]** by being more responsive than other

**[01:43]** by being more responsive than other conferences like Europe's and being more

**[01:45]** conferences like Europe's and being more

**[01:45]** conferences like Europe's and being more technical than other conferences uh like

**[01:47]** technical than other conferences uh like

**[01:47]** technical than other conferences uh like TED or whatever what have you. So we

**[01:49]** TED or whatever what have you. So we

**[01:49]** TED or whatever what have you. So we asked you what you wanted to hear about.

**[01:51]** asked you what you wanted to hear about.

**[01:51]** asked you what you wanted to hear about. These are the surveys. Uh we tried all

**[01:53]** These are the surveys. Uh we tried all

**[01:53]** These are the surveys. Uh we tried all sorts of things. We tried computer using

**[01:54]** sorts of things. We tried computer using

**[01:54]** sorts of things. We tried computer using agents. We tried AI and crypto. It's

**[01:58]** agents. We tried AI and crypto. It's

**[01:58]** agents. We tried AI and crypto. It's always a fun one. And uh but you guys


### [02:00 - 03:00]

**[02:00]** always a fun one. And uh but you guys

**[02:00]** always a fun one. And uh but you guys told told us what you wanted and we put

**[02:02]** told told us what you wanted and we put

**[02:02]** told told us what you wanted and we put it in there. Um for all for more data um

**[02:05]** it in there. Um for all for more data um

**[02:05]** it in there. Um for all for more data um we would actually like you to to finish

**[02:06]** we would actually like you to to finish

**[02:06]** we would actually like you to to finish out our survey where survey is not done.

**[02:08]** out our survey where survey is not done.

**[02:08]** out our survey where survey is not done. So if you want to head to that URL um we

**[02:10]** So if you want to head to that URL um we

**[02:10]** So if you want to head to that URL um we will present the results in full

**[02:12]** will present the results in full

**[02:12]** will present the results in full tomorrow. We would love all of you to to

**[02:14]** tomorrow. We would love all of you to to

**[02:14]** tomorrow. We would love all of you to to fill it out so we can get a

**[02:15]** fill it out so we can get a

**[02:15]** fill it out so we can get a representative sample of what you want

**[02:16]** representative sample of what you want

**[02:16]** representative sample of what you want and uh that will inform us next year.

**[02:20]** and uh that will inform us next year.

**[02:20]** and uh that will inform us next year. Okay. Um you know I think the other

**[02:22]** Okay. Um you know I think the other

**[02:22]** Okay. Um you know I think the other thing about AI engineering is that we

**[02:24]** thing about AI engineering is that we

**[02:24]** thing about AI engineering is that we also have been innovating as engineers

**[02:26]** also have been innovating as engineers

**[02:26]** also have been innovating as engineers right we we're the first conference to

**[02:27]** right we we're the first conference to

**[02:27]** right we we're the first conference to have an MCP. at our first conference to

**[02:29]** have an MCP. at our first conference to

**[02:29]** have an MCP. at our first conference to have an MCP talk accepted by MCP

**[02:33]** have an MCP talk accepted by MCP

**[02:34]** have an MCP talk accepted by MCP where shout out to Sam Julian from

**[02:36]** where shout out to Sam Julian from

**[02:36]** where shout out to Sam Julian from Writer for working with us on the

**[02:38]** Writer for working with us on the

**[02:38]** Writer for working with us on the official chatbot and Quinn and John from

**[02:41]** official chatbot and Quinn and John from

**[02:41]** official chatbot and Quinn and John from Daily for working with us on the

**[02:42]** Daily for working with us on the

**[02:42]** Daily for working with us on the official voice bot as well as Elizabeth

**[02:44]** official voice bot as well as Elizabeth

**[02:44]** official voice bot as well as Elizabeth Triken from uh Vappy. I need to give her

**[02:46]** Triken from uh Vappy. I need to give her

**[02:46]** Triken from uh Vappy. I need to give her a shout out because she originally uh

**[02:48]** a shout out because she originally uh

**[02:48]** a shout out because she originally uh helped us uh prototype uh the the voice

**[02:50]** helped us uh prototype uh the the voice

**[02:50]** helped us uh prototype uh the the voice bot as well. So we're trying to

**[02:52]** bot as well. So we're trying to

**[02:52]** bot as well. So we're trying to constantly improve the experience.

**[02:54]** constantly improve the experience.

**[02:54]** constantly improve the experience. Uh the other thing I think I want to

**[02:56]** Uh the other thing I think I want to

**[02:56]** Uh the other thing I think I want to emphasize as well is like these are the

**[02:58]** emphasize as well is like these are the

**[02:58]** emphasize as well is like these are the talks that I give like in 2023


### [03:00 - 04:00]

**[03:01]** talks that I give like in 2023

**[03:01]** talks that I give like in 2023 uh the very first AIE I talked about the

**[03:04]** uh the very first AIE I talked about the

**[03:04]** uh the very first AIE I talked about the uh the three types of AI engineer in

**[03:06]** uh the three types of AI engineer in

**[03:06]** uh the three types of AI engineer in 2024 I talked about um how AI

**[03:09]** 2024 I talked about um how AI

**[03:09]** 2024 I talked about um how AI engineering was becoming more multi

**[03:11]** engineering was becoming more multi

**[03:11]** engineering was becoming more multi disciplinary and that's why we started

**[03:12]** disciplinary and that's why we started

**[03:12]** disciplinary and that's why we started the world's fair with with multiple

**[03:14]** the world's fair with with multiple

**[03:14]** the world's fair with with multiple tracks in 2025 in in New York we talked

**[03:17]** tracks in 2025 in in New York we talked

**[03:17]** tracks in 2025 in in New York we talked about the evolution and the focus on

**[03:19]** about the evolution and the focus on

**[03:19]** about the evolution and the focus on agent engineering so where where are we

**[03:21]** agent engineering so where where are we

**[03:21]** agent engineering so where where are we now in sort of June of 2025 Um, that's

**[03:24]** now in sort of June of 2025 Um, that's

**[03:24]** now in sort of June of 2025 Um, that's where we're going to focus on. I think

**[03:25]** where we're going to focus on. I think

**[03:25]** where we're going to focus on. I think we we come a long way regardless like,

**[03:27]** we we come a long way regardless like,

**[03:27]** we we come a long way regardless like, you know, we people used to make fun of

**[03:29]** you know, we people used to make fun of

**[03:29]** you know, we people used to make fun of AI engineering and and I anticipated

**[03:30]** AI engineering and and I anticipated

**[03:30]** AI engineering and and I anticipated this. We used to be low status. People

**[03:33]** this. We used to be low status. People

**[03:33]** this. We used to be low status. People just derive GPT rappers and look at all

**[03:35]** just derive GPT rappers and look at all

**[03:35]** just derive GPT rappers and look at all the GPT rappers. Now all of you are

**[03:37]** the GPT rappers. Now all of you are

**[03:37]** the GPT rappers. Now all of you are rich. Um, so we're going to hear from

**[03:40]** rich. Um, so we're going to hear from

**[03:40]** rich. Um, so we're going to hear from some of these folks uh in the room. Um,

**[03:42]** some of these folks uh in the room. Um,

**[03:42]** some of these folks uh in the room. Um, and uh, thank you for sponsoring as

**[03:44]** and uh, thank you for sponsoring as

**[03:44]** and uh, thank you for sponsoring as well.

**[03:46]** well.

**[03:46]** well. Um but uh you know I think the other

**[03:48]** Um but uh you know I think the other

**[03:48]** Um but uh you know I think the other thing that's also super interesting is

**[03:49]** thing that's also super interesting is

**[03:50]** thing that's also super interesting is that like you should we the consistent

**[03:52]** that like you should we the consistent

**[03:52]** that like you should we the consistent lesson that we hear is to not over

**[03:53]** lesson that we hear is to not over

**[03:53]** lesson that we hear is to not over complicate things from enthropic on the

**[03:55]** complicate things from enthropic on the

**[03:55]** complicate things from enthropic on the lat space podcast. Uh we hear we hear we

**[03:58]** lat space podcast. Uh we hear we hear we

**[03:58]** lat space podcast. Uh we hear we hear we hear from uh Eric Suns about how they


### [04:00 - 05:00]

**[04:00]** hear from uh Eric Suns about how they

**[04:00]** hear from uh Eric Suns about how they beat Sweetbench with just a very simple

**[04:02]** beat Sweetbench with just a very simple

**[04:02]** beat Sweetbench with just a very simple scaffold. Uh same about deep research

**[04:04]** scaffold. Uh same about deep research

**[04:04]** scaffold. Uh same about deep research from Greg Brockman who you're going to

**[04:06]** from Greg Brockman who you're going to

**[04:06]** from Greg Brockman who you're going to hear later on um in the uh sort of

**[04:08]** hear later on um in the uh sort of

**[04:08]** hear later on um in the uh sort of closing keynotes as well as AMP code.

**[04:10]** closing keynotes as well as AMP code.

**[04:10]** closing keynotes as well as AMP code. Where's the AMP folks here? AMP amp amp

**[04:13]** Where's the AMP folks here? AMP amp amp

**[04:13]** Where's the AMP folks here? AMP amp amp I think they're probably back in the

**[04:14]** I think they're probably back in the

**[04:14]** I think they're probably back in the other room but um also you know there's

**[04:16]** other room but um also you know there's

**[04:16]** other room but um also you know there's there's a sort of emperor has no clothes

**[04:18]** there's a sort of emperor has no clothes

**[04:18]** there's a sort of emperor has no clothes like there's it's still very early fuel

**[04:19]** like there's it's still very early fuel

**[04:19]** like there's it's still very early fuel and I think the um AI engineers in the

**[04:21]** and I think the um AI engineers in the

**[04:21]** and I think the um AI engineers in the room like should be very encouraged by

**[04:23]** room like should be very encouraged by

**[04:23]** room like should be very encouraged by that like there's there's still a lot of

**[04:24]** that like there's there's still a lot of

**[04:24]** that like there's there's still a lot of alpha to mind

**[04:27]** alpha to mind

**[04:27]** alpha to mind um if you watch back all the way to the

**[04:29]** um if you watch back all the way to the

**[04:29]** um if you watch back all the way to the start of this conference we actually

**[04:31]** start of this conference we actually

**[04:31]** start of this conference we actually compared this moment a lot to uh the

**[04:33]** compared this moment a lot to uh the

**[04:33]** compared this moment a lot to uh the time when sort of physics was in was in

**[04:35]** time when sort of physics was in was in

**[04:35]** time when sort of physics was in was in full bloom right this is the solve

**[04:36]** full bloom right this is the solve

**[04:36]** full bloom right this is the solve conference in 1927 when Einstein Mary

**[04:38]** conference in 1927 when Einstein Mary

**[04:38]** conference in 1927 when Einstein Mary Cury and all the other household names

**[04:40]** Cury and all the other household names

**[04:40]** Cury and all the other household names in physics all gathered together And

**[04:41]** in physics all gathered together And

**[04:41]** in physics all gathered together And that's what we're trying to do for this

**[04:43]** that's what we're trying to do for this

**[04:43]** that's what we're trying to do for this conference. We've gathered the entire

**[04:45]** conference. We've gathered the entire

**[04:45]** conference. We've gathered the entire the best um sort of AI engineers in the

**[04:47]** the best um sort of AI engineers in the

**[04:47]** the best um sort of AI engineers in the in the world um and and researchers and

**[04:49]** in the world um and and researchers and

**[04:49]** in the world um and and researchers and and and all that uh to to build and push

**[04:52]** and and all that uh to to build and push

**[04:52]** and and all that uh to to build and push the frontier forward. Um the thesis is

**[04:55]** the frontier forward. Um the thesis is

**[04:55]** the frontier forward. Um the thesis is that there's this is the time this is

**[04:56]** that there's this is the time this is

**[04:56]** that there's this is the time this is the right time to do it. I said that two

**[04:59]** the right time to do it. I said that two

**[04:59]** the right time to do it. I said that two and a half years ago still true still


### [05:00 - 06:00]

**[05:00]** and a half years ago still true still

**[05:00]** and a half years ago still true still true today. But I think like there's a

**[05:02]** true today. But I think like there's a

**[05:02]** true today. But I think like there's a very specific time when like basically

**[05:05]** very specific time when like basically

**[05:05]** very specific time when like basically what people did in in that time of the

**[05:07]** what people did in in that time of the

**[05:07]** what people did in in that time of the formation of an industry is that they

**[05:08]** formation of an industry is that they

**[05:08]** formation of an industry is that they set out all the basic ideas that then

**[05:10]** set out all the basic ideas that then

**[05:10]** set out all the basic ideas that then lasted for the rest of that industry. So

**[05:12]** lasted for the rest of that industry. So

**[05:12]** lasted for the rest of that industry. So this is the standard model in physics

**[05:14]** this is the standard model in physics

**[05:14]** this is the standard model in physics and there was a very specific period in

**[05:16]** and there was a very specific period in

**[05:16]** and there was a very specific period in time from like the 40s to the 70s where

**[05:18]** time from like the 40s to the 70s where

**[05:18]** time from like the 40s to the 70s where they figured it all out and the the next

**[05:20]** they figured it all out and the the next

**[05:20]** they figured it all out and the the next 50 years we haven't really changed the

**[05:21]** 50 years we haven't really changed the

**[05:21]** 50 years we haven't really changed the standard model. So the question that I

**[05:23]** standard model. So the question that I

**[05:23]** standard model. So the question that I want to phrase here is what is the

**[05:25]** want to phrase here is what is the

**[05:25]** want to phrase here is what is the standard model in AI engineering right

**[05:27]** standard model in AI engineering right

**[05:27]** standard model in AI engineering right we have standard models in the rest of

**[05:29]** we have standard models in the rest of

**[05:29]** we have standard models in the rest of engineering right everyone knows ETL

**[05:31]** engineering right everyone knows ETL

**[05:32]** engineering right everyone knows ETL everyone knows MVC everyone knows CRUD

**[05:34]** everyone knows MVC everyone knows CRUD

**[05:34]** everyone knows MVC everyone knows CRUD everyone knows map reduce and I've used

**[05:37]** everyone knows map reduce and I've used

**[05:37]** everyone knows map reduce and I've used those things in like building AI

**[05:38]** those things in like building AI

**[05:38]** those things in like building AI applications and like it's pretty much

**[05:41]** applications and like it's pretty much

**[05:41]** applications and like it's pretty much like yes rag is there but I heard rag is

**[05:43]** like yes rag is there but I heard rag is

**[05:43]** like yes rag is there but I heard rag is dead I I don't know you guys can tell me

**[05:45]** dead I I don't know you guys can tell me

**[05:45]** dead I I don't know you guys can tell me um this day is like long long context

**[05:47]** um this day is like long long context

**[05:47]** um this day is like long long context killed rag the other day fine tuning

**[05:49]** killed rag the other day fine tuning

**[05:49]** killed rag the other day fine tuning kills rag I don't know but I I don't

**[05:51]** kills rag I don't know but I I don't

**[05:51]** kills rag I don't know but I I don't think I definitely don't think is the

**[05:52]** think I definitely don't think is the

**[05:52]** think I definitely don't think is the full answer. So what other standard

**[05:54]** full answer. So what other standard

**[05:54]** full answer. So what other standard models might emerge to help us guide our

**[05:57]** models might emerge to help us guide our

**[05:57]** models might emerge to help us guide our thinking and that's really what I want

**[05:58]** thinking and that's really what I want

**[05:58]** thinking and that's really what I want to push you guys to. So uh there are a


### [06:00 - 07:00]

**[06:00]** to push you guys to. So uh there are a

**[06:00]** to push you guys to. So uh there are a few candidates standard models and AI

**[06:02]** few candidates standard models and AI

**[06:02]** few candidates standard models and AI engineering. I'll pick out a few of

**[06:03]** engineering. I'll pick out a few of

**[06:03]** engineering. I'll pick out a few of these. I I don't have time to talk about

**[06:04]** these. I I don't have time to talk about

**[06:04]** these. I I don't have time to talk about all of them but definitely listen to the

**[06:06]** all of them but definitely listen to the

**[06:06]** all of them but definitely listen to the DSP talk from Omar later uh tomorrow.

**[06:10]** DSP talk from Omar later uh tomorrow.

**[06:10]** DSP talk from Omar later uh tomorrow. Um so we're going to cover uh a few of

**[06:12]** Um so we're going to cover uh a few of

**[06:12]** Um so we're going to cover uh a few of these. So first is the LM OS. Uh this is

**[06:15]** these. So first is the LM OS. Uh this is

**[06:15]** these. So first is the LM OS. Uh this is one of the earliest standard standard

**[06:16]** one of the earliest standard standard

**[06:16]** one of the earliest standard standard models um basically uh from Karpavi in

**[06:19]** models um basically uh from Karpavi in

**[06:19]** models um basically uh from Karpavi in 2023. Um I have updated it for 2025 um

**[06:22]** 2023. Um I have updated it for 2025 um

**[06:22]** 2023. Um I have updated it for 2025 um for multimodality for the standard set

**[06:25]** for multimodality for the standard set

**[06:25]** for multimodality for the standard set of tools that have come out um as well

**[06:27]** of tools that have come out um as well

**[06:27]** of tools that have come out um as well as um MCP which uh is is has become the

**[06:31]** as um MCP which uh is is has become the

**[06:31]** as um MCP which uh is is has become the default protocol for connecting with the

**[06:33]** default protocol for connecting with the

**[06:33]** default protocol for connecting with the outside world. Um second one would be

**[06:35]** outside world. Um second one would be

**[06:35]** outside world. Um second one would be the LN SDLC software development life

**[06:38]** the LN SDLC software development life

**[06:38]** the LN SDLC software development life cycle. Um I have two versions of this

**[06:40]** cycle. Um I have two versions of this

**[06:40]** cycle. Um I have two versions of this one with the intersecting concerns of

**[06:42]** one with the intersecting concerns of

**[06:42]** one with the intersecting concerns of all the tooling that you buy. Uh by the

**[06:44]** all the tooling that you buy. Uh by the

**[06:44]** all the tooling that you buy. Uh by the way this is all on the laten space blog

**[06:45]** way this is all on the laten space blog

**[06:45]** way this is all on the laten space blog if you want and I'll tweet out the

**[06:47]** if you want and I'll tweet out the

**[06:47]** if you want and I'll tweet out the slides so uh and it's live stream so

**[06:50]** slides so uh and it's live stream so

**[06:50]** slides so uh and it's live stream so whatever um but I think uh for me the

**[06:53]** whatever um but I think uh for me the

**[06:53]** whatever um but I think uh for me the most interesting insight and the aha

**[06:54]** most interesting insight and the aha

**[06:54]** most interesting insight and the aha moment when I was talking to anker of

**[06:57]** moment when I was talking to anker of

**[06:57]** moment when I was talking to anker of brain trust who's going to be keynoting

**[06:58]** brain trust who's going to be keynoting

**[06:58]** brain trust who's going to be keynoting tomorrow um is that you know the early


### [07:00 - 08:00]

**[07:02]** tomorrow um is that you know the early

**[07:02]** tomorrow um is that you know the early parts of the SDLC is are increasingly

**[07:04]** parts of the SDLC is are increasingly

**[07:04]** parts of the SDLC is are increasingly commodity right LLM's kind of free you

**[07:07]** commodity right LLM's kind of free you

**[07:07]** commodity right LLM's kind of free you know um monitoring kind of free and rag

**[07:10]** know um monitoring kind of free and rag

**[07:10]** know um monitoring kind of free and rag kind of free obviously there's it's just

**[07:12]** kind of free obviously there's it's just

**[07:12]** kind of free obviously there's it's just free tier for all of them and you you

**[07:13]** free tier for all of them and you you

**[07:14]** free tier for all of them and you you only get start paying but like when you

**[07:15]** only get start paying but like when you

**[07:15]** only get start paying but like when you start to make real money from your

**[07:17]** start to make real money from your

**[07:17]** start to make real money from your customers is when you start to do evals

**[07:19]** customers is when you start to do evals

**[07:19]** customers is when you start to do evals and you start to add in security

**[07:20]** and you start to add in security

**[07:20]** and you start to add in security orchestration and do real work uh that

**[07:22]** orchestration and do real work uh that

**[07:22]** orchestration and do real work uh that is real hard engineering work um and I

**[07:24]** is real hard engineering work um and I

**[07:24]** is real hard engineering work um and I think that's those are the tracks that

**[07:25]** think that's those are the tracks that

**[07:25]** think that's those are the tracks that we've added this year um and I'm very

**[07:28]** we've added this year um and I'm very

**[07:28]** we've added this year um and I'm very proud to you know I guess push AI

**[07:30]** proud to you know I guess push AI

**[07:30]** proud to you know I guess push AI engineering along from demos into

**[07:31]** engineering along from demos into

**[07:31]** engineering along from demos into production which is what everyone always

**[07:33]** production which is what everyone always

**[07:33]** production which is what everyone always wants another form of standard model is

**[07:36]** wants another form of standard model is

**[07:36]** wants another form of standard model is building effective agents uh our last

**[07:37]** building effective agents uh our last

**[07:37]** building effective agents uh our last conference we had uh Barry one of the

**[07:40]** conference we had uh Barry one of the

**[07:40]** conference we had uh Barry one of the co-authors of building effective agents

**[07:41]** co-authors of building effective agents

**[07:41]** co-authors of building effective agents from enthopic give an extremely really

**[07:43]** from enthopic give an extremely really

**[07:43]** from enthopic give an extremely really popular talk about this. Um I think that

**[07:45]** popular talk about this. Um I think that

**[07:45]** popular talk about this. Um I think that this is now at least the the received

**[07:47]** this is now at least the the received

**[07:47]** this is now at least the the received wisdom for how to build an agent. And I

**[07:50]** wisdom for how to build an agent. And I

**[07:50]** wisdom for how to build an agent. And I think like that's like that is one

**[07:52]** think like that's like that is one

**[07:52]** think like that's like that is one definition. Open AI has a different

**[07:53]** definition. Open AI has a different

**[07:53]** definition. Open AI has a different definition and I think we're we're

**[07:56]** definition and I think we're we're

**[07:56]** definition and I think we're we're contining to iterate. I think Dominic

**[07:57]** contining to iterate. I think Dominic

**[07:57]** contining to iterate. I think Dominic yesterday uh released another

**[07:59]** yesterday uh released another

**[07:59]** yesterday uh released another improvement on the agents SDK which


### [08:00 - 09:00]

**[08:01]** improvement on the agents SDK which

**[08:01]** improvement on the agents SDK which builds upon the swarm concept that

**[08:02]** builds upon the swarm concept that

**[08:02]** builds upon the swarm concept that OpenAI is pushing.

**[08:04]** OpenAI is pushing.

**[08:04]** OpenAI is pushing. Um um the way that I approach sort of

**[08:07]** Um um the way that I approach sort of

**[08:07]** Um um the way that I approach sort of the agent standard model has been very

**[08:09]** the agent standard model has been very

**[08:09]** the agent standard model has been very different. So you can refer to my talk

**[08:11]** different. So you can refer to my talk

**[08:11]** different. So you can refer to my talk from the previous conference on that. Um

**[08:13]** from the previous conference on that. Um

**[08:13]** from the previous conference on that. Um basically trying to do a descriptive u

**[08:16]** basically trying to do a descriptive u

**[08:16]** basically trying to do a descriptive u top down u model of what people use the

**[08:21]** top down u model of what people use the

**[08:21]** top down u model of what people use the words people use to describe agents like

**[08:22]** words people use to describe agents like

**[08:22]** words people use to describe agents like intent um you know control flow um

**[08:26]** intent um you know control flow um

**[08:26]** intent um you know control flow um memory planning and tool use. So there's

**[08:29]** memory planning and tool use. So there's

**[08:29]** memory planning and tool use. So there's all these there's all these like really

**[08:30]** all these there's all these like really

**[08:30]** all these there's all these like really really interesting things. But I think

**[08:31]** really interesting things. But I think

**[08:31]** really interesting things. But I think that the thing that really got me um is

**[08:34]** that the thing that really got me um is

**[08:34]** that the thing that really got me um is like I don't actually use all of that to

**[08:35]** like I don't actually use all of that to

**[08:36]** like I don't actually use all of that to build AI news. Um by the way who here

**[08:37]** build AI news. Um by the way who here

**[08:37]** build AI news. Um by the way who here reads AI news? I don't know if there's

**[08:38]** reads AI news? I don't know if there's

**[08:38]** reads AI news? I don't know if there's like a Yeah. Oh my god, like that's half

**[08:40]** like a Yeah. Oh my god, like that's half

**[08:40]** like a Yeah. Oh my god, like that's half of you. Thanks. Uh uh it's it's a really

**[08:43]** of you. Thanks. Uh uh it's it's a really

**[08:43]** of you. Thanks. Uh uh it's it's a really good tool I built for myself and you

**[08:45]** good tool I built for myself and you

**[08:45]** good tool I built for myself and you know hopefully uh now over 70,000 people

**[08:47]** know hopefully uh now over 70,000 people

**[08:47]** know hopefully uh now over 70,000 people are reading along as well. Um and the

**[08:49]** are reading along as well. Um and the

**[08:49]** are reading along as well. Um and the thing that really got me was Sum

**[08:52]** thing that really got me was Sum

**[08:52]** thing that really got me was Sum at the last conference. Uh you know he's

**[08:54]** at the last conference. Uh you know he's

**[08:54]** at the last conference. Uh you know he's the lead of PyTorch and he says he reads

**[08:55]** the lead of PyTorch and he says he reads

**[08:56]** the lead of PyTorch and he says he reads AI news he loves it but it is not an

**[08:57]** AI news he loves it but it is not an

**[08:57]** AI news he loves it but it is not an agent. And I was like what do you mean

**[08:58]** agent. And I was like what do you mean

**[08:58]** agent. And I was like what do you mean it's not an agent? I call it an agent.


### [09:00 - 10:00]

**[09:00]** it's not an agent? I call it an agent.

**[09:00]** it's not an agent? I call it an agent. You should call it an agent. Um but he's

**[09:02]** You should call it an agent. Um but he's

**[09:02]** You should call it an agent. Um but he's right. Um, it's actually uh it's

**[09:05]** right. Um, it's actually uh it's

**[09:05]** right. Um, it's actually uh it's actually I'm going to talk a little bit

**[09:07]** actually I'm going to talk a little bit

**[09:07]** actually I'm going to talk a little bit about that, but like like why does it

**[09:08]** about that, but like like why does it

**[09:08]** about that, but like like why does it still deliver value even though it's

**[09:10]** still deliver value even though it's

**[09:10]** still deliver value even though it's like a workflow and like you know is

**[09:12]** like a workflow and like you know is

**[09:12]** like a workflow and like you know is that still interesting to people, right?

**[09:13]** that still interesting to people, right?

**[09:13]** that still interesting to people, right? Like why do we not brand every single

**[09:16]** Like why do we not brand every single

**[09:16]** Like why do we not brand every single track here? Voice agents uh you know

**[09:18]** track here? Voice agents uh you know

**[09:18]** track here? Voice agents uh you know like uh like workflow agents, computer

**[09:21]** like uh like workflow agents, computer

**[09:21]** like uh like workflow agents, computer use agents like why is every single

**[09:23]** use agents like why is every single

**[09:23]** use agents like why is every single track in this conference not an agent?

**[09:25]** track in this conference not an agent?

**[09:25]** track in this conference not an agent? Well, I think basically we want to

**[09:27]** Well, I think basically we want to

**[09:28]** Well, I think basically we want to deliver value instead of arguable

**[09:29]** deliver value instead of arguable

**[09:29]** deliver value instead of arguable terminology. So the assertion that I

**[09:31]** terminology. So the assertion that I

**[09:31]** terminology. So the assertion that I have is that it's really about human

**[09:34]** have is that it's really about human

**[09:34]** have is that it's really about human input versus valuable um AI output and

**[09:37]** input versus valuable um AI output and

**[09:37]** input versus valuable um AI output and you can sort of make a mental model of

**[09:39]** you can sort of make a mental model of

**[09:39]** you can sort of make a mental model of this and track the ratio of this and

**[09:40]** this and track the ratio of this and

**[09:40]** this and track the ratio of this and that's more interesting than arguing

**[09:42]** that's more interesting than arguing

**[09:42]** that's more interesting than arguing about definitions of workflow versus

**[09:44]** about definitions of workflow versus

**[09:44]** about definitions of workflow versus agents. So for example in the copilot

**[09:46]** agents. So for example in the copilot

**[09:46]** agents. So for example in the copilot era you had sort of like a debounce

**[09:49]** era you had sort of like a debounce

**[09:49]** era you had sort of like a debounce input of like every few characters that

**[09:50]** input of like every few characters that

**[09:50]** input of like every few characters that you type then maybe it will do an

**[09:51]** you type then maybe it will do an

**[09:51]** you type then maybe it will do an autocomplete u in chatbt every few

**[09:54]** autocomplete u in chatbt every few

**[09:54]** autocomplete u in chatbt every few queries that you type it would maybe

**[09:55]** queries that you type it would maybe

**[09:55]** queries that you type it would maybe output a responding query. Um it starts

**[09:58]** output a responding query. Um it starts

**[09:58]** output a responding query. Um it starts to get more interesting with the

**[09:59]** to get more interesting with the

**[09:59]** to get more interesting with the reasoning models with like a 1 to10


### [10:00 - 11:00]

**[10:01]** reasoning models with like a 1 to10

**[10:01]** reasoning models with like a 1 to10 ratio and then obviously with like the

**[10:03]** ratio and then obviously with like the

**[10:03]** ratio and then obviously with like the new agents now it's like more sort of

**[10:05]** new agents now it's like more sort of

**[10:05]** new agents now it's like more sort of deep research notebook. Uh by the way

**[10:06]** deep research notebook. Uh by the way

**[10:06]** deep research notebook. Uh by the way Ryzen Martin also speaking on the

**[10:08]** Ryzen Martin also speaking on the

**[10:08]** Ryzen Martin also speaking on the product uh product management track. Um

**[10:10]** product uh product management track. Um

**[10:10]** product uh product management track. Um she's she's incredible on uh talking

**[10:12]** she's she's incredible on uh talking

**[10:12]** she's she's incredible on uh talking about the story of notebook LM. Um the

**[10:15]** about the story of notebook LM. Um the

**[10:15]** about the story of notebook LM. Um the other really interesting angle if you

**[10:17]** other really interesting angle if you

**[10:17]** other really interesting angle if you want to take this mental model to the

**[10:19]** want to take this mental model to the

**[10:19]** want to take this mental model to the stretch to stretch it is the zero to one

**[10:21]** stretch to stretch it is the zero to one

**[10:21]** stretch to stretch it is the zero to one the ambient agents with no human input.

**[10:23]** the ambient agents with no human input.

**[10:23]** the ambient agents with no human input. What kind of interesting uh AI output

**[10:25]** What kind of interesting uh AI output

**[10:25]** What kind of interesting uh AI output can you get? So to me that's that's more

**[10:27]** can you get? So to me that's that's more

**[10:28]** can you get? So to me that's that's more a useful discussion about input versus

**[10:29]** a useful discussion about input versus

**[10:29]** a useful discussion about input versus output than what is a workflow wise and

**[10:31]** output than what is a workflow wise and

**[10:31]** output than what is a workflow wise and an agent how agentic is your thing

**[10:32]** an agent how agentic is your thing

**[10:32]** an agent how agentic is your thing versus versus not.

**[10:35]** versus versus not.

**[10:35]** versus versus not. Um talking about AI news uh so you know

**[10:37]** Um talking about AI news uh so you know

**[10:37]** Um talking about AI news uh so you know it is it is like a bunch of scripts in a

**[10:40]** it is it is like a bunch of scripts in a

**[10:40]** it is it is like a bunch of scripts in a in a in a trench code. Um and I realized

**[10:42]** in a in a trench code. Um and I realized

**[10:42]** in a in a trench code. Um and I realized I've written it three times. I've

**[10:43]** I've written it three times. I've

**[10:43]** I've written it three times. I've written it for the Discord scrape. I've

**[10:45]** written it for the Discord scrape. I've

**[10:45]** written it for the Discord scrape. I've written it for the Reddit scrape. I've

**[10:46]** written it for the Reddit scrape. I've

**[10:46]** written it for the Reddit scrape. I've written it for the Twitter scrape. And

**[10:48]** written it for the Twitter scrape. And

**[10:48]** written it for the Twitter scrape. And basically it's just it's always the same

**[10:49]** basically it's just it's always the same

**[10:49]** basically it's just it's always the same process. You scrape it. You plan. You

**[10:51]** process. You scrape it. You plan. You

**[10:51]** process. You scrape it. You plan. You recursively summarize. You format and

**[10:53]** recursively summarize. You format and

**[10:53]** recursively summarize. You format and you evaluate. Um and and yeah, that's

**[10:56]** you evaluate. Um and and yeah, that's

**[10:56]** you evaluate. Um and and yeah, that's the three kids in the trench coat. Um

**[10:58]** the three kids in the trench coat. Um

**[10:58]** the three kids in the trench coat. Um and that's really how what it is. I run


### [11:00 - 12:00]

**[11:00]** and that's really how what it is. I run

**[11:00]** and that's really how what it is. I run it every day and like we improve it a

**[11:01]** it every day and like we improve it a

**[11:01]** it every day and like we improve it a little bit, but then I'm also running

**[11:03]** little bit, but then I'm also running

**[11:03]** little bit, but then I'm also running this conference. Um so if you generalize

**[11:05]** this conference. Um so if you generalize

**[11:05]** this conference. Um so if you generalize it, that actually starts to become an

**[11:07]** it, that actually starts to become an

**[11:07]** it, that actually starts to become an interesting model for building AI

**[11:09]** interesting model for building AI

**[11:10]** interesting model for building AI intensive applications where you start

**[11:11]** intensive applications where you start

**[11:11]** intensive applications where you start to make thousands of AI calls to serve

**[11:15]** to make thousands of AI calls to serve

**[11:15]** to make thousands of AI calls to serve serve a particular purpose. Um so you

**[11:17]** serve a particular purpose. Um so you

**[11:17]** serve a particular purpose. Um so you sync you plan and and you sort of

**[11:19]** sync you plan and and you sort of

**[11:19]** sync you plan and and you sort of parallel process you analyze and sort of

**[11:21]** parallel process you analyze and sort of

**[11:21]** parallel process you analyze and sort of reduce that down to uh from from many to

**[11:24]** reduce that down to uh from from many to

**[11:24]** reduce that down to uh from from many to one and then you uh deliver uh deliver

**[11:27]** one and then you uh deliver uh deliver

**[11:27]** one and then you uh deliver uh deliver the contents um to the to the user and

**[11:29]** the contents um to the to the user and

**[11:29]** the contents um to the to the user and then you evaluate and to me like that

**[11:31]** then you evaluate and to me like that

**[11:31]** then you evaluate and to me like that conveniently forms an acronym SP AD um

**[11:34]** conveniently forms an acronym SP AD um

**[11:34]** conveniently forms an acronym SP AD um which is which is really nice. There's

**[11:36]** which is which is really nice. There's

**[11:36]** which is which is really nice. There's also sort of interesting AI engineering

**[11:38]** also sort of interesting AI engineering

**[11:38]** also sort of interesting AI engineering elements that are that are fit in there.

**[11:40]** elements that are that are fit in there.

**[11:40]** elements that are that are fit in there. So you can process all these into a

**[11:41]** So you can process all these into a

**[11:41]** So you can process all these into a knowledge graph. you can um turn these

**[11:44]** knowledge graph. you can um turn these

**[11:44]** knowledge graph. you can um turn these into like structured outputs and you can

**[11:46]** into like structured outputs and you can

**[11:46]** into like structured outputs and you can generate code as well. So for example um

**[11:48]** generate code as well. So for example um

**[11:48]** generate code as well. So for example um you know chat GBT with canvas or cloud

**[11:51]** you know chat GBT with canvas or cloud

**[11:51]** you know chat GBT with canvas or cloud with um artifacts is a way of just

**[11:54]** with um artifacts is a way of just

**[11:54]** with um artifacts is a way of just delivering the output as a code artifact

**[11:56]** delivering the output as a code artifact

**[11:56]** delivering the output as a code artifact instead of just uh text output and I

**[11:58]** instead of just uh text output and I

**[11:58]** instead of just uh text output and I think it's like a really interesting way

**[11:59]** think it's like a really interesting way

**[11:59]** think it's like a really interesting way to think about this. So this is my


### [12:00 - 13:00]

**[12:01]** to think about this. So this is my

**[12:01]** to think about this. So this is my mental model so far. Um I I wish I had

**[12:03]** mental model so far. Um I I wish I had

**[12:03]** mental model so far. Um I I wish I had the space to go into it but ask me

**[12:05]** the space to go into it but ask me

**[12:05]** the space to go into it but ask me later. This is what I'm developing right

**[12:06]** later. This is what I'm developing right

**[12:06]** later. This is what I'm developing right now. I think what I what I would really

**[12:08]** now. I think what I what I would really

**[12:08]** now. I think what I what I would really emphasize is, you know, I think like

**[12:10]** emphasize is, you know, I think like

**[12:10]** emphasize is, you know, I think like there's all sorts of interesting ways to

**[12:12]** there's all sorts of interesting ways to

**[12:12]** there's all sorts of interesting ways to think about what the standard model is

**[12:14]** think about what the standard model is

**[12:14]** think about what the standard model is and whether it's useful for you in in

**[12:16]** and whether it's useful for you in in

**[12:16]** and whether it's useful for you in in taking your application to the next step

**[12:18]** taking your application to the next step

**[12:18]** taking your application to the next step of like how do I add more intelligence

**[12:20]** of like how do I add more intelligence

**[12:20]** of like how do I add more intelligence to this in in a way that's useful and

**[12:21]** to this in in a way that's useful and

**[12:21]** to this in in a way that's useful and not annoying. Uh, and for me, this is

**[12:23]** not annoying. Uh, and for me, this is

**[12:23]** not annoying. Uh, and for me, this is it. Okay. So, I've I've thrown a bunch

**[12:26]** it. Okay. So, I've I've thrown a bunch

**[12:26]** it. Okay. So, I've I've thrown a bunch of standard models in here, but that's

**[12:28]** of standard models in here, but that's

**[12:28]** of standard models in here, but that's just my current hypothesis. I want you

**[12:30]** just my current hypothesis. I want you

**[12:30]** just my current hypothesis. I want you at this conference when in all your

**[12:31]** at this conference when in all your

**[12:31]** at this conference when in all your conversations with each other and with

**[12:33]** conversations with each other and with

**[12:33]** conversations with each other and with the speakers to think about what the new

**[12:35]** the speakers to think about what the new

**[12:35]** the speakers to think about what the new standard model for AI engineering is.

**[12:36]** standard model for AI engineering is.

**[12:36]** standard model for AI engineering is. What can everyone use to improve their

**[12:38]** What can everyone use to improve their

**[12:38]** What can everyone use to improve their applications and I guess ultimately

**[12:40]** applications and I guess ultimately

**[12:40]** applications and I guess ultimately build products that people want to use

**[12:42]** build products that people want to use

**[12:42]** build products that people want to use which is what Lori uh mentioned at the

**[12:44]** which is what Lori uh mentioned at the

**[12:44]** which is what Lori uh mentioned at the start. So um I'm really excited about

**[12:46]** start. So um I'm really excited about

**[12:46]** start. So um I'm really excited about this conference. It's so it's been such

**[12:49]** this conference. It's so it's been such

**[12:49]** this conference. It's so it's been such an honor and a joy to get it together

**[12:50]** an honor and a joy to get it together

**[12:50]** an honor and a joy to get it together for you guys and I hope you enjoy the

**[12:52]** for you guys and I hope you enjoy the

**[12:52]** for you guys and I hope you enjoy the rest of the conference. Thank you so

**[12:53]** rest of the conference. Thank you so

**[12:53]** rest of the conference. Thank you so much.

**[12:56]** much.

**[12:56]** much. [Music]


