# The 2025 AI Engineering Report â€” Barr Yaron, Amplify

**Video URL:** https://www.youtube.com/watch?v=mQ7_Zje7WKE

---

## Full Transcript

### [00:00 - 01:00]

**[00:21]** [Music]

**[00:21]** [Music] [Applause]

**[00:31]** All right. Hi everyone.

**[00:31]** All right. Hi everyone. Uh, thank you for having me here and

**[00:33]** Uh, thank you for having me here and

**[00:33]** Uh, thank you for having me here and huge thanks to Ben, to Swix, to all the

**[00:35]** huge thanks to Ben, to Swix, to all the

**[00:35]** huge thanks to Ben, to Swix, to all the organizers who've put so much time and

**[00:37]** organizers who've put so much time and

**[00:38]** organizers who've put so much time and heart into bringing this community

**[00:39]** heart into bringing this community

**[00:39]** heart into bringing this community together.

**[00:41]** together.

**[00:41]** together. Yeah.

**[00:47]** All right. So, we're here because we

**[00:47]** All right. So, we're here because we care about AI engineering and where this

**[00:49]** care about AI engineering and where this

**[00:49]** care about AI engineering and where this field is headed. So, to better

**[00:51]** field is headed. So, to better

**[00:51]** field is headed. So, to better understand the current landscape, we

**[00:53]** understand the current landscape, we

**[00:53]** understand the current landscape, we launched the 2025 state of AI

**[00:56]** launched the 2025 state of AI

**[00:56]** launched the 2025 state of AI engineering survey. And I'm excited to

**[00:58]** engineering survey. And I'm excited to

**[00:58]** engineering survey. And I'm excited to share some early findings with you

**[00:59]** share some early findings with you

**[00:59]** share some early findings with you today.


### [01:00 - 02:00]

**[01:05]** All right, before we dive into the

**[01:05]** All right, before we dive into the results, the least interesting slide. Uh

**[01:07]** results, the least interesting slide. Uh

**[01:07]** results, the least interesting slide. Uh I don't know everyone in this audience,

**[01:09]** I don't know everyone in this audience,

**[01:09]** I don't know everyone in this audience, but I'm bar. I'm an investment partner

**[01:11]** but I'm bar. I'm an investment partner

**[01:12]** but I'm bar. I'm an investment partner at Amplify, where I'm lucky to invest in

**[01:14]** at Amplify, where I'm lucky to invest in

**[01:14]** at Amplify, where I'm lucky to invest in technical founders, including companies

**[01:16]** technical founders, including companies

**[01:16]** technical founders, including companies built by and for AI engineers.

**[01:19]** built by and for AI engineers.

**[01:19]** built by and for AI engineers. And uh with that, let's get into what

**[01:21]** And uh with that, let's get into what

**[01:21]** And uh with that, let's get into what you actually care about, which is enough

**[01:23]** you actually care about, which is enough

**[01:23]** you actually care about, which is enough bar and more bar charts.

**[01:25]** bar and more bar charts.

**[01:25]** bar and more bar charts. And there are a lot of bar charts coming

**[01:28]** And there are a lot of bar charts coming

**[01:28]** And there are a lot of bar charts coming up.

**[01:30]** up.

**[01:30]** up. Okay, so first our sample. We had 500

**[01:33]** Okay, so first our sample. We had 500

**[01:33]** Okay, so first our sample. We had 500 respondents fill out the survey,

**[01:35]** respondents fill out the survey,

**[01:35]** respondents fill out the survey, including many of you here in the

**[01:37]** including many of you here in the

**[01:37]** including many of you here in the audience today and on the live stream.

**[01:39]** audience today and on the live stream.

**[01:39]** audience today and on the live stream. Thank you for doing that.

**[01:42]** Thank you for doing that.

**[01:42]** Thank you for doing that. And the largest group called themselves

**[01:44]** And the largest group called themselves

**[01:44]** And the largest group called themselves engineers, whether software engineers or

**[01:47]** engineers, whether software engineers or

**[01:47]** engineers, whether software engineers or AI engineers. While this is the AI

**[01:50]** AI engineers. While this is the AI

**[01:50]** AI engineers. While this is the AI engineering conference, it's clear from

**[01:52]** engineering conference, it's clear from

**[01:52]** engineering conference, it's clear from the speakers, from the hallway chats,

**[01:54]** the speakers, from the hallway chats,

**[01:54]** the speakers, from the hallway chats, there's a wide mix of titles and roles.

**[01:57]** there's a wide mix of titles and roles.

**[01:57]** there's a wide mix of titles and roles. You even let a VC sneak in.

**[01:59]** You even let a VC sneak in.

**[01:59]** You even let a VC sneak in. Um, so let's test this with a quick show


### [02:00 - 03:00]

**[02:01]** Um, so let's test this with a quick show

**[02:01]** Um, so let's test this with a quick show of hands. Raise your hand if your title

**[02:04]** of hands. Raise your hand if your title

**[02:04]** of hands. Raise your hand if your title is actually AI engineer at the AI

**[02:07]** is actually AI engineer at the AI

**[02:07]** is actually AI engineer at the AI engineering conference. Okay, that is

**[02:09]** engineering conference. Okay, that is

**[02:09]** engineering conference. Okay, that is extremely sparse.

**[02:12]** extremely sparse.

**[02:12]** extremely sparse. Uh, raise your put your hands down.

**[02:15]** Uh, raise your put your hands down.

**[02:15]** Uh, raise your put your hands down. Raise your hand if your title is

**[02:16]** Raise your hand if your title is

**[02:16]** Raise your hand if your title is something else entirely. So that should

**[02:18]** something else entirely. So that should

**[02:18]** something else entirely. So that should be almost everyone. Keep it up if you

**[02:22]** be almost everyone. Keep it up if you

**[02:22]** be almost everyone. Keep it up if you think you're doing the exact same work

**[02:23]** think you're doing the exact same work

**[02:24]** think you're doing the exact same work as many of the AI engineers.

**[02:27]** as many of the AI engineers.

**[02:27]** as many of the AI engineers. All right. So this sort of tracks titles

**[02:30]** All right. So this sort of tracks titles

**[02:30]** All right. So this sort of tracks titles are weird right now, but the community

**[02:31]** are weird right now, but the community

**[02:31]** are weird right now, but the community is broad. It's technical. It's growing.

**[02:33]** is broad. It's technical. It's growing.

**[02:34]** is broad. It's technical. It's growing. We expect that AI engineer label to gain

**[02:36]** We expect that AI engineer label to gain

**[02:36]** We expect that AI engineer label to gain even more ground. Uh couldn't help

**[02:38]** even more ground. Uh couldn't help

**[02:38]** even more ground. Uh couldn't help myself. Quick Google trend search. Term

**[02:40]** myself. Quick Google trend search. Term

**[02:40]** myself. Quick Google trend search. Term AI engineering barely registered before

**[02:43]** AI engineering barely registered before

**[02:43]** AI engineering barely registered before late 2022. Uh we know what happened.

**[02:46]** late 2022. Uh we know what happened.

**[02:46]** late 2022. Uh we know what happened. Chat GPT launched and the moment for AI

**[02:48]** Chat GPT launched and the moment for AI

**[02:48]** Chat GPT launched and the moment for AI engineering interest has not slowed

**[02:49]** engineering interest has not slowed

**[02:49]** engineering interest has not slowed since. Okay. So people had a wide

**[02:52]** since. Okay. So people had a wide

**[02:52]** since. Okay. So people had a wide variety of titles but also a wide

**[02:54]** variety of titles but also a wide

**[02:54]** variety of titles but also a wide variety of experience. Uh the

**[02:56]** variety of experience. Uh the

**[02:56]** variety of experience. Uh the interesting part here is that many of

**[02:58]** interesting part here is that many of

**[02:58]** interesting part here is that many of our most seasoned developers are AI


### [03:00 - 04:00]

**[03:00]** our most seasoned developers are AI

**[03:00]** our most seasoned developers are AI newcomers. So among software engineers

**[03:03]** newcomers. So among software engineers

**[03:03]** newcomers. So among software engineers with 10 plus years of software

**[03:05]** with 10 plus years of software

**[03:05]** with 10 plus years of software experience nearly half have been working

**[03:07]** experience nearly half have been working

**[03:07]** experience nearly half have been working with AI for three years or less and one

**[03:10]** with AI for three years or less and one

**[03:10]** with AI for three years or less and one in 10 started just this past year. So

**[03:12]** in 10 started just this past year. So

**[03:12]** in 10 started just this past year. So change right now is the only constant

**[03:14]** change right now is the only constant

**[03:14]** change right now is the only constant even for the veterans.

**[03:17]** even for the veterans.

**[03:17]** even for the veterans. All right. So what are folks actually

**[03:18]** All right. So what are folks actually

**[03:18]** All right. So what are folks actually building? Let's get into the juice. So

**[03:21]** building? Let's get into the juice. So

**[03:21]** building? Let's get into the juice. So more than half of the respondents are

**[03:23]** more than half of the respondents are

**[03:23]** more than half of the respondents are using LLMs for both internal and

**[03:25]** using LLMs for both internal and

**[03:25]** using LLMs for both internal and external use cases. Uh what was striking

**[03:28]** external use cases. Uh what was striking

**[03:28]** external use cases. Uh what was striking to me was that three out of the top five

**[03:30]** to me was that three out of the top five

**[03:30]** to me was that three out of the top five models and half of the top 10 models

**[03:33]** models and half of the top 10 models

**[03:33]** models and half of the top 10 models that respondents are using for those

**[03:34]** that respondents are using for those

**[03:34]** that respondents are using for those external cases for the customerf facing

**[03:37]** external cases for the customerf facing

**[03:37]** external cases for the customerf facing products are from open AI.

**[03:41]** products are from open AI.

**[03:41]** products are from open AI. The top use cases that we saw are code

**[03:43]** The top use cases that we saw are code

**[03:43]** The top use cases that we saw are code generation and code intelligence and

**[03:45]** generation and code intelligence and

**[03:45]** generation and code intelligence and writing assistant content generation.

**[03:47]** writing assistant content generation.

**[03:47]** writing assistant content generation. Maybe that's not particularly

**[03:48]** Maybe that's not particularly

**[03:48]** Maybe that's not particularly surprising. Uh but the real story here

**[03:50]** surprising. Uh but the real story here

**[03:50]** surprising. Uh but the real story here is heterogeneity. So 94% of people who

**[03:54]** is heterogeneity. So 94% of people who

**[03:54]** is heterogeneity. So 94% of people who use LLMs are using it for at least two

**[03:56]** use LLMs are using it for at least two

**[03:56]** use LLMs are using it for at least two use cases. 82% using it for at least

**[03:59]** use cases. 82% using it for at least

**[03:59]** use cases. 82% using it for at least three. Basically folks who are using


### [04:00 - 05:00]

**[04:01]** three. Basically folks who are using

**[04:01]** three. Basically folks who are using LLMs are using it internally,

**[04:03]** LLMs are using it internally,

**[04:03]** LLMs are using it internally, externally, and across multiple use

**[04:05]** externally, and across multiple use

**[04:05]** externally, and across multiple use cases. All right. So you may ask how are

**[04:08]** cases. All right. So you may ask how are

**[04:08]** cases. All right. So you may ask how are folks actually interfacing with the

**[04:10]** folks actually interfacing with the

**[04:10]** folks actually interfacing with the models and how are they customizing

**[04:12]** models and how are they customizing

**[04:12]** models and how are they customizing their systems to for these use cases. Uh

**[04:16]** their systems to for these use cases. Uh

**[04:16]** their systems to for these use cases. Uh besides fshot learning rag is the most

**[04:19]** besides fshot learning rag is the most

**[04:19]** besides fshot learning rag is the most popular way folks are customizing their

**[04:21]** popular way folks are customizing their

**[04:21]** popular way folks are customizing their systems. So 70% of respondents said

**[04:24]** systems. So 70% of respondents said

**[04:24]** systems. So 70% of respondents said they're using it. The real surprise for

**[04:26]** they're using it. The real surprise for

**[04:26]** they're using it. The real surprise for me here I uh I'm I'm looking to gauge

**[04:29]** me here I uh I'm I'm looking to gauge

**[04:29]** me here I uh I'm I'm looking to gauge surprise in the audience was how much

**[04:31]** surprise in the audience was how much

**[04:31]** surprise in the audience was how much fine-tune is hap fine-tuning is

**[04:33]** fine-tune is hap fine-tuning is

**[04:33]** fine-tune is hap fine-tuning is happening across the board. It was much

**[04:35]** happening across the board. It was much

**[04:35]** happening across the board. It was much more than I had expected overall. Uh, in

**[04:37]** more than I had expected overall. Uh, in

**[04:38]** more than I had expected overall. Uh, in the sample, we have researchers and we

**[04:39]** the sample, we have researchers and we

**[04:39]** the sample, we have researchers and we have research engineers who were the

**[04:41]** have research engineers who were the

**[04:41]** have research engineers who were the ones doing fine-tuning by far the most.

**[04:44]** ones doing fine-tuning by far the most.

**[04:44]** ones doing fine-tuning by far the most. We also asked an open-ended question for

**[04:46]** We also asked an open-ended question for

**[04:46]** We also asked an open-ended question for those who were fine-tuning. What

**[04:48]** those who were fine-tuning. What

**[04:48]** those who were fine-tuning. What specific techniques are you using? So,

**[04:50]** specific techniques are you using? So,

**[04:50]** specific techniques are you using? So, here's what the fine-tuners had to say.

**[04:53]** here's what the fine-tuners had to say.

**[04:53]** here's what the fine-tuners had to say. Uh, 40% mentioned Laura or Qura

**[04:55]** Uh, 40% mentioned Laura or Qura

**[04:56]** Uh, 40% mentioned Laura or Qura reflecting a strong preference for

**[04:57]** reflecting a strong preference for

**[04:57]** reflecting a strong preference for parameter efficient methods. And we also


### [05:00 - 06:00]

**[05:00]** parameter efficient methods. And we also

**[05:00]** parameter efficient methods. And we also saw a bunch of different fine-tuning

**[05:02]** saw a bunch of different fine-tuning

**[05:02]** saw a bunch of different fine-tuning methods, uh, including DPO,

**[05:04]** methods, uh, including DPO,

**[05:04]** methods, uh, including DPO, reinforcement fine-tuning, and the most

**[05:07]** reinforcement fine-tuning, and the most

**[05:07]** reinforcement fine-tuning, and the most popular core training approach was good

**[05:09]** popular core training approach was good

**[05:09]** popular core training approach was good old supervised fine-tuning.

**[05:12]** old supervised fine-tuning.

**[05:12]** old supervised fine-tuning. Many hybrid approaches were listed as

**[05:14]** Many hybrid approaches were listed as

**[05:14]** Many hybrid approaches were listed as well.

**[05:16]** well.

**[05:16]** well. Um, moving on top uh to up on top of

**[05:20]** Um, moving on top uh to up on top of

**[05:20]** Um, moving on top uh to up on top of updating systems, sometimes it can feel

**[05:23]** updating systems, sometimes it can feel

**[05:23]** updating systems, sometimes it can feel like new models come out every single

**[05:25]** like new models come out every single

**[05:25]** like new models come out every single week. Just as you finished integrating

**[05:27]** week. Just as you finished integrating

**[05:27]** week. Just as you finished integrating one, another one drops with better

**[05:29]** one, another one drops with better

**[05:29]** one, another one drops with better benchmarks and a breaking change. So, it

**[05:31]** benchmarks and a breaking change. So, it

**[05:31]** benchmarks and a breaking change. So, it turns out more than 50% are updating

**[05:34]** turns out more than 50% are updating

**[05:34]** turns out more than 50% are updating their models at least monthly, 17%

**[05:37]** their models at least monthly, 17%

**[05:37]** their models at least monthly, 17% weekly,

**[05:39]** weekly,

**[05:40]** weekly, and folks are updating their prompts

**[05:42]** and folks are updating their prompts

**[05:42]** and folks are updating their prompts much more frequently. So, 70% of

**[05:44]** much more frequently. So, 70% of

**[05:44]** much more frequently. So, 70% of respondents are updating prompts at

**[05:46]** respondents are updating prompts at

**[05:46]** respondents are updating prompts at least monthly and one in 10 are doing it

**[05:49]** least monthly and one in 10 are doing it

**[05:49]** least monthly and one in 10 are doing it daily. So, it sounds like some of you

**[05:51]** daily. So, it sounds like some of you

**[05:51]** daily. So, it sounds like some of you have not stopped typing since GPT4

**[05:53]** have not stopped typing since GPT4

**[05:53]** have not stopped typing since GPT4 dropped.

**[05:54]** dropped.

**[05:54]** dropped. Um, but I also understand I have

**[05:57]** Um, but I also understand I have

**[05:57]** Um, but I also understand I have empathy. Uh, seeing one blog post from

**[05:59]** empathy. Uh, seeing one blog post from

**[05:59]** empathy. Uh, seeing one blog post from Simon Willis and suddenly your trusty


### [06:00 - 07:00]

**[06:01]** Simon Willis and suddenly your trusty

**[06:02]** Simon Willis and suddenly your trusty prompt just isn't good enough anymore.

**[06:09]** Despite all of these prompt changes, a

**[06:09]** Despite all of these prompt changes, a full 31% of respondents don't have any

**[06:12]** full 31% of respondents don't have any

**[06:12]** full 31% of respondents don't have any way of managing their prompts. Uh, what

**[06:15]** way of managing their prompts. Uh, what

**[06:15]** way of managing their prompts. Uh, what I did not ask is how AI engineers feel

**[06:18]** I did not ask is how AI engineers feel

**[06:18]** I did not ask is how AI engineers feel about not doing anything to manage their

**[06:20]** about not doing anything to manage their

**[06:20]** about not doing anything to manage their prompts. So, we have the 2026 survey for

**[06:23]** prompts. So, we have the 2026 survey for

**[06:23]** prompts. So, we have the 2026 survey for that.

**[06:25]** that.

**[06:25]** that. We also ask folks across the different

**[06:28]** We also ask folks across the different

**[06:28]** We also ask folks across the different modalities who is actually using these

**[06:30]** modalities who is actually using these

**[06:30]** modalities who is actually using these models at work and is it actually going

**[06:33]** models at work and is it actually going

**[06:33]** models at work and is it actually going well and we see that image, video and

**[06:35]** well and we see that image, video and

**[06:36]** well and we see that image, video and audio usage all lag text usage by

**[06:38]** audio usage all lag text usage by

**[06:38]** audio usage all lag text usage by significant margins.

**[06:41]** significant margins.

**[06:41]** significant margins. I like to call this the multimodal

**[06:43]** I like to call this the multimodal

**[06:43]** I like to call this the multimodal production gap

**[06:45]** production gap

**[06:45]** production gap because I wanted an animation. Um, and

**[06:48]** because I wanted an animation. Um, and

**[06:48]** because I wanted an animation. Um, and this gap still p persists when we add in

**[06:51]** this gap still p persists when we add in

**[06:51]** this gap still p persists when we add in folks who have these models in

**[06:53]** folks who have these models in

**[06:53]** folks who have these models in production but have not garnered as much

**[06:56]** production but have not garnered as much

**[06:56]** production but have not garnered as much traction.


### [07:00 - 08:00]

**[07:02]** Okay, what's interesting here is when we

**[07:02]** Okay, what's interesting here is when we add the folks who are not using models

**[07:05]** add the folks who are not using models

**[07:05]** add the folks who are not using models at all in this chart too. So here we can

**[07:08]** at all in this chart too. So here we can

**[07:08]** at all in this chart too. So here we can see folks who are not using text, not

**[07:11]** see folks who are not using text, not

**[07:11]** see folks who are not using text, not using image, not using audio or not

**[07:14]** using image, not using audio or not

**[07:14]** using image, not using audio or not using video. And we have two categories.

**[07:16]** using video. And we have two categories.

**[07:16]** using video. And we have two categories. It's broken down by folks who plan to

**[07:18]** It's broken down by folks who plan to

**[07:18]** It's broken down by folks who plan to eventually use these modalities and

**[07:20]** eventually use these modalities and

**[07:20]** eventually use these modalities and folks who do not currently plan to.

**[07:23]** folks who do not currently plan to.

**[07:24]** folks who do not currently plan to. You can roughly see this ratio of no

**[07:26]** You can roughly see this ratio of no

**[07:26]** You can roughly see this ratio of no plan to adopt versus plan to adopt.

**[07:29]** plan to adopt versus plan to adopt.

**[07:29]** plan to adopt versus plan to adopt. Audio has the highest intent to adopt.

**[07:31]** Audio has the highest intent to adopt.

**[07:31]** Audio has the highest intent to adopt. So 37% of the folks not using audio

**[07:35]** So 37% of the folks not using audio

**[07:35]** So 37% of the folks not using audio today have a plan to eventually adopt

**[07:38]** today have a plan to eventually adopt

**[07:38]** today have a plan to eventually adopt audio. So get ready to see an audio

**[07:40]** audio. So get ready to see an audio

**[07:40]** audio. So get ready to see an audio wave. Um, of course, as models get

**[07:43]** wave. Um, of course, as models get

**[07:43]** wave. Um, of course, as models get better and more accessible, I imagine

**[07:45]** better and more accessible, I imagine

**[07:45]** better and more accessible, I imagine some of these adoption numbers will go

**[07:46]** some of these adoption numbers will go

**[07:46]** some of these adoption numbers will go up even further.

**[07:48]** up even further.

**[07:48]** up even further. All right, so we have to talk about

**[07:50]** All right, so we have to talk about

**[07:50]** All right, so we have to talk about agents. One question I almost put in the

**[07:52]** agents. One question I almost put in the

**[07:52]** agents. One question I almost put in the survey was, "How do you define an AI

**[07:54]** survey was, "How do you define an AI

**[07:54]** survey was, "How do you define an AI agent?" But I thought I would still be

**[07:57]** agent?" But I thought I would still be

**[07:57]** agent?" But I thought I would still be reading through different responses. Uh,

**[07:59]** reading through different responses. Uh,

**[07:59]** reading through different responses. Uh, so for the sake of clarity, we defined


### [08:00 - 09:00]

**[08:01]** so for the sake of clarity, we defined

**[08:01]** so for the sake of clarity, we defined an AI agent as a system where an LLM

**[08:04]** an AI agent as a system where an LLM

**[08:04]** an AI agent as a system where an LLM controls the core decision-making or

**[08:06]** controls the core decision-making or

**[08:06]** controls the core decision-making or workflow.

**[08:08]** workflow.

**[08:08]** workflow. 80% of respondents say LLMs are working

**[08:11]** 80% of respondents say LLMs are working

**[08:11]** 80% of respondents say LLMs are working well at work, but less than 20% say the

**[08:13]** well at work, but less than 20% say the

**[08:14]** well at work, but less than 20% say the same about agents.

**[08:16]** same about agents.

**[08:16]** same about agents. Agents aren't everywhere yet, but

**[08:18]** Agents aren't everywhere yet, but

**[08:18]** Agents aren't everywhere yet, but they're coming. Uh, the majority of

**[08:20]** they're coming. Uh, the majority of

**[08:20]** they're coming. Uh, the majority of folks uh may not be using agents, but

**[08:22]** folks uh may not be using agents, but

**[08:22]** folks uh may not be using agents, but most at least plan to. So, fewer than

**[08:25]** most at least plan to. So, fewer than

**[08:25]** most at least plan to. So, fewer than one in 10 say that they will never use

**[08:27]** one in 10 say that they will never use

**[08:27]** one in 10 say that they will never use agents. All to say that people want

**[08:29]** agents. All to say that people want

**[08:29]** agents. All to say that people want their agents. And I'm probably uh

**[08:31]** their agents. And I'm probably uh

**[08:31]** their agents. And I'm probably uh preaching to the choir.

**[08:34]** preaching to the choir.

**[08:34]** preaching to the choir. Um the majority of agents already in

**[08:36]** Um the majority of agents already in

**[08:36]** Um the majority of agents already in production do have right access uh

**[08:38]** production do have right access uh

**[08:38]** production do have right access uh typically with a human in the loop and

**[08:40]** typically with a human in the loop and

**[08:40]** typically with a human in the loop and some can even take actions

**[08:42]** some can even take actions

**[08:42]** some can even take actions independently.

**[08:44]** independently.

**[08:44]** independently. So um excited as more agents are adopted

**[08:46]** So um excited as more agents are adopted

**[08:46]** So um excited as more agents are adopted to learn more about the tool

**[08:48]** to learn more about the tool

**[08:48]** to learn more about the tool permissioning that folks uh have access

**[08:50]** permissioning that folks uh have access

**[08:50]** permissioning that folks uh have access to.

**[08:52]** to.

**[08:52]** to. If we want AI in production of course we

**[08:54]** If we want AI in production of course we

**[08:54]** If we want AI in production of course we need strong monitoring and

**[08:55]** need strong monitoring and

**[08:55]** need strong monitoring and observability. So we asked do you manage

**[08:58]** observability. So we asked do you manage

**[08:58]** observability. So we asked do you manage and monitor your AI systems? This was a


### [09:00 - 10:00]

**[09:00]** and monitor your AI systems? This was a

**[09:00]** and monitor your AI systems? This was a multi- select question. So most folks

**[09:02]** multi- select question. So most folks

**[09:02]** multi- select question. So most folks are using multiple methods to monitor

**[09:04]** are using multiple methods to monitor

**[09:04]** are using multiple methods to monitor their systems. 60% are using standard

**[09:07]** their systems. 60% are using standard

**[09:07]** their systems. 60% are using standard observability. Over 50% rely on offline

**[09:10]** observability. Over 50% rely on offline

**[09:10]** observability. Over 50% rely on offline eval.

**[09:12]** eval.

**[09:12]** eval. And we asked the same thing for how you

**[09:14]** And we asked the same thing for how you

**[09:14]** And we asked the same thing for how you evaluate your model and system accuracy

**[09:16]** evaluate your model and system accuracy

**[09:16]** evaluate your model and system accuracy and quality. So folks are using a

**[09:19]** and quality. So folks are using a

**[09:19]** and quality. So folks are using a combination of methods including data

**[09:21]** combination of methods including data

**[09:21]** combination of methods including data collection from users, benchmarks, etc.

**[09:24]** collection from users, benchmarks, etc.

**[09:24]** collection from users, benchmarks, etc. But the most popular at the at the end

**[09:26]** But the most popular at the at the end

**[09:26]** But the most popular at the at the end of the day is still human review.

**[09:28]** of the day is still human review.

**[09:28]** of the day is still human review. Um and for monitoring their own model

**[09:30]** Um and for monitoring their own model

**[09:30]** Um and for monitoring their own model usage. Most respondents rely on internal

**[09:33]** usage. Most respondents rely on internal

**[09:33]** usage. Most respondents rely on internal metrics.

**[09:35]** metrics.

**[09:35]** metrics. So storage is important too. Where does

**[09:37]** So storage is important too. Where does

**[09:37]** So storage is important too. Where does the context live? How do we get it when

**[09:39]** the context live? How do we get it when

**[09:39]** the context live? How do we get it when we need it? 65% of respondents are using

**[09:42]** we need it? 65% of respondents are using

**[09:42]** we need it? 65% of respondents are using a dedicated vector database. And this

**[09:44]** a dedicated vector database. And this

**[09:44]** a dedicated vector database. And this suggests that for many use cases,

**[09:46]** suggests that for many use cases,

**[09:46]** suggests that for many use cases, specialized vector databases are

**[09:48]** specialized vector databases are

**[09:48]** specialized vector databases are providing enough value over

**[09:50]** providing enough value over

**[09:50]** providing enough value over generalpurpose databases with vector

**[09:52]** generalpurpose databases with vector

**[09:52]** generalpurpose databases with vector extensions. Uh among that group, 35%

**[09:56]** extensions. Uh among that group, 35%

**[09:56]** extensions. Uh among that group, 35% said that they primarily self-host. 30%

**[09:59]** said that they primarily self-host. 30%

**[09:59]** said that they primarily self-host. 30% primarily use a thirdparty provider.


### [10:00 - 11:00]

**[10:02]** primarily use a thirdparty provider.

**[10:02]** primarily use a thirdparty provider. All right, I think we've been having fun

**[10:04]** All right, I think we've been having fun

**[10:04]** All right, I think we've been having fun this whole time, but we're entering a

**[10:06]** this whole time, but we're entering a

**[10:06]** this whole time, but we're entering a section I like to formally call other

**[10:07]** section I like to formally call other

**[10:07]** section I like to formally call other fun stuff. Uh, I spent hours

**[10:10]** fun stuff. Uh, I spent hours

**[10:10]** fun stuff. Uh, I spent hours workshopping the name. So, we asked AI

**[10:13]** workshopping the name. So, we asked AI

**[10:13]** workshopping the name. So, we asked AI engineers, should agents be required to

**[10:15]** engineers, should agents be required to

**[10:16]** engineers, should agents be required to disclose when they're AI and not human?

**[10:19]** disclose when they're AI and not human?

**[10:19]** disclose when they're AI and not human? Most folks think yes, agents should

**[10:21]** Most folks think yes, agents should

**[10:21]** Most folks think yes, agents should disclose that they're AI. Uh we asked

**[10:23]** disclose that they're AI. Uh we asked

**[10:23]** disclose that they're AI. Uh we asked folks if they'd pay more for inference

**[10:25]** folks if they'd pay more for inference

**[10:25]** folks if they'd pay more for inference time compute and the answer was yes but

**[10:27]** time compute and the answer was yes but

**[10:27]** time compute and the answer was yes but not by a wide margin. And we asked folks

**[10:29]** not by a wide margin. And we asked folks

**[10:29]** not by a wide margin. And we asked folks if transformer-based models will be

**[10:31]** if transformer-based models will be

**[10:31]** if transformer-based models will be dominant in 2030 and it seems like

**[10:33]** dominant in 2030 and it seems like

**[10:33]** dominant in 2030 and it seems like people do believe that attention is all

**[10:35]** people do believe that attention is all

**[10:35]** people do believe that attention is all we'll need in 2030.

**[10:38]** we'll need in 2030.

**[10:38]** we'll need in 2030. Uh the majority of respondents also

**[10:40]** Uh the majority of respondents also

**[10:40]** Uh the majority of respondents also think open source and closed source

**[10:41]** think open source and closed source

**[10:41]** think open source and closed source models are going to converge. So I will

**[10:43]** models are going to converge. So I will

**[10:43]** models are going to converge. So I will let you debate that after. Um no

**[10:46]** let you debate that after. Um no

**[10:46]** let you debate that after. Um no commentary needed here. So, uh, the

**[10:49]** commentary needed here. So, uh, the

**[10:49]** commentary needed here. So, uh, the average or the mean guess for the

**[10:51]** average or the mean guess for the

**[10:51]** average or the mean guess for the percentage of US Gen Z population that

**[10:53]** percentage of US Gen Z population that

**[10:53]** percentage of US Gen Z population that will have AI girlfriends, boyfriends is

**[10:55]** will have AI girlfriends, boyfriends is

**[10:55]** will have AI girlfriends, boyfriends is 26%.

**[10:57]** 26%.

**[10:57]** 26%. Um, I don't really know what to say or

**[10:59]** Um, I don't really know what to say or

**[10:59]** Um, I don't really know what to say or expect here, but we'll see. Uh, we'll


### [11:00 - 12:00]

**[11:02]** expect here, but we'll see. Uh, we'll

**[11:02]** expect here, but we'll see. Uh, we'll see what happens. Uh, in a world where

**[11:05]** see what happens. Uh, in a world where

**[11:05]** see what happens. Uh, in a world where folks don't know if they're being left

**[11:07]** folks don't know if they're being left

**[11:07]** folks don't know if they're being left on red or just facing latency issues,

**[11:10]** on red or just facing latency issues,

**[11:10]** on red or just facing latency issues, um, or uh, of course, the dreaded it's

**[11:12]** um, or uh, of course, the dreaded it's

**[11:12]** um, or uh, of course, the dreaded it's not you, it's my algorithm.

**[11:16]** not you, it's my algorithm.

**[11:16]** not you, it's my algorithm. And finally, we asked folks, what is the

**[11:18]** And finally, we asked folks, what is the

**[11:18]** And finally, we asked folks, what is the number one most painful thing about AI

**[11:20]** number one most painful thing about AI

**[11:20]** number one most painful thing about AI engineering today? And evaluation topped

**[11:23]** engineering today? And evaluation topped

**[11:23]** engineering today? And evaluation topped that list. Uh, so it's a good thing this

**[11:25]** that list. Uh, so it's a good thing this

**[11:25]** that list. Uh, so it's a good thing this conference and the talk before me has

**[11:27]** conference and the talk before me has

**[11:27]** conference and the talk before me has been so focused on evals because clearly

**[11:29]** been so focused on evals because clearly

**[11:29]** been so focused on evals because clearly they're causing some serious pain. Okay.

**[11:32]** they're causing some serious pain. Okay.

**[11:32]** they're causing some serious pain. Okay. And now to bring us home, I'm going to

**[11:33]** And now to bring us home, I'm going to

**[11:33]** And now to bring us home, I'm going to show you what's popular. So, we asked

**[11:35]** show you what's popular. So, we asked

**[11:35]** show you what's popular. So, we asked folks to pick all the podcasts and

**[11:37]** folks to pick all the podcasts and

**[11:37]** folks to pick all the podcasts and newsletters that they actively learn

**[11:39]** newsletters that they actively learn

**[11:39]** newsletters that they actively learn something from at least once a month.

**[11:41]** something from at least once a month.

**[11:41]** something from at least once a month. And these were the top 10 of each. So,

**[11:43]** And these were the top 10 of each. So,

**[11:43]** And these were the top 10 of each. So, if you're looking for new content to

**[11:45]** if you're looking for new content to

**[11:45]** if you're looking for new content to follow and to learn from, this is your

**[11:46]** follow and to learn from, this is your

**[11:46]** follow and to learn from, this is your guide. Uh, many of the creators are in

**[11:49]** guide. Uh, many of the creators are in

**[11:49]** guide. Uh, many of the creators are in this room, so keep up the great work.

**[11:51]** this room, so keep up the great work.

**[11:52]** this room, so keep up the great work. And I'll just shout out that Swix is

**[11:53]** And I'll just shout out that Swix is

**[11:53]** And I'll just shout out that Swix is listed both on popular newsletter and

**[11:55]** listed both on popular newsletter and

**[11:55]** listed both on popular newsletter and popular podcast for latent space. Uh, so

**[11:58]** popular podcast for latent space. Uh, so

**[11:58]** popular podcast for latent space. Uh, so I will just leave this here.


### [12:00 - 13:00]

**[12:06]** Um, I think that's enough bar charts and

**[12:06]** Um, I think that's enough bar charts and bar time, but if you want to geek out

**[12:08]** bar time, but if you want to geek out

**[12:08]** bar time, but if you want to geek out about AI trends, you can come find me

**[12:10]** about AI trends, you can come find me

**[12:10]** about AI trends, you can come find me online in the hallways. Uh, we're going

**[12:12]** online in the hallways. Uh, we're going

**[12:12]** online in the hallways. Uh, we're going to be publishing a full report next

**[12:14]** to be publishing a full report next

**[12:14]** to be publishing a full report next week. Uh, I'll let Elon and Musk have

**[12:16]** week. Uh, I'll let Elon and Musk have

**[12:16]** week. Uh, I'll let Elon and Musk have Twitter today, but um, it's going to

**[12:19]** Twitter today, but um, it's going to

**[12:19]** Twitter today, but um, it's going to include more juicy details, including

**[12:21]** include more juicy details, including

**[12:21]** include more juicy details, including everyone's favorite models and tools

**[12:23]** everyone's favorite models and tools

**[12:23]** everyone's favorite models and tools across the stack. Thank you for the

**[12:25]** across the stack. Thank you for the

**[12:25]** across the stack. Thank you for the time. Enjoy the afternoon.

**[12:27]** time. Enjoy the afternoon.

**[12:27]** time. Enjoy the afternoon. [Music]


