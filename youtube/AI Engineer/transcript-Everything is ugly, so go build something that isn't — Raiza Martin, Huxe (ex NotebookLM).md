# Everything is ugly, so go build something that isn't â€” Raiza Martin, Huxe (ex NotebookLM)

**Video URL:** https://www.youtube.com/watch?v=yG5d5UaGz1M

---

## Full Transcript

### [00:00 - 01:00]

**[00:15]** Really quick show of hands. How many

**[00:16]** Really quick show of hands. How many folks actually work in product?

**[00:18]** folks actually work in product?

**[00:18]** folks actually work in product? Wow. Okay. Engineering,

**[00:21]** Wow. Okay. Engineering,

**[00:21]** Wow. Okay. Engineering, UX. Okay. I feel like there's definitely

**[00:24]** UX. Okay. I feel like there's definitely

**[00:24]** UX. Okay. I feel like there's definitely some overlap there, right? But that's

**[00:25]** some overlap there, right? But that's

**[00:25]** some overlap there, right? But that's that's exactly what we're seeing happen

**[00:27]** that's exactly what we're seeing happen

**[00:28]** that's exactly what we're seeing happen right now. Sorry, I have to keep walking

**[00:29]** right now. Sorry, I have to keep walking

**[00:29]** right now. Sorry, I have to keep walking over here because I'm so short. Like, if

**[00:30]** over here because I'm so short. Like, if

**[00:30]** over here because I'm so short. Like, if I stand here, I can't see you. Um, but

**[00:33]** I stand here, I can't see you. Um, but

**[00:33]** I stand here, I can't see you. Um, but what what's crazy is I feel like we're

**[00:36]** what what's crazy is I feel like we're

**[00:36]** what what's crazy is I feel like we're all doing all the jobs now, right? Like

**[00:39]** all doing all the jobs now, right? Like

**[00:39]** all doing all the jobs now, right? Like that's the crazy thing about AI. That's

**[00:41]** that's the crazy thing about AI. That's

**[00:41]** that's the crazy thing about AI. That's the crazy thing about right now. And uh

**[00:44]** the crazy thing about right now. And uh

**[00:44]** the crazy thing about right now. And uh I wonder how much longer it's going to

**[00:46]** I wonder how much longer it's going to

**[00:46]** I wonder how much longer it's going to be relevant for to ask, you know, what

**[00:48]** be relevant for to ask, you know, what

**[00:48]** be relevant for to ask, you know, what do you do? What do you do at your

**[00:50]** do you do? What do you do at your

**[00:50]** do you do? What do you do at your company? Because chances are you're

**[00:52]** company? Because chances are you're

**[00:52]** company? Because chances are you're probably doing everything. And you can,

**[00:54]** probably doing everything. And you can,

**[00:54]** probably doing everything. And you can, right, with with some ease. And so I

**[00:56]** right, with with some ease. And so I

**[00:56]** right, with with some ease. And so I think a lot of questions, people ask me

**[00:57]** think a lot of questions, people ask me

**[00:57]** think a lot of questions, people ask me this all the time. Students in

**[00:59]** this all the time. Students in

**[00:59]** this all the time. Students in particular ask me this all the time. Uh


### [01:00 - 02:00]

**[01:01]** particular ask me this all the time. Uh

**[01:01]** particular ask me this all the time. Uh so what does product do like in this new

**[01:04]** so what does product do like in this new

**[01:04]** so what does product do like in this new world? And so the way that I think about

**[01:06]** world? And so the way that I think about

**[01:06]** world? And so the way that I think about product is kind of like a multi-layer

**[01:08]** product is kind of like a multi-layer

**[01:08]** product is kind of like a multi-layer cake. And I think that it starts with

**[01:11]** cake. And I think that it starts with

**[01:11]** cake. And I think that it starts with how we think about ourselves. And I know

**[01:13]** how we think about ourselves. And I know

**[01:13]** how we think about ourselves. And I know this is like kind of a weird topic. is

**[01:15]** this is like kind of a weird topic. is

**[01:15]** this is like kind of a weird topic. is like not super technical but I think

**[01:17]** like not super technical but I think

**[01:17]** like not super technical but I think it's probably one of the most important

**[01:19]** it's probably one of the most important

**[01:19]** it's probably one of the most important which is uh I remember when it was

**[01:21]** which is uh I remember when it was

**[01:21]** which is uh I remember when it was considered technical to be uh the type

**[01:24]** considered technical to be uh the type

**[01:24]** considered technical to be uh the type of PM that could write your own SQL

**[01:26]** of PM that could write your own SQL

**[01:26]** of PM that could write your own SQL queries right but you know if I said

**[01:29]** queries right but you know if I said

**[01:29]** queries right but you know if I said that to you now like it's kind of silly

**[01:31]** that to you now like it's kind of silly

**[01:31]** that to you now like it's kind of silly because everybody knows how to write

**[01:32]** because everybody knows how to write

**[01:32]** because everybody knows how to write their own SQL queries because chatgbt

**[01:34]** their own SQL queries because chatgbt

**[01:34]** their own SQL queries because chatgbt does right like all you have to do is to

**[01:37]** does right like all you have to do is to

**[01:37]** does right like all you have to do is to know what question you're asking and

**[01:39]** know what question you're asking and

**[01:39]** know what question you're asking and then you can do it right but it's not

**[01:41]** then you can do it right but it's not

**[01:41]** then you can do it right but it's not just like these little tasks that you

**[01:43]** just like these little tasks that you

**[01:43]** just like these little tasks that you can do it's also

**[01:44]** can do it's also

**[01:44]** can do it's also like the entire roles themselves that

**[01:47]** like the entire roles themselves that

**[01:47]** like the entire roles themselves that are changing because it's easier than

**[01:49]** are changing because it's easier than

**[01:49]** are changing because it's easier than ever to access expertise or simulate it

**[01:53]** ever to access expertise or simulate it

**[01:53]** ever to access expertise or simulate it right so in a world where the jobs are

**[01:55]** right so in a world where the jobs are

**[01:55]** right so in a world where the jobs are blending together I feel like it's even

**[01:58]** blending together I feel like it's even

**[01:58]** blending together I feel like it's even more important to understand you know


### [02:00 - 03:00]

**[02:00]** more important to understand you know

**[02:00]** more important to understand you know where are you coming from what is the

**[02:02]** where are you coming from what is the

**[02:02]** where are you coming from what is the value that you bring you know coming

**[02:04]** value that you bring you know coming

**[02:04]** value that you bring you know coming from yourself and then there's this

**[02:06]** from yourself and then there's this

**[02:06]** from yourself and then there's this other thing that's really interesting

**[02:08]** other thing that's really interesting

**[02:08]** other thing that's really interesting that's happening which is teams are

**[02:10]** that's happening which is teams are

**[02:10]** that's happening which is teams are becoming drastically reconfigured and

**[02:12]** becoming drastically reconfigured and

**[02:12]** becoming drastically reconfigured and even at like a super basic level. Like

**[02:15]** even at like a super basic level. Like

**[02:15]** even at like a super basic level. Like if you think about it, every team now

**[02:17]** if you think about it, every team now

**[02:17]** if you think about it, every team now has a bunch of like invisible

**[02:19]** has a bunch of like invisible

**[02:19]** has a bunch of like invisible participants, right? Like every doc,

**[02:22]** participants, right? Like every doc,

**[02:22]** participants, right? Like every doc, every slide, every little bit of thing

**[02:25]** every slide, every little bit of thing

**[02:25]** every slide, every little bit of thing that is passed around or created,

**[02:27]** that is passed around or created,

**[02:27]** that is passed around or created, there's like a chat GPT or a claude or a

**[02:29]** there's like a chat GPT or a claude or a

**[02:29]** there's like a chat GPT or a claude or a Gemini behind that thing, right? Like

**[02:31]** Gemini behind that thing, right? Like

**[02:31]** Gemini behind that thing, right? Like most of the time, even when I read

**[02:33]** most of the time, even when I read

**[02:33]** most of the time, even when I read something like with my own raw eyeballs,

**[02:36]** something like with my own raw eyeballs,

**[02:36]** something like with my own raw eyeballs, I'll still give it to ChatGpt and be

**[02:37]** I'll still give it to ChatGpt and be

**[02:37]** I'll still give it to ChatGpt and be like, "What did I miss?" Right? Like

**[02:39]** like, "What did I miss?" Right? Like

**[02:39]** like, "What did I miss?" Right? Like here's my takeaways. What's yours? And

**[02:41]** here's my takeaways. What's yours? And

**[02:41]** here's my takeaways. What's yours? And that's crazy because teams are now fully

**[02:43]** that's crazy because teams are now fully

**[02:44]** that's crazy because teams are now fully augmented, right? We've got like five

**[02:46]** augmented, right? We've got like five

**[02:46]** augmented, right? We've got like five people on a team and we've got five chat

**[02:47]** people on a team and we've got five chat

**[02:48]** people on a team and we've got five chat GPTs and that's crazy. We don't really

**[02:50]** GPTs and that's crazy. We don't really

**[02:50]** GPTs and that's crazy. We don't really know what that means, right? But we've

**[02:52]** know what that means, right? But we've

**[02:52]** know what that means, right? But we've got we've got superpowers now. How are

**[02:53]** got we've got superpowers now. How are

**[02:53]** got we've got superpowers now. How are we going to use it? And then there's

**[02:56]** we going to use it? And then there's

**[02:56]** we going to use it? And then there's this layer which I think is like super

**[02:58]** this layer which I think is like super

**[02:58]** this layer which I think is like super interesting which is this is where the


### [03:00 - 04:00]

**[03:00]** interesting which is this is where the

**[03:00]** interesting which is this is where the title slide comes from where um I think

**[03:03]** title slide comes from where um I think

**[03:03]** title slide comes from where um I think products come from from people like deep

**[03:05]** products come from from people like deep

**[03:05]** products come from from people like deep within people, right? You pull an idea

**[03:08]** within people, right? You pull an idea

**[03:08]** within people, right? You pull an idea out of yourself and you translate it

**[03:09]** out of yourself and you translate it

**[03:10]** out of yourself and you translate it into technology and that's what a

**[03:11]** into technology and that's what a

**[03:11]** into technology and that's what a product is. But when you look at every

**[03:14]** product is. But when you look at every

**[03:14]** product is. But when you look at every product that we are using, you can tell

**[03:17]** product that we are using, you can tell

**[03:17]** product that we are using, you can tell we are in the clunky awkward years,

**[03:20]** we are in the clunky awkward years,

**[03:20]** we are in the clunky awkward years, right? You can tell everything is about

**[03:22]** right? You can tell everything is about

**[03:22]** right? You can tell everything is about to change. And literally everything we

**[03:24]** to change. And literally everything we

**[03:24]** to change. And literally everything we are using is the ugliest that it will

**[03:27]** are using is the ugliest that it will

**[03:27]** are using is the ugliest that it will ever be because everything we use was

**[03:30]** ever be because everything we use was

**[03:30]** ever be because everything we use was created in like the pre-ai era where you

**[03:33]** created in like the pre-ai era where you

**[03:33]** created in like the pre-ai era where you know we had to imagine well how do I

**[03:35]** know we had to imagine well how do I

**[03:35]** know we had to imagine well how do I make this thing work like if I press

**[03:37]** make this thing work like if I press

**[03:37]** make this thing work like if I press this button like it makes a J on my

**[03:39]** this button like it makes a J on my

**[03:39]** this button like it makes a J on my screen like now it feels like kind of

**[03:41]** screen like now it feels like kind of

**[03:41]** screen like now it feels like kind of strange like when you think about the

**[03:43]** strange like when you think about the

**[03:43]** strange like when you think about the richness of like the interactions that

**[03:45]** richness of like the interactions that

**[03:45]** richness of like the interactions that are possible it now feels kind of

**[03:47]** are possible it now feels kind of

**[03:47]** are possible it now feels kind of strange to use like an everyday thing

**[03:49]** strange to use like an everyday thing

**[03:49]** strange to use like an everyday thing like a microwave or maybe it's just me

**[03:51]** like a microwave or maybe it's just me

**[03:51]** like a microwave or maybe it's just me maybe I'm the only one who wants like an

**[03:53]** maybe I'm the only one who wants like an

**[03:53]** maybe I'm the only one who wants like an AI AI microwave, right? Or whatever

**[03:54]** AI AI microwave, right? Or whatever

**[03:54]** AI AI microwave, right? Or whatever whatever that thing does. Um, but I

**[03:56]** whatever that thing does. Um, but I

**[03:56]** whatever that thing does. Um, but I think what I'm trying to say is like

**[03:57]** think what I'm trying to say is like

**[03:58]** think what I'm trying to say is like we're starting to assemble the shapes of


### [04:00 - 05:00]

**[04:00]** we're starting to assemble the shapes of

**[04:00]** we're starting to assemble the shapes of what we think AI is really capable of

**[04:03]** what we think AI is really capable of

**[04:03]** what we think AI is really capable of and what it can deliver. And I think

**[04:05]** and what it can deliver. And I think

**[04:05]** and what it can deliver. And I think that the best products out there haven't

**[04:06]** that the best products out there haven't

**[04:06]** that the best products out there haven't been discovered yet.

**[04:09]** been discovered yet.

**[04:09]** been discovered yet. How do we discover it? Well, I think the

**[04:11]** How do we discover it? Well, I think the

**[04:11]** How do we discover it? Well, I think the answer lies in the final layer and sort

**[04:13]** answer lies in the final layer and sort

**[04:13]** answer lies in the final layer and sort of typically right what a product

**[04:15]** of typically right what a product

**[04:15]** of typically right what a product manager would say. I think it's in the

**[04:17]** manager would say. I think it's in the

**[04:17]** manager would say. I think it's in the user layer. And uh what I mean by this

**[04:20]** user layer. And uh what I mean by this

**[04:20]** user layer. And uh what I mean by this is I don't know if you all have noticed

**[04:22]** is I don't know if you all have noticed

**[04:22]** is I don't know if you all have noticed it but there is this kind of like

**[04:25]** it but there is this kind of like

**[04:25]** it but there is this kind of like consumer unrest right where as we use

**[04:29]** consumer unrest right where as we use

**[04:29]** consumer unrest right where as we use products like chat GBT cursor claude

**[04:33]** products like chat GBT cursor claude

**[04:33]** products like chat GBT cursor claude right you start to see wow it's super

**[04:36]** right you start to see wow it's super

**[04:36]** right you start to see wow it's super easy to use this it's just like I

**[04:38]** easy to use this it's just like I

**[04:38]** easy to use this it's just like I have to say what I want and something

**[04:40]** have to say what I want and something

**[04:40]** have to say what I want and something magical comes back and now I have to go

**[04:42]** magical comes back and now I have to go

**[04:42]** magical comes back and now I have to go use the rest of this dumb thing like

**[04:44]** use the rest of this dumb thing like

**[04:44]** use the rest of this dumb thing like dumb products out there that don't do

**[04:46]** dumb products out there that don't do

**[04:46]** dumb products out there that don't do that and so you have a little bit of

**[04:49]** that and so you have a little bit of

**[04:49]** that and so you have a little bit of this chasm now where you have these

**[04:50]** this chasm now where you have these

**[04:50]** this chasm now where you have these super powerful, really intuitive, really

**[04:52]** super powerful, really intuitive, really

**[04:52]** super powerful, really intuitive, really smart products and you have the rest of

**[04:55]** smart products and you have the rest of

**[04:55]** smart products and you have the rest of the world which is just like janky. And

**[04:58]** the world which is just like janky. And

**[04:58]** the world which is just like janky. And I think that what we're going to see is

**[04:59]** I think that what we're going to see is


### [05:00 - 06:00]

**[05:00]** I think that what we're going to see is that there's going to be a phase where

**[05:03]** that there's going to be a phase where

**[05:03]** that there's going to be a phase where everything gets rebuilt, right? So

**[05:08]** everything gets rebuilt, right? So

**[05:08]** everything gets rebuilt, right? So how should we think about rebuilding?

**[05:10]** how should we think about rebuilding?

**[05:10]** how should we think about rebuilding? Well, first of all, I think we should

**[05:13]** Well, first of all, I think we should

**[05:13]** Well, first of all, I think we should not underell the fact that there is a

**[05:15]** not underell the fact that there is a

**[05:15]** not underell the fact that there is a lot of chaos. Like all the time, I think

**[05:19]** lot of chaos. Like all the time, I think

**[05:19]** lot of chaos. Like all the time, I think I try to emphasize this to people. Even

**[05:21]** I try to emphasize this to people. Even

**[05:21]** I try to emphasize this to people. Even though things are like really cool and

**[05:24]** though things are like really cool and

**[05:24]** though things are like really cool and pretty magical, it's also pretty

**[05:26]** pretty magical, it's also pretty

**[05:26]** pretty magical, it's also pretty hard because each of these layers is

**[05:29]** hard because each of these layers is

**[05:29]** hard because each of these layers is being effectively rewritten and that is

**[05:32]** being effectively rewritten and that is

**[05:32]** being effectively rewritten and that is not without cost, right? Like even the

**[05:33]** not without cost, right? Like even the

**[05:33]** not without cost, right? Like even the first question I asked which was like,

**[05:34]** first question I asked which was like,

**[05:34]** first question I asked which was like, "Hey, what do you do for a living?" Like

**[05:36]** "Hey, what do you do for a living?" Like

**[05:36]** "Hey, what do you do for a living?" Like it's kind of weird. Like it's really

**[05:37]** it's kind of weird. Like it's really

**[05:37]** it's kind of weird. Like it's really uncomfortable to be like, "I don't

**[05:38]** uncomfortable to be like, "I don't

**[05:38]** uncomfortable to be like, "I don't know." like are they still going to be

**[05:40]** know." like are they still going to be

**[05:40]** know." like are they still going to be hiring product managers next year? Not

**[05:42]** hiring product managers next year? Not

**[05:42]** hiring product managers next year? Not sure. Engineers don't know. Designers

**[05:44]** sure. Engineers don't know. Designers

**[05:44]** sure. Engineers don't know. Designers maybe, right? But for the most part,

**[05:46]** maybe, right? But for the most part,

**[05:46]** maybe, right? But for the most part, right, that that unrest lives inside of

**[05:48]** right, that that unrest lives inside of

**[05:48]** right, that that unrest lives inside of us at each of these layers. And that's

**[05:51]** us at each of these layers. And that's

**[05:51]** us at each of these layers. And that's crazy. And so I started out this spiel

**[05:54]** crazy. And so I started out this spiel

**[05:54]** crazy. And so I started out this spiel asking, you know, what is the role of

**[05:55]** asking, you know, what is the role of

**[05:55]** asking, you know, what is the role of product? And ultimately,

**[05:58]** product? And ultimately,

**[05:58]** product? And ultimately, I think that complimentary to chaos is


### [06:00 - 07:00]

**[06:01]** I think that complimentary to chaos is

**[06:01]** I think that complimentary to chaos is always opportunity, right? And our job

**[06:05]** always opportunity, right? And our job

**[06:05]** always opportunity, right? And our job as product people, I I don't say product

**[06:07]** as product people, I I don't say product

**[06:07]** as product people, I I don't say product managers, I think just like whoever you

**[06:09]** managers, I think just like whoever you

**[06:09]** managers, I think just like whoever you are, right? Like if you embody sort of

**[06:11]** are, right? Like if you embody sort of

**[06:11]** are, right? Like if you embody sort of like the force behind a product, this

**[06:12]** like the force behind a product, this

**[06:12]** like the force behind a product, this applies to you. Your job is to find the

**[06:16]** applies to you. Your job is to find the

**[06:16]** applies to you. Your job is to find the nugget of opportunity out there and

**[06:19]** nugget of opportunity out there and

**[06:19]** nugget of opportunity out there and explode it like a popcorn kernel, right?

**[06:22]** explode it like a popcorn kernel, right?

**[06:22]** explode it like a popcorn kernel, right? Like that is your singular job. And I

**[06:24]** Like that is your singular job. And I

**[06:24]** Like that is your singular job. And I think it's actually kind of exciting if

**[06:26]** think it's actually kind of exciting if

**[06:26]** think it's actually kind of exciting if you work at an organization where every

**[06:28]** you work at an organization where every

**[06:28]** you work at an organization where every person embraces this mission.

**[06:31]** person embraces this mission.

**[06:31]** person embraces this mission. Okay, so my talk is largely about this

**[06:33]** Okay, so my talk is largely about this

**[06:33]** Okay, so my talk is largely about this opportunity and how I think you should

**[06:35]** opportunity and how I think you should

**[06:35]** opportunity and how I think you should go about exploding it. Um, I think there

**[06:37]** go about exploding it. Um, I think there

**[06:37]** go about exploding it. Um, I think there are a lot of talks that you could attend

**[06:38]** are a lot of talks that you could attend

**[06:38]** are a lot of talks that you could attend that tell you sort of practically how

**[06:40]** that tell you sort of practically how

**[06:40]** that tell you sort of practically how to, you know, technically build

**[06:42]** to, you know, technically build

**[06:42]** to, you know, technically build products, but like I I really want to

**[06:44]** products, but like I I really want to

**[06:44]** products, but like I I really want to talk through sort of the principles that

**[06:46]** talk through sort of the principles that

**[06:46]** talk through sort of the principles that I use to drive product building, right?

**[06:49]** I use to drive product building, right?

**[06:49]** I use to drive product building, right? So, let's jump in. What does it take to

**[06:51]** So, let's jump in. What does it take to

**[06:51]** So, let's jump in. What does it take to build a great AI product?

**[06:54]** build a great AI product?

**[06:54]** build a great AI product? So I think first I want to acknowledge

**[06:57]** So I think first I want to acknowledge

**[06:57]** So I think first I want to acknowledge that for folks who have shipped things


### [07:00 - 08:00]

**[07:00]** that for folks who have shipped things

**[07:00]** that for folks who have shipped things uh especially you know if you're a part

**[07:01]** uh especially you know if you're a part

**[07:01]** uh especially you know if you're a part of a team or a company I think that

**[07:04]** of a team or a company I think that

**[07:04]** of a team or a company I think that building a product is a forceful

**[07:06]** building a product is a forceful

**[07:06]** building a product is a forceful experience like I tried to think about

**[07:09]** experience like I tried to think about

**[07:09]** experience like I tried to think about the right word to use here. I actually

**[07:11]** the right word to use here. I actually

**[07:11]** the right word to use here. I actually first was like, I think it's a violent

**[07:13]** first was like, I think it's a violent

**[07:13]** first was like, I think it's a violent experience. And my team was like, I

**[07:16]** experience. And my team was like, I

**[07:16]** experience. And my team was like, I don't know if you can say that, right?

**[07:17]** don't know if you can say that, right?

**[07:17]** don't know if you can say that, right? Like, I'm pretty sure people don't know

**[07:20]** Like, I'm pretty sure people don't know

**[07:20]** Like, I'm pretty sure people don't know if like a tech job is violent. And I was

**[07:22]** if like a tech job is violent. And I was

**[07:22]** if like a tech job is violent. And I was like, okay, okay, okay. It's forceful,

**[07:24]** like, okay, okay, okay. It's forceful,

**[07:24]** like, okay, okay, okay. It's forceful, right? And what I mean when I say that

**[07:27]** right? And what I mean when I say that

**[07:27]** right? And what I mean when I say that is I think that you almost have to force

**[07:29]** is I think that you almost have to force

**[07:29]** is I think that you almost have to force a product into existence. And I don't

**[07:32]** a product into existence. And I don't

**[07:32]** a product into existence. And I don't mean sort of like the hobby stuff,

**[07:34]** mean sort of like the hobby stuff,

**[07:34]** mean sort of like the hobby stuff, right? Like I mean to truly build

**[07:37]** right? Like I mean to truly build

**[07:37]** right? Like I mean to truly build something that can meaningfully exist as

**[07:40]** something that can meaningfully exist as

**[07:40]** something that can meaningfully exist as a product that has a place in people's

**[07:42]** a product that has a place in people's

**[07:42]** a product that has a place in people's lives like that takes a lot of force and

**[07:46]** lives like that takes a lot of force and

**[07:46]** lives like that takes a lot of force and I think that to to do that to do that

**[07:48]** I think that to to do that to do that

**[07:48]** I think that to to do that to do that particularly well you need a lot of

**[07:50]** particularly well you need a lot of

**[07:50]** particularly well you need a lot of personal clarity right and it's like

**[07:53]** personal clarity right and it's like

**[07:53]** personal clarity right and it's like it's like this thing that is inside of

**[07:55]** it's like this thing that is inside of

**[07:56]** it's like this thing that is inside of like an individual person right

**[07:57]** like an individual person right

**[07:58]** like an individual person right sometimes we talk about clarity we talk

**[07:59]** sometimes we talk about clarity we talk

**[07:59]** sometimes we talk about clarity we talk about like oh the team has to be clear


### [08:00 - 09:00]

**[08:01]** about like oh the team has to be clear

**[08:01]** about like oh the team has to be clear on this the org has to be clear on this

**[08:03]** on this the org has to be clear on this

**[08:03]** on this the org has to be clear on this it no right like I don't think that's

**[08:05]** it no right like I don't think that's

**[08:05]** it no right like I don't think that's where it starts. I actually think it has

**[08:06]** where it starts. I actually think it has

**[08:06]** where it starts. I actually think it has to start with sort of a singular

**[08:08]** to start with sort of a singular

**[08:08]** to start with sort of a singular individual that like carries this

**[08:10]** individual that like carries this

**[08:10]** individual that like carries this clarity with them, right? Because once

**[08:13]** clarity with them, right? Because once

**[08:13]** clarity with them, right? Because once you know the what of of what you're

**[08:16]** you know the what of of what you're

**[08:16]** you know the what of of what you're building and the why of it, that's real

**[08:18]** building and the why of it, that's real

**[08:18]** building and the why of it, that's real energy. And I think when people talk

**[08:21]** energy. And I think when people talk

**[08:21]** energy. And I think when people talk about technology, we're always talking

**[08:23]** about technology, we're always talking

**[08:23]** about technology, we're always talking about technology, tech, the stack, etc.,

**[08:25]** about technology, tech, the stack, etc.,

**[08:25]** about technology, tech, the stack, etc., right? Hiring. I think everything we are

**[08:28]** right? Hiring. I think everything we are

**[08:28]** right? Hiring. I think everything we are talking about is just a transformed

**[08:30]** talking about is just a transformed

**[08:30]** talking about is just a transformed energy that comes from people. And so

**[08:33]** energy that comes from people. And so

**[08:33]** energy that comes from people. And so ultimately this personal clarity is

**[08:35]** ultimately this personal clarity is

**[08:35]** ultimately this personal clarity is what's going to give you the energy to

**[08:37]** what's going to give you the energy to

**[08:37]** what's going to give you the energy to push your team, to push your

**[08:38]** push your team, to push your

**[08:38]** push your team, to push your stakeholders, and to push your users

**[08:41]** stakeholders, and to push your users

**[08:41]** stakeholders, and to push your users because it's like it's it's really hard.

**[08:44]** because it's like it's it's really hard.

**[08:44]** because it's like it's it's really hard. And your primary role is just to

**[08:46]** And your primary role is just to

**[08:46]** And your primary role is just to cultivate that relentlessly. And I think

**[08:49]** cultivate that relentlessly. And I think

**[08:49]** cultivate that relentlessly. And I think it's three things, right? It's the

**[08:50]** it's three things, right? It's the

**[08:50]** it's three things, right? It's the clarity of your vision, the clarity of

**[08:53]** clarity of your vision, the clarity of

**[08:53]** clarity of your vision, the clarity of your purpose, and the clarity of taste,

**[08:54]** your purpose, and the clarity of taste,

**[08:54]** your purpose, and the clarity of taste, which I'll talk more about in just a

**[08:56]** which I'll talk more about in just a

**[08:56]** which I'll talk more about in just a little bit. I'll tell you a short story

**[08:58]** little bit. I'll tell you a short story

**[08:58]** little bit. I'll tell you a short story which is has anybody ever seen this or


### [09:00 - 10:00]

**[09:00]** which is has anybody ever seen this or

**[09:00]** which is has anybody ever seen this or used this thing?

**[09:03]** used this thing?

**[09:03]** used this thing? No. Yes. Okay. Well, this was the first

**[09:05]** No. Yes. Okay. Well, this was the first

**[09:05]** No. Yes. Okay. Well, this was the first version of Notebook LM. It was called

**[09:06]** version of Notebook LM. It was called

**[09:06]** version of Notebook LM. It was called Tailwind. We announced it at Google IO

**[09:09]** Tailwind. We announced it at Google IO

**[09:09]** Tailwind. We announced it at Google IO in 2023.

**[09:11]** in 2023.

**[09:12]** in 2023. And I will never forget the road to get

**[09:14]** And I will never forget the road to get

**[09:14]** And I will never forget the road to get to this thing, right? Like I think the

**[09:16]** to this thing, right? Like I think the

**[09:16]** to this thing, right? Like I think the amount of people that told me it was

**[09:17]** amount of people that told me it was

**[09:17]** amount of people that told me it was stupid was actually like like

**[09:20]** stupid was actually like like

**[09:20]** stupid was actually like like fascinatingly high. Uh, and it it was

**[09:23]** fascinatingly high. Uh, and it it was

**[09:23]** fascinatingly high. Uh, and it it was really great that I was like, "Wow, I

**[09:25]** really great that I was like, "Wow, I

**[09:26]** really great that I was like, "Wow, I think it might actually be stupid." But

**[09:28]** think it might actually be stupid." But

**[09:28]** think it might actually be stupid." But it's like that force, right? That

**[09:30]** it's like that force, right? That

**[09:30]** it's like that force, right? That personal clarity that gave me the energy

**[09:33]** personal clarity that gave me the energy

**[09:33]** personal clarity that gave me the energy to keep driving forward with it. And in

**[09:35]** to keep driving forward with it. And in

**[09:35]** to keep driving forward with it. And in reality, the reason why I had so much

**[09:37]** reality, the reason why I had so much

**[09:37]** reality, the reason why I had so much personal clarity, I don't think a lot of

**[09:38]** personal clarity, I don't think a lot of

**[09:38]** personal clarity, I don't think a lot of people know this, but I had dropped out

**[09:39]** people know this, but I had dropped out

**[09:40]** people know this, but I had dropped out of college and I went back to school

**[09:42]** of college and I went back to school

**[09:42]** of college and I went back to school full-time when I was working at Google.

**[09:44]** full-time when I was working at Google.

**[09:44]** full-time when I was working at Google. And so, I was full-time in college. I

**[09:46]** And so, I was full-time in college. I

**[09:46]** And so, I was full-time in college. I was full-time building Notebook LM. And

**[09:48]** was full-time building Notebook LM. And

**[09:48]** was full-time building Notebook LM. And I was like, I don't know how else to

**[09:50]** I was like, I don't know how else to

**[09:50]** I was like, I don't know how else to explain this to you, but if I could just

**[09:52]** explain this to you, but if I could just

**[09:52]** explain this to you, but if I could just have a tool where I put a bunch of

**[09:54]** have a tool where I put a bunch of

**[09:54]** have a tool where I put a bunch of in it, right? Like just a bunch of docs,

**[09:56]** in it, right? Like just a bunch of docs,

**[09:56]** in it, right? Like just a bunch of docs, a bunch of slides, and I just chat with

**[09:58]** a bunch of slides, and I just chat with

**[09:58]** a bunch of slides, and I just chat with it and it does something for me, that


### [10:00 - 11:00]

**[10:01]** it and it does something for me, that

**[10:02]** it and it does something for me, that seems really valuable. Like I've never

**[10:04]** seems really valuable. Like I've never

**[10:04]** seems really valuable. Like I've never been able to do that before, right? And

**[10:06]** been able to do that before, right? And

**[10:06]** been able to do that before, right? And I'm not just bolting it on. Like I want

**[10:07]** I'm not just bolting it on. Like I want

**[10:07]** I'm not just bolting it on. Like I want to build this thing from the ground up.

**[10:09]** to build this thing from the ground up.

**[10:09]** to build this thing from the ground up. And so every time somebody would tell me

**[10:11]** And so every time somebody would tell me

**[10:11]** And so every time somebody would tell me it was stupid, whether it was a user, a

**[10:13]** it was stupid, whether it was a user, a

**[10:13]** it was stupid, whether it was a user, a stakeholder, teammates even would be

**[10:15]** stakeholder, teammates even would be

**[10:15]** stakeholder, teammates even would be like, I don't understand, right? I would

**[10:17]** like, I don't understand, right? I would

**[10:17]** like, I don't understand, right? I would say no. I do though, right? Like I get

**[10:20]** say no. I do though, right? Like I get

**[10:20]** say no. I do though, right? Like I get it. I know why this thing is important.

**[10:23]** it. I know why this thing is important.

**[10:23]** it. I know why this thing is important. And so personal clarity will get you far

**[10:26]** And so personal clarity will get you far

**[10:26]** And so personal clarity will get you far and it will get your team far. Um and so

**[10:29]** and it will get your team far. Um and so

**[10:29]** and it will get your team far. Um and so I highly recommend starting from this

**[10:31]** I highly recommend starting from this

**[10:31]** I highly recommend starting from this place of just like cultivating this

**[10:33]** place of just like cultivating this

**[10:33]** place of just like cultivating this energy.

**[10:35]** energy.

**[10:35]** energy. Okay. So now you have clarity. Great.

**[10:37]** Okay. So now you have clarity. Great.

**[10:38]** Okay. So now you have clarity. Great. How do you turn that into a real thing?

**[10:40]** How do you turn that into a real thing?

**[10:40]** How do you turn that into a real thing? Well, I think that the first thing that

**[10:41]** Well, I think that the first thing that

**[10:41]** Well, I think that the first thing that I always tell people to do is you have

**[10:43]** I always tell people to do is you have

**[10:43]** I always tell people to do is you have to start with the job and not the

**[10:44]** to start with the job and not the

**[10:44]** to start with the job and not the pixels, right? Because when we talk

**[10:46]** pixels, right? Because when we talk

**[10:46]** pixels, right? Because when we talk about taste, I think sometimes people

**[10:49]** about taste, I think sometimes people

**[10:49]** about taste, I think sometimes people feel that that it's about an aesthetic

**[10:51]** feel that that it's about an aesthetic

**[10:51]** feel that that it's about an aesthetic thing, but I actually think it's about

**[10:53]** thing, but I actually think it's about

**[10:53]** thing, but I actually think it's about an outcome, right? I think it's about

**[10:56]** an outcome, right? I think it's about

**[10:56]** an outcome, right? I think it's about the question of what is the single

**[10:59]** the question of what is the single

**[10:59]** the question of what is the single outcome that your product has to deliver


### [11:00 - 12:00]

**[11:02]** outcome that your product has to deliver

**[11:02]** outcome that your product has to deliver every time for every user flawlessly.

**[11:06]** every time for every user flawlessly.

**[11:06]** every time for every user flawlessly. Like that is purpose, right? purpose is

**[11:08]** Like that is purpose, right? purpose is

**[11:08]** Like that is purpose, right? purpose is the north star that tells you whether a

**[11:11]** the north star that tells you whether a

**[11:11]** the north star that tells you whether a feature is uh gold or if it's just

**[11:14]** feature is uh gold or if it's just

**[11:14]** feature is uh gold or if it's just baggage and it's the antidote to uh a

**[11:18]** baggage and it's the antidote to uh a

**[11:18]** baggage and it's the antidote to uh a really common problem that I see all the

**[11:20]** really common problem that I see all the

**[11:20]** really common problem that I see all the time which is AI demo disease which is

**[11:23]** time which is AI demo disease which is

**[11:23]** time which is AI demo disease which is hey this thing is a cool demo I made it

**[11:25]** hey this thing is a cool demo I made it

**[11:25]** hey this thing is a cool demo I made it it demos really well I made a really

**[11:27]** it demos really well I made a really

**[11:27]** it demos really well I made a really cool Twitter video or whatever but these

**[11:29]** cool Twitter video or whatever but these

**[11:29]** cool Twitter video or whatever but these are not real products right if they're

**[11:32]** are not real products right if they're

**[11:32]** are not real products right if they're grounded in hype if they're grounded in

**[11:34]** grounded in hype if they're grounded in

**[11:34]** grounded in hype if they're grounded in sort of like trying to ride the waves of

**[11:36]** sort of like trying to ride the waves of

**[11:36]** sort of like trying to ride the waves of chaos you're not going to get anywhere.

**[11:38]** chaos you're not going to get anywhere.

**[11:38]** chaos you're not going to get anywhere. So purpose is what helps you say no to

**[11:40]** So purpose is what helps you say no to

**[11:40]** So purpose is what helps you say no to novelty when it's deluding your core

**[11:43]** novelty when it's deluding your core

**[11:43]** novelty when it's deluding your core job, right? Users literally do not give

**[11:45]** job, right? Users literally do not give

**[11:45]** job, right? Users literally do not give a if something is AI. I think

**[11:47]** a if something is AI. I think

**[11:47]** a if something is AI. I think people are actually kind of tired of the

**[11:49]** people are actually kind of tired of the

**[11:49]** people are actually kind of tired of the word. I think that what people care

**[11:51]** word. I think that what people care

**[11:51]** word. I think that what people care about ultimately is when they have an

**[11:53]** about ultimately is when they have an

**[11:53]** about ultimately is when they have an intent and you deliver it to them in a

**[11:57]** intent and you deliver it to them in a

**[11:57]** intent and you deliver it to them in a way that feels inevitable, right? And I

**[11:59]** way that feels inevitable, right? And I

**[11:59]** way that feels inevitable, right? And I think we go back to that energy, right?


### [12:00 - 13:00]

**[12:01]** think we go back to that energy, right?

**[12:01]** think we go back to that energy, right? It takes energy to get there. It's very

**[12:03]** It takes energy to get there. It's very

**[12:03]** It takes energy to get there. It's very hard and you need to be purpose obsessed

**[12:05]** hard and you need to be purpose obsessed

**[12:05]** hard and you need to be purpose obsessed in order to get there. And here's

**[12:08]** in order to get there. And here's

**[12:08]** in order to get there. And here's another example um that I want to give

**[12:10]** another example um that I want to give

**[12:10]** another example um that I want to give which is I was singularly obsessed with

**[12:12]** which is I was singularly obsessed with

**[12:12]** which is I was singularly obsessed with this use case of like I want to put 50

**[12:14]** this use case of like I want to put 50

**[12:14]** this use case of like I want to put 50 things in the tool and I want to be able

**[12:16]** things in the tool and I want to be able

**[12:16]** things in the tool and I want to be able to do stuff with it and summarization

**[12:18]** to do stuff with it and summarization

**[12:18]** to do stuff with it and summarization was a really big one because I figured

**[12:21]** was a really big one because I figured

**[12:21]** was a really big one because I figured if you could do this you could certainly

**[12:22]** if you could do this you could certainly

**[12:22]** if you could do this you could certainly do a lot more things across data right

**[12:25]** do a lot more things across data right

**[12:25]** do a lot more things across data right and uh it was really hard to do this. It

**[12:29]** and uh it was really hard to do this. It

**[12:29]** and uh it was really hard to do this. It was really hard for UX reasons. It was

**[12:31]** was really hard for UX reasons. It was

**[12:31]** was really hard for UX reasons. It was really hard for sort of the actual way

**[12:33]** really hard for sort of the actual way

**[12:33]** really hard for sort of the actual way that we were able to generate this in a

**[12:35]** that we were able to generate this in a

**[12:35]** that we were able to generate this in a smart way. But the tradeoff is that once

**[12:38]** smart way. But the tradeoff is that once

**[12:38]** smart way. But the tradeoff is that once we built this auto summary into notebook

**[12:40]** we built this auto summary into notebook

**[12:40]** we built this auto summary into notebook LM, it made it so much easier for people

**[12:43]** LM, it made it so much easier for people

**[12:43]** LM, it made it so much easier for people to understand a really foreign concept

**[12:45]** to understand a really foreign concept

**[12:45]** to understand a really foreign concept at the time, right? Which is like the

**[12:47]** at the time, right? Which is like the

**[12:48]** at the time, right? Which is like the concept that I would put 50 files in one

**[12:50]** concept that I would put 50 files in one

**[12:50]** concept that I would put 50 files in one place and I would interact with it in

**[12:52]** place and I would interact with it in

**[12:52]** place and I would interact with it in this different way that we hadn't really

**[12:54]** this different way that we hadn't really

**[12:54]** this different way that we hadn't really done before. It it was like a little

**[12:56]** done before. It it was like a little

**[12:56]** done before. It it was like a little token feature that was both a tutorial

**[12:59]** token feature that was both a tutorial

**[12:59]** token feature that was both a tutorial and was useful at a glance. But it's


### [13:00 - 14:00]

**[13:02]** and was useful at a glance. But it's

**[13:02]** and was useful at a glance. But it's like you could not have arrived at this

**[13:04]** like you could not have arrived at this

**[13:04]** like you could not have arrived at this type of idea which looks really basic

**[13:07]** type of idea which looks really basic

**[13:07]** type of idea which looks really basic just like from the outside of it. You

**[13:08]** just like from the outside of it. You

**[13:08]** just like from the outside of it. You could not have arrived at it if you were

**[13:10]** could not have arrived at it if you were

**[13:10]** could not have arrived at it if you were not sort of obsessively trying to drive

**[13:13]** not sort of obsessively trying to drive

**[13:13]** not sort of obsessively trying to drive at like the value that you're trying to

**[13:15]** at like the value that you're trying to

**[13:15]** at like the value that you're trying to deliver to somebody.

**[13:18]** deliver to somebody.

**[13:18]** deliver to somebody. And so I think that when we think about

**[13:21]** And so I think that when we think about

**[13:21]** And so I think that when we think about the value and what we're trying to give

**[13:22]** the value and what we're trying to give

**[13:22]** the value and what we're trying to give to users, I think that in reality the

**[13:26]** to users, I think that in reality the

**[13:26]** to users, I think that in reality the value of a product is a promise, right?

**[13:29]** value of a product is a promise, right?

**[13:29]** value of a product is a promise, right? Like ultimately any product is a promise

**[13:32]** Like ultimately any product is a promise

**[13:32]** Like ultimately any product is a promise to a user and you're making claims about

**[13:35]** to a user and you're making claims about

**[13:35]** to a user and you're making claims about what it can do, right? So then the user

**[13:37]** what it can do, right? So then the user

**[13:37]** what it can do, right? So then the user tries it. But trust is oxygen and using

**[13:42]** tries it. But trust is oxygen and using

**[13:42]** tries it. But trust is oxygen and using a product is like a transaction between

**[13:44]** a product is like a transaction between

**[13:44]** a product is like a transaction between the user and the company. And without

**[13:46]** the user and the company. And without

**[13:46]** the user and the company. And without it, you're nothing, right? You have like

**[13:47]** it, you're nothing, right? You have like

**[13:47]** it, you're nothing, right? You have like a pretty limited credit. Like most

**[13:49]** a pretty limited credit. Like most

**[13:49]** a pretty limited credit. Like most products get a credit of like negative

**[13:50]** products get a credit of like negative

**[13:50]** products get a credit of like negative one because not everybody's going to

**[13:52]** one because not everybody's going to

**[13:52]** one because not everybody's going to want to try your And then like the

**[13:54]** want to try your And then like the

**[13:54]** want to try your And then like the person that does like they don't have

**[13:55]** person that does like they don't have

**[13:55]** person that does like they don't have the patience for whatever things you put

**[13:57]** the patience for whatever things you put

**[13:57]** the patience for whatever things you put in there. They only have patience for

**[13:59]** in there. They only have patience for

**[13:59]** in there. They only have patience for one thing. And so I think one of the


### [14:00 - 15:00]

**[14:02]** one thing. And so I think one of the

**[14:02]** one thing. And so I think one of the best ways that you can actually build

**[14:04]** best ways that you can actually build

**[14:04]** best ways that you can actually build trust is to expose the edges, right?

**[14:08]** trust is to expose the edges, right?

**[14:08]** trust is to expose the edges, right? Show people where the model is dumb and

**[14:11]** Show people where the model is dumb and

**[14:11]** Show people where the model is dumb and make it seamless between the user and

**[14:13]** make it seamless between the user and

**[14:13]** make it seamless between the user and the product. like don't paper over it

**[14:15]** the product. like don't paper over it

**[14:15]** the product. like don't paper over it because even though we have these really

**[14:17]** because even though we have these really

**[14:17]** because even though we have these really smart incredible models, the way that we

**[14:20]** smart incredible models, the way that we

**[14:20]** smart incredible models, the way that we are building them is still like a very

**[14:22]** are building them is still like a very

**[14:22]** are building them is still like a very human type of thing. So when you when

**[14:25]** human type of thing. So when you when

**[14:25]** human type of thing. So when you when you give a product to a person, you are

**[14:26]** you give a product to a person, you are

**[14:26]** you give a product to a person, you are exposing your own process, your own

**[14:28]** exposing your own process, your own

**[14:28]** exposing your own process, your own thought process, your own workflow to

**[14:30]** thought process, your own workflow to

**[14:30]** thought process, your own workflow to them and you're making a promise about

**[14:32]** them and you're making a promise about

**[14:32]** them and you're making a promise about how it works. And so when it when it

**[14:35]** how it works. And so when it when it

**[14:35]** how it works. And so when it when it fails, when it doesn't work, think about

**[14:37]** fails, when it doesn't work, think about

**[14:37]** fails, when it doesn't work, think about how you go about it in the most human

**[14:39]** how you go about it in the most human

**[14:39]** how you go about it in the most human way possible, right? Like I I see this

**[14:41]** way possible, right? Like I I see this

**[14:41]** way possible, right? Like I I see this all the time where people are trying to

**[14:43]** all the time where people are trying to

**[14:43]** all the time where people are trying to instrument for like the best use case

**[14:45]** instrument for like the best use case

**[14:45]** instrument for like the best use case but not the worst case and so you kind

**[14:47]** but not the worst case and so you kind

**[14:47]** but not the worst case and so you kind of have this like weird halfbaked

**[14:48]** of have this like weird halfbaked

**[14:48]** of have this like weird halfbaked product in space where it's purely

**[14:51]** product in space where it's purely

**[14:51]** product in space where it's purely machine and very little human involved.

**[14:55]** machine and very little human involved.

**[14:55]** machine and very little human involved. I think on this note, I want to say

**[14:58]** I think on this note, I want to say

**[14:58]** I think on this note, I want to say something that sounds really dumb and

**[14:59]** something that sounds really dumb and

**[14:59]** something that sounds really dumb and basic, but I think that you have to nail


### [15:00 - 16:00]

**[15:01]** basic, but I think that you have to nail

**[15:01]** basic, but I think that you have to nail the deterministic things before the

**[15:04]** the deterministic things before the

**[15:04]** the deterministic things before the delightful probabilistic bits because at

**[15:07]** delightful probabilistic bits because at

**[15:07]** delightful probabilistic bits because at the end of the day, a good app is still

**[15:10]** the end of the day, a good app is still

**[15:10]** the end of the day, a good app is still just a really good app. Like, it's just

**[15:13]** just a really good app. Like, it's just

**[15:13]** just a really good app. Like, it's just an app, right? And it's like doesn't

**[15:15]** an app, right? And it's like doesn't

**[15:15]** an app, right? And it's like doesn't matter what you jam in there, it's still

**[15:17]** matter what you jam in there, it's still

**[15:17]** matter what you jam in there, it's still an app.

**[15:19]** an app.

**[15:20]** an app. Uh this is another one of like sort of

**[15:23]** Uh this is another one of like sort of

**[15:23]** Uh this is another one of like sort of the older uh user interfaces we had in

**[15:25]** the older uh user interfaces we had in

**[15:25]** the older uh user interfaces we had in notebook. But users routinely would do

**[15:27]** notebook. But users routinely would do

**[15:27]** notebook. But users routinely would do this thing where they would upload

**[15:29]** this thing where they would upload

**[15:29]** this thing where they would upload sources and they would enter a query

**[15:31]** sources and they would enter a query

**[15:31]** sources and they would enter a query like summarize this doc

**[15:34]** like summarize this doc

**[15:34]** like summarize this doc summarize this doc and this doc only

**[15:37]** summarize this doc and this doc only

**[15:37]** summarize this doc and this doc only summarize only this concept. And this

**[15:40]** summarize only this concept. And this

**[15:40]** summarize only this concept. And this was very hard to do in the early days of

**[15:42]** was very hard to do in the early days of

**[15:42]** was very hard to do in the early days of notebook LM particularly with the

**[15:43]** notebook LM particularly with the

**[15:44]** notebook LM particularly with the smaller context windows. And one of the

**[15:46]** smaller context windows. And one of the

**[15:46]** smaller context windows. And one of the things that we saw was the query type

**[15:49]** things that we saw was the query type

**[15:49]** things that we saw was the query type for summarization was like in terms of

**[15:52]** for summarization was like in terms of

**[15:52]** for summarization was like in terms of like the the percent of like first

**[15:54]** like the the percent of like first

**[15:54]** like the the percent of like first queries, it was like 90%. 90% of like

**[15:58]** queries, it was like 90%. 90% of like

**[15:58]** queries, it was like 90%. 90% of like users their first query was a

**[15:59]** users their first query was a

**[15:59]** users their first query was a summarization query and it was this


### [16:00 - 17:00]

**[16:02]** summarization query and it was this

**[16:02]** summarization query and it was this testing behavior, right? People were

**[16:05]** testing behavior, right? People were

**[16:05]** testing behavior, right? People were trying it out. They were like, I heard

**[16:06]** trying it out. They were like, I heard

**[16:06]** trying it out. They were like, I heard about this thing. Okay, saw the website.

**[16:08]** about this thing. Okay, saw the website.

**[16:08]** about this thing. Okay, saw the website. Cool. I'm gonna upload a thing. Like

**[16:10]** Cool. I'm gonna upload a thing. Like

**[16:10]** Cool. I'm gonna upload a thing. Like think about all the steps the user went

**[16:12]** think about all the steps the user went

**[16:12]** think about all the steps the user went through to get there. user gets there,

**[16:15]** through to get there. user gets there,

**[16:15]** through to get there. user gets there, they upload something, they enter

**[16:17]** they upload something, they enter

**[16:17]** they upload something, they enter summarize, and it it bors. It didn't

**[16:20]** summarize, and it it bors. It didn't

**[16:20]** summarize, and it it bors. It didn't work. So, the user leaves, they leave

**[16:22]** work. So, the user leaves, they leave

**[16:22]** work. So, the user leaves, they leave forever.

**[16:24]** forever.

**[16:24]** forever. But like, think about like the amount of

**[16:27]** But like, think about like the amount of

**[16:27]** But like, think about like the amount of time that like that person put into it

**[16:29]** time that like that person put into it

**[16:29]** time that like that person put into it because you made a promise to them that

**[16:30]** because you made a promise to them that

**[16:30]** because you made a promise to them that it was going to do exactly that. And so,

**[16:32]** it was going to do exactly that. And so,

**[16:32]** it was going to do exactly that. And so, I think that one of the things I want to

**[16:34]** I think that one of the things I want to

**[16:34]** I think that one of the things I want to say about trust is it's not it's not

**[16:36]** say about trust is it's not it's not

**[16:36]** say about trust is it's not it's not cheap, right? If you get a user to try

**[16:38]** cheap, right? If you get a user to try

**[16:38]** cheap, right? If you get a user to try your product, make it as good as

**[16:40]** your product, make it as good as

**[16:40]** your product, make it as good as possible the first time because they're

**[16:42]** possible the first time because they're

**[16:42]** possible the first time because they're not going to come back. In fact, it was

**[16:44]** not going to come back. In fact, it was

**[16:44]** not going to come back. In fact, it was like so detrimental the summarization

**[16:46]** like so detrimental the summarization

**[16:46]** like so detrimental the summarization use case that it was like all I thought

**[16:49]** use case that it was like all I thought

**[16:49]** use case that it was like all I thought about uh for a very long for a very long

**[16:51]** about uh for a very long for a very long

**[16:51]** about uh for a very long for a very long time.

**[16:53]** time.

**[16:53]** time. Okay. So, let's let's say you managed to

**[16:56]** Okay. So, let's let's say you managed to

**[16:56]** Okay. So, let's let's say you managed to earn the trust of your users. You've got

**[16:58]** earn the trust of your users. You've got

**[16:58]** earn the trust of your users. You've got a bunch of them. They love it. And


### [17:00 - 18:00]

**[17:01]** a bunch of them. They love it. And

**[17:01]** a bunch of them. They love it. And really uh to be honest with you, in real

**[17:03]** really uh to be honest with you, in real

**[17:03]** really uh to be honest with you, in real life, right, like this this flow that

**[17:04]** life, right, like this this flow that

**[17:04]** life, right, like this this flow that we're describing, it's actually like a

**[17:06]** we're describing, it's actually like a

**[17:06]** we're describing, it's actually like a matter of seconds for a person. This is

**[17:08]** matter of seconds for a person. This is

**[17:08]** matter of seconds for a person. This is like one minute, right, for you to

**[17:09]** like one minute, right, for you to

**[17:09]** like one minute, right, for you to deliver on this whole thing. Um, but you

**[17:12]** deliver on this whole thing. Um, but you

**[17:12]** deliver on this whole thing. Um, but you get to earn the next thing after we have

**[17:14]** get to earn the next thing after we have

**[17:14]** get to earn the next thing after we have trust, which is the potential to

**[17:16]** trust, which is the potential to

**[17:16]** trust, which is the potential to delight. And I think with notebook, this

**[17:19]** delight. And I think with notebook, this

**[17:19]** delight. And I think with notebook, this was like really cool where I feel like

**[17:22]** was like really cool where I feel like

**[17:22]** was like really cool where I feel like um the delightfulness was that it was

**[17:24]** um the delightfulness was that it was

**[17:24]** um the delightfulness was that it was unexpected and it was kind of funny

**[17:26]** unexpected and it was kind of funny

**[17:26]** unexpected and it was kind of funny where people would upload documents and

**[17:28]** where people would upload documents and

**[17:28]** where people would upload documents and then they would make a podcast and

**[17:29]** then they would make a podcast and

**[17:29]** then they would make a podcast and they're like, I don't know what it's

**[17:31]** they're like, I don't know what it's

**[17:31]** they're like, I don't know what it's going to say. Like it could be kind of

**[17:33]** going to say. Like it could be kind of

**[17:33]** going to say. Like it could be kind of goofy. It could be pretty funny. And I

**[17:35]** goofy. It could be pretty funny. And I

**[17:35]** goofy. It could be pretty funny. And I think there's like an aspect in there

**[17:38]** think there's like an aspect in there

**[17:38]** think there's like an aspect in there that is like just very playful, right?

**[17:40]** that is like just very playful, right?

**[17:40]** that is like just very playful, right? like delightfulness is almost is very

**[17:43]** like delightfulness is almost is very

**[17:43]** like delightfulness is almost is very similar to playfulness and it sort of

**[17:45]** similar to playfulness and it sort of

**[17:45]** similar to playfulness and it sort of lives I think in this interesting space

**[17:48]** lives I think in this interesting space

**[17:48]** lives I think in this interesting space between technical capabilities and user

**[17:50]** between technical capabilities and user

**[17:50]** between technical capabilities and user expectations because it's like you kind

**[17:53]** expectations because it's like you kind

**[17:53]** expectations because it's like you kind of have to meet users where they are but

**[17:55]** of have to meet users where they are but

**[17:55]** of have to meet users where they are but you have to push them just a little bit

**[17:58]** you have to push them just a little bit

**[17:58]** you have to push them just a little bit you know where once you've built trust


### [18:00 - 19:00]

**[18:00]** you know where once you've built trust

**[18:00]** you know where once you've built trust you can push just one step past what's

**[18:03]** you can push just one step past what's

**[18:03]** you can push just one step past what's familiar and not spook anybody because I

**[18:05]** familiar and not spook anybody because I

**[18:06]** familiar and not spook anybody because I I think we we've seen this too right

**[18:07]** I think we we've seen this too right

**[18:07]** I think we we've seen this too right like when things are like too weird it's

**[18:08]** like when things are like too weird it's

**[18:08]** like when things are like too weird it's like spooky and people are like I don't

**[18:10]** like spooky and people are like I don't

**[18:10]** like spooky and people are like I don't you know, I'm not going to look at it

**[18:11]** you know, I'm not going to look at it

**[18:11]** you know, I'm not going to look at it anymore. I feel like people felt this

**[18:12]** anymore. I feel like people felt this

**[18:12]** anymore. I feel like people felt this way about robots for a long time. And

**[18:14]** way about robots for a long time. And

**[18:14]** way about robots for a long time. And so, I think that in reality, kind of

**[18:16]** so, I think that in reality, kind of

**[18:16]** so, I think that in reality, kind of just going back to the trust piece, we

**[18:18]** just going back to the trust piece, we

**[18:18]** just going back to the trust piece, we get one chance to really make the

**[18:20]** get one chance to really make the

**[18:20]** get one chance to really make the machine feel like magic. And so, my my

**[18:23]** machine feel like magic. And so, my my

**[18:23]** machine feel like magic. And so, my my tip here is actually just like a very

**[18:25]** tip here is actually just like a very

**[18:26]** tip here is actually just like a very like kind of a tactical one, which is I

**[18:28]** like kind of a tactical one, which is I

**[18:28]** like kind of a tactical one, which is I think you need to surface delightfulness

**[18:30]** think you need to surface delightfulness

**[18:30]** think you need to surface delightfulness through agency and not trickery, right?

**[18:33]** through agency and not trickery, right?

**[18:33]** through agency and not trickery, right? where it's like the user has to feel

**[18:35]** where it's like the user has to feel

**[18:35]** where it's like the user has to feel like they are part of it that they are

**[18:37]** like they are part of it that they are

**[18:37]** like they are part of it that they are steering and it feels self-directed and

**[18:40]** steering and it feels self-directed and

**[18:40]** steering and it feels self-directed and that was one of the big things about

**[18:41]** that was one of the big things about

**[18:41]** that was one of the big things about notebookm which was like it wasn't like

**[18:43]** notebookm which was like it wasn't like

**[18:43]** notebookm which was like it wasn't like a random button right it was like I knew

**[18:45]** a random button right it was like I knew

**[18:45]** a random button right it was like I knew the specific document I had uploaded I

**[18:48]** the specific document I had uploaded I

**[18:48]** the specific document I had uploaded I knew that it was going to make something

**[18:49]** knew that it was going to make something

**[18:49]** knew that it was going to make something magical for me but it felt like equal

**[18:51]** magical for me but it felt like equal

**[18:51]** magical for me but it felt like equal parts me and the machine right it wasn't

**[18:53]** parts me and the machine right it wasn't

**[18:53]** parts me and the machine right it wasn't just the machine like it felt like there

**[18:55]** just the machine like it felt like there

**[18:55]** just the machine like it felt like there was like a healthy tension between there

**[18:57]** was like a healthy tension between there

**[18:57]** was like a healthy tension between there where the machine had a real opportunity

**[18:59]** where the machine had a real opportunity

**[18:59]** where the machine had a real opportunity to delight me


### [19:00 - 20:00]

**[19:02]** to delight me

**[19:02]** to delight me um I'm not going to show an example here

**[19:03]** um I'm not going to show an example here

**[19:03]** um I'm not going to show an example here in particular, but I want to make a

**[19:05]** in particular, but I want to make a

**[19:05]** in particular, but I want to make a point about delightfulness, which is it

**[19:07]** point about delightfulness, which is it

**[19:07]** point about delightfulness, which is it is actually really hard to delight

**[19:09]** is actually really hard to delight

**[19:09]** is actually really hard to delight people if you're doing too much

**[19:11]** people if you're doing too much

**[19:11]** people if you're doing too much right? And I really think that you're

**[19:13]** right? And I really think that you're

**[19:13]** right? And I really think that you're either shipping model capabilities or

**[19:15]** either shipping model capabilities or

**[19:15]** either shipping model capabilities or actual new outcomes. There is no real in

**[19:17]** actual new outcomes. There is no real in

**[19:17]** actual new outcomes. There is no real in between here. And this is where sort of

**[19:19]** between here. And this is where sort of

**[19:19]** between here. And this is where sort of like the stack will will come to kind of

**[19:21]** like the stack will will come to kind of

**[19:22]** like the stack will will come to kind of haunt you where do you know the outcome

**[19:24]** haunt you where do you know the outcome

**[19:24]** haunt you where do you know the outcome that you are optimizing for? Do you know

**[19:27]** that you are optimizing for? Do you know

**[19:27]** that you are optimizing for? Do you know how the user is supposed to get there?

**[19:28]** how the user is supposed to get there?

**[19:28]** how the user is supposed to get there? Do you know what is preventing users

**[19:30]** Do you know what is preventing users

**[19:30]** Do you know what is preventing users from getting there? you know, do you

**[19:32]** from getting there? you know, do you

**[19:32]** from getting there? you know, do you know how to show them what is possible

**[19:34]** know how to show them what is possible

**[19:34]** know how to show them what is possible with the system? And I think these are

**[19:36]** with the system? And I think these are

**[19:36]** with the system? And I think these are sort of like kind of deep gnarly

**[19:38]** sort of like kind of deep gnarly

**[19:38]** sort of like kind of deep gnarly questions and it's just like something

**[19:39]** questions and it's just like something

**[19:40]** questions and it's just like something that you will only get to by using the

**[19:41]** that you will only get to by using the

**[19:41]** that you will only get to by using the product a lot yourself. I think that

**[19:44]** product a lot yourself. I think that

**[19:44]** product a lot yourself. I think that that is the way to build a delightful

**[19:46]** that is the way to build a delightful

**[19:46]** that is the way to build a delightful product, right? Is to not test your

**[19:48]** product, right? Is to not test your

**[19:48]** product, right? Is to not test your product, but to sort of live and breathe

**[19:51]** product, but to sort of live and breathe

**[19:51]** product, but to sort of live and breathe it and and live the life of your users.

**[19:53]** it and and live the life of your users.

**[19:53]** it and and live the life of your users. Like who do you think is going to use

**[19:55]** Like who do you think is going to use

**[19:55]** Like who do you think is going to use this thing? Like if you are not that

**[19:57]** this thing? Like if you are not that

**[19:57]** this thing? Like if you are not that person then you have to become that

**[19:58]** person then you have to become that

**[19:58]** person then you have to become that person because that's the only way that


### [20:00 - 21:00]

**[20:00]** person because that's the only way that

**[20:00]** person because that's the only way that I think you can start to feel at the

**[20:02]** I think you can start to feel at the

**[20:02]** I think you can start to feel at the borders of what people are ready for and

**[20:04]** borders of what people are ready for and

**[20:04]** borders of what people are ready for and what the technology is capable of right

**[20:06]** what the technology is capable of right

**[20:06]** what the technology is capable of right I think I think that's ultimately like

**[20:08]** I think I think that's ultimately like

**[20:08]** I think I think that's ultimately like the the little trick to getting within

**[20:11]** the the little trick to getting within

**[20:11]** the the little trick to getting within that space and building something

**[20:13]** that space and building something

**[20:13]** that space and building something interesting

**[20:15]** interesting

**[20:15]** interesting okay finally I think that delight shows

**[20:20]** okay finally I think that delight shows

**[20:20]** okay finally I think that delight shows us what the product can do and what's

**[20:22]** us what the product can do and what's

**[20:22]** us what the product can do and what's magical about it but I think what a lot

**[20:25]** magical about it but I think what a lot

**[20:25]** magical about it but I think what a lot of people are not actually as judicious

**[20:27]** of people are not actually as judicious

**[20:27]** of people are not actually as judicious about is what it should do. Uh, and this

**[20:30]** about is what it should do. Uh, and this

**[20:30]** about is what it should do. Uh, and this is this is kind of like a weird piece of

**[20:32]** is this is kind of like a weird piece of

**[20:32]** is this is kind of like a weird piece of advice, especially because like I've

**[20:33]** advice, especially because like I've

**[20:33]** advice, especially because like I've made this mistake many many many times.

**[20:35]** made this mistake many many many times.

**[20:35]** made this mistake many many many times. Like I only say this from sort of the

**[20:37]** Like I only say this from sort of the

**[20:37]** Like I only say this from sort of the tried and tested experience of being a

**[20:39]** tried and tested experience of being a

**[20:39]** tried and tested experience of being a kitchen sink person, right? And we've

**[20:41]** kitchen sink person, right? And we've

**[20:41]** kitchen sink person, right? And we've all used products like this where uh

**[20:44]** all used products like this where uh

**[20:44]** all used products like this where uh when you look around you there's there's

**[20:45]** when you look around you there's there's

**[20:45]** when you look around you there's there's plenty of examples where it kind of

**[20:47]** plenty of examples where it kind of

**[20:47]** plenty of examples where it kind of feels like you have not shipped your POV

**[20:50]** feels like you have not shipped your POV

**[20:50]** feels like you have not shipped your POV on the world. you actually just shipped

**[20:52]** on the world. you actually just shipped

**[20:52]** on the world. you actually just shipped a kitchen sink of model capabilities

**[20:54]** a kitchen sink of model capabilities

**[20:54]** a kitchen sink of model capabilities with your slight flare on it, right?

**[20:55]** with your slight flare on it, right?

**[20:55]** with your slight flare on it, right? Like maybe you changed the color and

**[20:57]** Like maybe you changed the color and

**[20:57]** Like maybe you changed the color and that's kind of cool because you know I

**[20:59]** that's kind of cool because you know I

**[20:59]** that's kind of cool because you know I think like we're all still living in the


### [21:00 - 22:00]

**[21:01]** think like we're all still living in the

**[21:01]** think like we're all still living in the era of like research previews like it's

**[21:02]** era of like research previews like it's

**[21:02]** era of like research previews like it's cool to know what the models can do.

**[21:04]** cool to know what the models can do.

**[21:04]** cool to know what the models can do. Like it's ever increasing in capability

**[21:06]** Like it's ever increasing in capability

**[21:06]** Like it's ever increasing in capability but I think like to true end users like

**[21:08]** but I think like to true end users like

**[21:08]** but I think like to true end users like it's probably not that interesting,

**[21:10]** it's probably not that interesting,

**[21:10]** it's probably not that interesting, right? Because that is just chatgbt.

**[21:12]** right? Because that is just chatgbt.

**[21:12]** right? Because that is just chatgbt. Like I'll just use chat GBT. I don't

**[21:14]** Like I'll just use chat GBT. I don't

**[21:14]** Like I'll just use chat GBT. I don't think you're gonna do a better job than

**[21:16]** think you're gonna do a better job than

**[21:16]** think you're gonna do a better job than them. Um, and it's probably not right to

**[21:19]** them. Um, and it's probably not right to

**[21:19]** them. Um, and it's probably not right to jam everything in there and try to see

**[21:21]** jam everything in there and try to see

**[21:21]** jam everything in there and try to see what's sticking with who, right? So, the

**[21:24]** what's sticking with who, right? So, the

**[21:24]** what's sticking with who, right? So, the barrier to shipping, especially

**[21:26]** barrier to shipping, especially

**[21:26]** barrier to shipping, especially nowadays, it is not it's not about the

**[21:28]** nowadays, it is not it's not about the

**[21:28]** nowadays, it is not it's not about the capability, right? It's about judgment.

**[21:31]** capability, right? It's about judgment.

**[21:31]** capability, right? It's about judgment. And the thing that I try to ask myself

**[21:33]** And the thing that I try to ask myself

**[21:33]** And the thing that I try to ask myself is, you know, does this product respect

**[21:35]** is, you know, does this product respect

**[21:35]** is, you know, does this product respect user time, data, and agency? Because I

**[21:39]** user time, data, and agency? Because I

**[21:39]** user time, data, and agency? Because I really believe that restraint in

**[21:42]** really believe that restraint in

**[21:42]** really believe that restraint in particular, right, this is a new

**[21:44]** particular, right, this is a new

**[21:44]** particular, right, this is a new innovation multiplier. Like if you

**[21:47]** innovation multiplier. Like if you

**[21:47]** innovation multiplier. Like if you yourself have that personal clarity, you

**[21:49]** yourself have that personal clarity, you

**[21:49]** yourself have that personal clarity, you have that purpose, and you are focused,

**[21:51]** have that purpose, and you are focused,

**[21:51]** have that purpose, and you are focused, you're driven, you're resilient, like

**[21:52]** you're driven, you're resilient, like

**[21:52]** you're driven, you're resilient, like 100%. People are going to tell you stuff

**[21:54]** 100%. People are going to tell you stuff

**[21:54]** 100%. People are going to tell you stuff like, "Well, this is like the simplest

**[21:56]** like, "Well, this is like the simplest

**[21:56]** like, "Well, this is like the simplest thing ever. How do you aim to compete?"

**[21:59]** thing ever. How do you aim to compete?"

**[21:59]** thing ever. How do you aim to compete?" Well, exactly. By being focused, right?


### [22:00 - 23:00]

**[22:01]** Well, exactly. By being focused, right?

**[22:01]** Well, exactly. By being focused, right? By doing one thing incredibly reasonably

**[22:03]** By doing one thing incredibly reasonably

**[22:03]** By doing one thing incredibly reasonably well. And you will get to a point where

**[22:05]** well. And you will get to a point where

**[22:05]** well. And you will get to a point where the thing is so excellent that you are

**[22:07]** the thing is so excellent that you are

**[22:07]** the thing is so excellent that you are beginning to really delight people. Like

**[22:10]** beginning to really delight people. Like

**[22:10]** beginning to really delight people. Like you will have more of an intuition about

**[22:12]** you will have more of an intuition about

**[22:12]** you will have more of an intuition about the borders that I was talking about in

**[22:14]** the borders that I was talking about in

**[22:14]** the borders that I was talking about in the previous slide.

**[22:15]** the previous slide.

**[22:16]** the previous slide. I think one last note I'll say on

**[22:17]** I think one last note I'll say on

**[22:17]** I think one last note I'll say on delightfulness is that I mean on the

**[22:19]** delightfulness is that I mean on the

**[22:20]** delightfulness is that I mean on the kitchen sink is that users are not that

**[22:23]** kitchen sink is that users are not that

**[22:23]** kitchen sink is that users are not that different from you or me right like we

**[22:25]** different from you or me right like we

**[22:25]** different from you or me right like we are all users of something and so think

**[22:27]** are all users of something and so think

**[22:27]** are all users of something and so think about the last time you tried something

**[22:28]** about the last time you tried something

**[22:28]** about the last time you tried something new like think about how much patience

**[22:30]** new like think about how much patience

**[22:30]** new like think about how much patience you had for it and think about how

**[22:32]** you had for it and think about how

**[22:32]** you had for it and think about how annoying it was when you tried it and

**[22:34]** annoying it was when you tried it and

**[22:34]** annoying it was when you tried it and you're like I just don't know what I

**[22:35]** you're like I just don't know what I

**[22:35]** you're like I just don't know what I would do with this thing like it does

**[22:37]** would do with this thing like it does

**[22:37]** would do with this thing like it does like 30 things but I don't know when I

**[22:38]** like 30 things but I don't know when I

**[22:38]** like 30 things but I don't know when I would use it right and that's just like

**[22:41]** would use it right and that's just like

**[22:41]** would use it right and that's just like what happens when you sort of let the

**[22:42]** what happens when you sort of let the

**[22:42]** what happens when you sort of let the chaos overwhelm you and you're not clear

**[22:45]** chaos overwhelm you and you're not clear

**[22:45]** chaos overwhelm you and you're not clear about what the whole point of like your

**[22:47]** about what the whole point of like your

**[22:48]** about what the whole point of like your thing is, right? And that that comes

**[22:50]** thing is, right? And that that comes

**[22:50]** thing is, right? And that that comes that comes from a place that I think is

**[22:52]** that comes from a place that I think is

**[22:52]** that comes from a place that I think is like the entire stack. Like if you

**[22:54]** like the entire stack. Like if you

**[22:54]** like the entire stack. Like if you yourself don't know what you're trying

**[22:56]** yourself don't know what you're trying

**[22:56]** yourself don't know what you're trying to do with yourself, then you don't know

**[22:58]** to do with yourself, then you don't know

**[22:58]** to do with yourself, then you don't know what to do with your product. Then you

**[22:59]** what to do with your product. Then you


### [23:00 - 24:00]

**[23:00]** what to do with your product. Then you don't know which model capabilities are

**[23:01]** don't know which model capabilities are

**[23:01]** don't know which model capabilities are actually useful, you know, in the

**[23:03]** actually useful, you know, in the

**[23:03]** actually useful, you know, in the context of your outcome, and you end up

**[23:05]** context of your outcome, and you end up

**[23:05]** context of your outcome, and you end up with a kitchen sink, which is not great.

**[23:07]** with a kitchen sink, which is not great.

**[23:07]** with a kitchen sink, which is not great. It's not a great experience. This

**[23:09]** It's not a great experience. This

**[23:10]** It's not a great experience. This actually happened to me recently. This

**[23:11]** actually happened to me recently. This

**[23:11]** actually happened to me recently. This is Hux. Um, uh, I don't know. I I mean I

**[23:15]** is Hux. Um, uh, I don't know. I I mean I

**[23:15]** is Hux. Um, uh, I don't know. I I mean I do know actually, but we ended up in a

**[23:17]** do know actually, but we ended up in a

**[23:17]** do know actually, but we ended up in a place where we had an app that did all

**[23:19]** place where we had an app that did all

**[23:19]** place where we had an app that did all these things. And I was like, it's so

**[23:22]** these things. And I was like, it's so

**[23:22]** these things. And I was like, it's so beautiful. Okay, it does this thing. You

**[23:24]** beautiful. Okay, it does this thing. You

**[23:24]** beautiful. Okay, it does this thing. You can chat with it. You can make podcasts.

**[23:26]** can chat with it. You can make podcasts.

**[23:26]** can chat with it. You can make podcasts. You can read the news. It generates

**[23:28]** You can read the news. It generates

**[23:28]** You can read the news. It generates images. It generates videos. I was so

**[23:30]** images. It generates videos. I was so

**[23:30]** images. It generates videos. I was so excited. It was like my dream product

**[23:33]** excited. It was like my dream product

**[23:34]** excited. It was like my dream product until it wasn't because then I started

**[23:36]** until it wasn't because then I started

**[23:36]** until it wasn't because then I started using it every day. And I'm like, whoa,

**[23:38]** using it every day. And I'm like, whoa,

**[23:38]** using it every day. And I'm like, whoa, I don't really use any of this. I just

**[23:39]** I don't really use any of this. I just

**[23:40]** I don't really use any of this. I just use one thing. And we gave it to a bunch

**[23:42]** use one thing. And we gave it to a bunch

**[23:42]** use one thing. And we gave it to a bunch of users. give it to several hundred

**[23:43]** of users. give it to several hundred

**[23:43]** of users. give it to several hundred people and they also just used one thing

**[23:46]** people and they also just used one thing

**[23:46]** people and they also just used one thing in the product and I was like well you

**[23:48]** in the product and I was like well you

**[23:48]** in the product and I was like well you know I think in real life people only

**[23:50]** know I think in real life people only

**[23:50]** know I think in real life people only have the bandwidth to sort of be like

**[23:52]** have the bandwidth to sort of be like

**[23:52]** have the bandwidth to sort of be like this is my one thing right like I'm sure

**[23:54]** this is my one thing right like I'm sure

**[23:54]** this is my one thing right like I'm sure Spotify does a lot of things but I still

**[23:56]** Spotify does a lot of things but I still

**[23:56]** Spotify does a lot of things but I still use it for one thing which is to play

**[23:57]** use it for one thing which is to play

**[23:58]** use it for one thing which is to play music I don't know what else it really

**[23:59]** music I don't know what else it really

**[23:59]** music I don't know what else it really does right I'm sure like it's a huge


### [24:00 - 25:00]

**[24:01]** does right I'm sure like it's a huge

**[24:01]** does right I'm sure like it's a huge team it's like a bajillion dollar

**[24:02]** team it's like a bajillion dollar

**[24:02]** team it's like a bajillion dollar industry but that's what it does and so

**[24:05]** industry but that's what it does and so

**[24:05]** industry but that's what it does and so when we were working on Hux I'm like

**[24:06]** when we were working on Hux I'm like

**[24:06]** when we were working on Hux I'm like whoa how crazy oh I forgot it does chat

**[24:09]** whoa how crazy oh I forgot it does chat

**[24:09]** whoa how crazy oh I forgot it does chat too which is wild except I made it like

**[24:11]** too which is wild except I made it like

**[24:11]** too which is wild except I made it like really goofy instead of Chach GPT. It's

**[24:13]** really goofy instead of Chach GPT. It's

**[24:13]** really goofy instead of Chach GPT. It's just crazy. But I think like to look at

**[24:16]** just crazy. But I think like to look at

**[24:16]** just crazy. But I think like to look at this product now and to see sort of like

**[24:18]** this product now and to see sort of like

**[24:18]** this product now and to see sort of like the lack of focus in the product

**[24:19]** the lack of focus in the product

**[24:19]** the lack of focus in the product direction, it's like, hey, this has a

**[24:21]** direction, it's like, hey, this has a

**[24:21]** direction, it's like, hey, this has a little bit of like that demo disease,

**[24:22]** little bit of like that demo disease,

**[24:22]** little bit of like that demo disease, right? Where it looks cool, but in real

**[24:25]** right? Where it looks cool, but in real

**[24:25]** right? Where it looks cool, but in real life, like nobody's going to love that

**[24:26]** life, like nobody's going to love that

**[24:26]** life, like nobody's going to love that thing. And so I just want to reiterate

**[24:29]** thing. And so I just want to reiterate

**[24:29]** thing. And so I just want to reiterate kind of the message here, which is

**[24:30]** kind of the message here, which is

**[24:30]** kind of the message here, which is clarity is what is going to give you the

**[24:32]** clarity is what is going to give you the

**[24:32]** clarity is what is going to give you the energy for the job. And the job is hard,

**[24:34]** energy for the job. And the job is hard,

**[24:34]** energy for the job. And the job is hard, so you're going to need lots of that.

**[24:36]** so you're going to need lots of that.

**[24:36]** so you're going to need lots of that. Purpose is what keeps us focused on it

**[24:39]** Purpose is what keeps us focused on it

**[24:39]** Purpose is what keeps us focused on it and makes sure that we know what outcome

**[24:41]** and makes sure that we know what outcome

**[24:41]** and makes sure that we know what outcome we are marching towards. And it is the

**[24:44]** we are marching towards. And it is the

**[24:44]** we are marching towards. And it is the trust in that purpose that's going to

**[24:46]** trust in that purpose that's going to

**[24:46]** trust in that purpose that's going to earn us the belief, right, of our users.

**[24:49]** earn us the belief, right, of our users.

**[24:49]** earn us the belief, right, of our users. And the belief is what's going to get us

**[24:51]** And the belief is what's going to get us

**[24:51]** And the belief is what's going to get us to a place where we have an opportunity

**[24:53]** to a place where we have an opportunity

**[24:53]** to a place where we have an opportunity to delight, right? And that delight is

**[24:55]** to delight, right? And that delight is

**[24:55]** to delight, right? And that delight is going to prove potential. And the

**[24:57]** going to prove potential. And the

**[24:57]** going to prove potential. And the kitchen sink is just like a checks and

**[24:58]** kitchen sink is just like a checks and

**[24:58]** kitchen sink is just like a checks and balances kind of a thing. And it keeps


### [25:00 - 26:00]

**[25:00]** balances kind of a thing. And it keeps

**[25:00]** balances kind of a thing. And it keeps us honest and focused about whether or

**[25:02]** us honest and focused about whether or

**[25:02]** us honest and focused about whether or not meeting the first four. And that's

**[25:05]** not meeting the first four. And that's

**[25:05]** not meeting the first four. And that's how I bu I believe that we build

**[25:07]** how I bu I believe that we build

**[25:07]** how I bu I believe that we build something that isn't ugly. Thank you.


