# Why your product needs an AI product manager, and why it should be you — James Lowe, i.AI

**Video URL:** https://www.youtube.com/watch?v=xzJdSi2Tsqw

---

## Full Transcript

### [00:00 - 01:00]

**[00:18]** Hi everyone. Thanks for that welcome.

**[00:18]** Hi everyone. Thanks for that welcome. Uh, as you just heard, my name is James

**[00:20]** Uh, as you just heard, my name is James

**[00:20]** Uh, as you just heard, my name is James Low. I'm head of AI engineering at the

**[00:21]** Low. I'm head of AI engineering at the

**[00:22]** Low. I'm head of AI engineering at the Incubator for AI. We're a small team of

**[00:25]** Incubator for AI. We're a small team of

**[00:25]** Incubator for AI. We're a small team of experts uh, in the UK government. We

**[00:27]** experts uh, in the UK government. We

**[00:27]** experts uh, in the UK government. We were created by 10 Downing Street to

**[00:30]** were created by 10 Downing Street to

**[00:30]** were created by 10 Downing Street to deliver public good using AI and we do

**[00:33]** deliver public good using AI and we do

**[00:33]** deliver public good using AI and we do that via experimentation and product

**[00:35]** that via experimentation and product

**[00:35]** that via experimentation and product building.

**[00:37]** building.

**[00:37]** building. The UK government delivers uh for its

**[00:39]** The UK government delivers uh for its

**[00:39]** The UK government delivers uh for its citizens. It spends over a trillion

**[00:42]** citizens. It spends over a trillion

**[00:42]** citizens. It spends over a trillion pounds delivering for its over 70

**[00:44]** pounds delivering for its over 70

**[00:44]** pounds delivering for its over 70 million citizens. So there's a lot to

**[00:46]** million citizens. So there's a lot to

**[00:46]** million citizens. So there's a lot to play for. At the incubator for AI, uh we

**[00:51]** play for. At the incubator for AI, uh we

**[00:51]** play for. At the incubator for AI, uh we deliver products that uh

**[00:55]** deliver products that uh

**[00:55]** deliver products that uh uh a wide range of products all the way

**[00:57]** uh a wide range of products all the way

**[00:57]** uh a wide range of products all the way from frontline services all the way up


### [01:00 - 02:00]

**[01:00]** from frontline services all the way up

**[01:00]** from frontline services all the way up to the prime minister's meetings.

**[01:04]** to the prime minister's meetings.

**[01:04]** to the prime minister's meetings. This remmit is very wide. Uh and so

**[01:06]** This remmit is very wide. Uh and so

**[01:06]** This remmit is very wide. Uh and so we've had to get quite good at deciding

**[01:08]** we've had to get quite good at deciding

**[01:08]** we've had to get quite good at deciding what we should build and that is what

**[01:10]** what we should build and that is what

**[01:10]** what we should build and that is what I'm here to talk to you about today.

**[01:17]** I'm going to start with a post from

**[01:17]** I'm going to start with a post from Andrew Ing.

**[01:19]** Andrew Ing.

**[01:19]** Andrew Ing. He says, "Writing software, especially

**[01:21]** He says, "Writing software, especially

**[01:21]** He says, "Writing software, especially prototypes, is becoming cheaper. This is

**[01:25]** prototypes, is becoming cheaper. This is

**[01:25]** prototypes, is becoming cheaper. This is not just because of AI coding agents and

**[01:27]** not just because of AI coding agents and

**[01:27]** not just because of AI coding agents and assistants, but also because AI features

**[01:29]** assistants, but also because AI features

**[01:29]** assistants, but also because AI features in products uh make the previously

**[01:32]** in products uh make the previously

**[01:32]** in products uh make the previously impossible possible."

**[01:35]** impossible possible."

**[01:35]** impossible possible." He says this will lead to increased

**[01:37]** He says this will lead to increased

**[01:37]** He says this will lead to increased demand for people who can decide what to

**[01:39]** demand for people who can decide what to

**[01:39]** demand for people who can decide what to build.

**[01:41]** build.

**[01:41]** build. AI product management has a bright

**[01:43]** AI product management has a bright

**[01:43]** AI product management has a bright future.

**[01:44]** future.

**[01:44]** future. In this talk, I'm going to build on this

**[01:46]** In this talk, I'm going to build on this

**[01:46]** In this talk, I'm going to build on this post and I'm going to make the case for

**[01:47]** post and I'm going to make the case for

**[01:47]** post and I'm going to make the case for the AI product manager. I'm going to

**[01:50]** the AI product manager. I'm going to

**[01:50]** the AI product manager. I'm going to argue that AI expertise is really

**[01:53]** argue that AI expertise is really

**[01:53]** argue that AI expertise is really important for this role. I'm going to

**[01:55]** important for this role. I'm going to

**[01:55]** important for this role. I'm going to deliver three hardearned lessons from

**[01:58]** deliver three hardearned lessons from

**[01:58]** deliver three hardearned lessons from the incubator for AI.


### [02:00 - 03:00]

**[02:00]** the incubator for AI.

**[02:00]** the incubator for AI. So, I hope that whether you're uh a

**[02:03]** So, I hope that whether you're uh a

**[02:03]** So, I hope that whether you're uh a product manager, whether you're an AI

**[02:05]** product manager, whether you're an AI

**[02:05]** product manager, whether you're an AI engineer, or whether you're a founder,

**[02:07]** engineer, or whether you're a founder,

**[02:07]** engineer, or whether you're a founder, uh there's going to be a lot for you to

**[02:10]** uh there's going to be a lot for you to

**[02:10]** uh there's going to be a lot for you to learn from these lessons and help you

**[02:11]** learn from these lessons and help you

**[02:11]** learn from these lessons and help you build great AI products.

**[02:17]** Before I talk about AI product

**[02:17]** Before I talk about AI product management, I'm going to quickly recap

**[02:18]** management, I'm going to quickly recap

**[02:18]** management, I'm going to quickly recap product management. This is an extremely

**[02:21]** product management. This is an extremely

**[02:21]** product management. This is an extremely rich field, so I'm only going to skin

**[02:22]** rich field, so I'm only going to skin

**[02:22]** rich field, so I'm only going to skin the surface here.

**[02:25]** the surface here.

**[02:25]** the surface here. Product management can be thought of as

**[02:27]** Product management can be thought of as

**[02:27]** Product management can be thought of as the intersect between these three

**[02:28]** the intersect between these three

**[02:28]** the intersect between these three important areas. We have the business.

**[02:31]** important areas. We have the business.

**[02:31]** important areas. We have the business. Is your product viable? For example, is

**[02:34]** Is your product viable? For example, is

**[02:34]** Is your product viable? For example, is it going to be profitable? We have the

**[02:36]** it going to be profitable? We have the

**[02:36]** it going to be profitable? We have the technology. Is your product feasible?

**[02:39]** technology. Is your product feasible?

**[02:39]** technology. Is your product feasible? For example, do we have the right skills

**[02:41]** For example, do we have the right skills

**[02:41]** For example, do we have the right skills on the team? And we have users. Most

**[02:44]** on the team? And we have users. Most

**[02:44]** on the team? And we have users. Most importantly of all, is your product

**[02:46]** importantly of all, is your product

**[02:46]** importantly of all, is your product desirable? What problem are you solving

**[02:48]** desirable? What problem are you solving

**[02:48]** desirable? What problem are you solving for your users? A product manager sits

**[02:51]** for your users? A product manager sits

**[02:51]** for your users? A product manager sits at the intercept of these three areas

**[02:53]** at the intercept of these three areas

**[02:53]** at the intercept of these three areas and has to balance them all to find the

**[02:55]** and has to balance them all to find the

**[02:55]** and has to balance them all to find the right path forward for the product.

**[02:57]** right path forward for the product.

**[02:57]** right path forward for the product. Then AI comes along and makes the whole


### [03:00 - 04:00]

**[03:00]** Then AI comes along and makes the whole

**[03:00]** Then AI comes along and makes the whole process a bit more complicated and a bit

**[03:01]** process a bit more complicated and a bit

**[03:01]** process a bit more complicated and a bit messier.

**[03:03]** messier.

**[03:03]** messier. It intersects with each of these areas

**[03:05]** It intersects with each of these areas

**[03:05]** It intersects with each of these areas in slightly different ways. For example,

**[03:07]** in slightly different ways. For example,

**[03:07]** in slightly different ways. For example, for the business, is your business happy

**[03:09]** for the business, is your business happy

**[03:09]** for the business, is your business happy with the fact that for AI products, a

**[03:12]** with the fact that for AI products, a

**[03:12]** with the fact that for AI products, a higher amount of experimentation uh is

**[03:14]** higher amount of experimentation uh is

**[03:14]** higher amount of experimentation uh is needed and there's a higher chance of

**[03:15]** needed and there's a higher chance of

**[03:16]** needed and there's a higher chance of failure

**[03:18]** failure

**[03:18]** failure for technology. How do you evaluate and

**[03:20]** for technology. How do you evaluate and

**[03:20]** for technology. How do you evaluate and monitor the performance of your AI?

**[03:23]** monitor the performance of your AI?

**[03:23]** monitor the performance of your AI? And for users, how should you handle the

**[03:25]** And for users, how should you handle the

**[03:25]** And for users, how should you handle the probabilistic nature of AI? In

**[03:27]** probabilistic nature of AI? In

**[03:27]** probabilistic nature of AI? In particular, will it work for your users?

**[03:29]** particular, will it work for your users?

**[03:29]** particular, will it work for your users? What guard rails do you need? And how do

**[03:31]** What guard rails do you need? And how do

**[03:31]** What guard rails do you need? And how do you build human in the loop? And for AI

**[03:34]** you build human in the loop? And for AI

**[03:34]** you build human in the loop? And for AI products sitting right in the middle of

**[03:35]** products sitting right in the middle of

**[03:35]** products sitting right in the middle of all of this, we have a big question. Is

**[03:37]** all of this, we have a big question. Is

**[03:37]** all of this, we have a big question. Is what you're doing even possible?

**[03:40]** what you're doing even possible?

**[03:40]** what you're doing even possible? An AI product manager has to resolve all

**[03:42]** An AI product manager has to resolve all

**[03:42]** An AI product manager has to resolve all of these different areas to find the

**[03:44]** of these different areas to find the

**[03:44]** of these different areas to find the right path forward.

**[03:47]** right path forward.

**[03:47]** right path forward. A lot of the existing product manager

**[03:48]** A lot of the existing product manager

**[03:48]** A lot of the existing product manager skills skill set is still very

**[03:50]** skills skill set is still very

**[03:50]** skills skill set is still very important, but now there is an increased

**[03:52]** important, but now there is an increased

**[03:52]** important, but now there is an increased importance in things like data and AI

**[03:54]** importance in things like data and AI

**[03:54]** importance in things like data and AI proficiency. AI product managers need to

**[03:57]** proficiency. AI product managers need to

**[03:57]** proficiency. AI product managers need to understand the importance of data, the


### [04:00 - 05:00]

**[04:00]** understand the importance of data, the

**[04:00]** understand the importance of data, the necessity of evaluation, and how to deal

**[04:02]** necessity of evaluation, and how to deal

**[04:02]** necessity of evaluation, and how to deal with the probabilistic nature of AI.

**[04:11]** whether you're uh what what that

**[04:11]** whether you're uh what what that essentially means for you is uh if

**[04:13]** essentially means for you is uh if

**[04:13]** essentially means for you is uh if you're a product person in this room, if

**[04:14]** you're a product person in this room, if

**[04:14]** you're a product person in this room, if you're a product manager, is the

**[04:15]** you're a product manager, is the

**[04:15]** you're a product manager, is the importance of upskilling in AI. But what

**[04:17]** importance of upskilling in AI. But what

**[04:17]** importance of upskilling in AI. But what it also means is if you're an AI

**[04:20]** it also means is if you're an AI

**[04:20]** it also means is if you're an AI engineer or someone more technical, that

**[04:22]** engineer or someone more technical, that

**[04:22]** engineer or someone more technical, that actually that is a good background also

**[04:24]** actually that is a good background also

**[04:24]** actually that is a good background also to go into the product manager space as

**[04:26]** to go into the product manager space as

**[04:26]** to go into the product manager space as well. And just to be clear, when I talk

**[04:28]** well. And just to be clear, when I talk

**[04:28]** well. And just to be clear, when I talk about the product manager space, I

**[04:30]** about the product manager space, I

**[04:30]** about the product manager space, I actually think of this as more of a

**[04:31]** actually think of this as more of a

**[04:31]** actually think of this as more of a mindset than like a specific role you

**[04:33]** mindset than like a specific role you

**[04:33]** mindset than like a specific role you need on your team. What's really

**[04:35]** need on your team. What's really

**[04:35]** need on your team. What's really important is that you have someone on

**[04:36]** important is that you have someone on

**[04:36]** important is that you have someone on your team that is grappling with these

**[04:38]** your team that is grappling with these

**[04:38]** your team that is grappling with these four areas in order to find the path

**[04:40]** four areas in order to find the path

**[04:40]** four areas in order to find the path forward.

**[04:42]** forward.

**[04:42]** forward. As Brett Taylor said on a recent episode

**[04:44]** As Brett Taylor said on a recent episode

**[04:44]** As Brett Taylor said on a recent episode of the latent space podcast, there is a

**[04:46]** of the latent space podcast, there is a

**[04:46]** of the latent space podcast, there is a lot of power in combining product and

**[04:48]** lot of power in combining product and

**[04:48]** lot of power in combining product and engineering into as few people as

**[04:50]** engineering into as few people as

**[04:50]** engineering into as few people as possible. Few great things have been

**[04:51]** possible. Few great things have been

**[04:51]** possible. Few great things have been created by committee and that's exactly

**[04:53]** created by committee and that's exactly

**[04:53]** created by committee and that's exactly the point that we're stressing here.

**[04:56]** the point that we're stressing here.

**[04:56]** the point that we're stressing here. So, I hope you feel uh excited by the

**[04:59]** So, I hope you feel uh excited by the

**[04:59]** So, I hope you feel uh excited by the prospect of of adopting that AI product


### [05:00 - 06:00]

**[05:02]** prospect of of adopting that AI product

**[05:02]** prospect of of adopting that AI product manager mindset. And the question now is

**[05:04]** manager mindset. And the question now is

**[05:04]** manager mindset. And the question now is what lessons can you learn from the

**[05:05]** what lessons can you learn from the

**[05:06]** what lessons can you learn from the incubator for AI?

**[05:08]** incubator for AI?

**[05:08]** incubator for AI? The first lesson is going to come from

**[05:09]** The first lesson is going to come from

**[05:10]** The first lesson is going to come from our project called consult and it's

**[05:11]** our project called consult and it's

**[05:11]** our project called consult and it's going to be all about evaluating AI

**[05:13]** going to be all about evaluating AI

**[05:13]** going to be all about evaluating AI early.

**[05:15]** early.

**[05:15]** early. Every time the government wants to

**[05:16]** Every time the government wants to

**[05:16]** Every time the government wants to undertake a really big policy change,

**[05:18]** undertake a really big policy change,

**[05:18]** undertake a really big policy change, they need to and want to get input from

**[05:20]** they need to and want to get input from

**[05:20]** they need to and want to get input from the public and in fact they have a legal

**[05:22]** the public and in fact they have a legal

**[05:22]** the public and in fact they have a legal duty to do so. They do this via

**[05:25]** duty to do so. They do this via

**[05:25]** duty to do so. They do this via consultations which are essentially

**[05:27]** consultations which are essentially

**[05:27]** consultations which are essentially large uh surveys with free text

**[05:29]** large uh surveys with free text

**[05:29]** large uh surveys with free text responses.

**[05:31]** responses.

**[05:31]** responses. They run hundreds of these a year and

**[05:33]** They run hundreds of these a year and

**[05:33]** They run hundreds of these a year and some of these attract hundreds of

**[05:35]** some of these attract hundreds of

**[05:35]** some of these attract hundreds of thousands of responses.

**[05:37]** thousands of responses.

**[05:38]** thousands of responses. Analyzing these responses can take

**[05:39]** Analyzing these responses can take

**[05:39]** Analyzing these responses can take months and cost millions of pounds.

**[05:43]** months and cost millions of pounds.

**[05:43]** months and cost millions of pounds. This is a prototypical use case for AI,

**[05:45]** This is a prototypical use case for AI,

**[05:45]** This is a prototypical use case for AI, but when we started this project 18

**[05:47]** but when we started this project 18

**[05:47]** but when we started this project 18 months ago, we weren't sure exactly what

**[05:49]** months ago, we weren't sure exactly what

**[05:49]** months ago, we weren't sure exactly what path to take.

**[05:51]** path to take.

**[05:51]** path to take. You see, there was already precedent for

**[05:53]** You see, there was already precedent for

**[05:53]** You see, there was already precedent for using natural language programming uh

**[05:55]** using natural language programming uh

**[05:55]** using natural language programming uh techniques such as BERT topic to analyze

**[05:57]** techniques such as BERT topic to analyze

**[05:57]** techniques such as BERT topic to analyze consultations and we were under a large


### [06:00 - 07:00]

**[06:00]** consultations and we were under a large

**[06:00]** consultations and we were under a large amount of pressure to start delivering.

**[06:03]** amount of pressure to start delivering.

**[06:03]** amount of pressure to start delivering. So we made the mistake of going straight

**[06:04]** So we made the mistake of going straight

**[06:04]** So we made the mistake of going straight into product building mode.

**[06:07]** into product building mode.

**[06:07]** into product building mode. What we did is we built a product around

**[06:09]** What we did is we built a product around

**[06:09]** What we did is we built a product around those existing uh techniques. Uh but

**[06:13]** those existing uh techniques. Uh but

**[06:13]** those existing uh techniques. Uh but what we found is once we started testing

**[06:14]** what we found is once we started testing

**[06:14]** what we found is once we started testing with real users, we found that the

**[06:16]** with real users, we found that the

**[06:16]** with real users, we found that the results were uh inaccurate. they were

**[06:19]** results were uh inaccurate. they were

**[06:19]** results were uh inaccurate. they were inconsistent and they not only didn't

**[06:21]** inconsistent and they not only didn't

**[06:21]** inconsistent and they not only didn't meet user needs but wouldn't have passed

**[06:22]** meet user needs but wouldn't have passed

**[06:22]** meet user needs but wouldn't have passed the very high legal threshold that we

**[06:25]** the very high legal threshold that we

**[06:25]** the very high legal threshold that we needed to pass. So we went back to the

**[06:27]** needed to pass. So we went back to the

**[06:27]** needed to pass. So we went back to the drawing board and instead prioritized

**[06:29]** drawing board and instead prioritized

**[06:29]** drawing board and instead prioritized the AI capability first.

**[06:32]** the AI capability first.

**[06:32]** the AI capability first. We got data from real users and

**[06:34]** We got data from real users and

**[06:34]** We got data from real users and generated synthetic data to create eval

**[06:36]** generated synthetic data to create eval

**[06:36]** generated synthetic data to create eval which we optimized against. And then we

**[06:39]** which we optimized against. And then we

**[06:39]** which we optimized against. And then we started testing the outputs as well with

**[06:41]** started testing the outputs as well with

**[06:41]** started testing the outputs as well with real users and we developed that into a

**[06:44]** real users and we developed that into a

**[06:44]** real users and we developed that into a package which we call themefinder which

**[06:46]** package which we call themefinder which

**[06:46]** package which we call themefinder which has now been open source that other

**[06:47]** has now been open source that other

**[06:47]** has now been open source that other people can benefit from it.

**[06:50]** people can benefit from it.

**[06:50]** people can benefit from it. What we found was that the output of

**[06:51]** What we found was that the output of

**[06:51]** What we found was that the output of this package was not only comparable to

**[06:53]** this package was not only comparable to

**[06:53]** this package was not only comparable to what humans were doing but it was a

**[06:55]** what humans were doing but it was a

**[06:55]** what humans were doing but it was a thousand times faster and 400 times

**[06:57]** thousand times faster and 400 times

**[06:57]** thousand times faster and 400 times cheaper.

**[06:59]** cheaper.

**[06:59]** cheaper. Most importantly of all, by prioritizing


### [07:00 - 08:00]

**[07:01]** Most importantly of all, by prioritizing

**[07:01]** Most importantly of all, by prioritizing the AI capability, what we found was the

**[07:04]** the AI capability, what we found was the

**[07:04]** the AI capability, what we found was the key points in the package in the

**[07:06]** key points in the package in the

**[07:06]** key points in the package in the pipeline where human input and human in

**[07:09]** pipeline where human input and human in

**[07:09]** pipeline where human input and human in the loop was really valuable. That meant

**[07:11]** the loop was really valuable. That meant

**[07:11]** the loop was really valuable. That meant the product that the product that we

**[07:13]** the product that the product that we

**[07:13]** the product that the product that we then went on to build was actually

**[07:14]** then went on to build was actually

**[07:14]** then went on to build was actually different from the one we originally

**[07:16]** different from the one we originally

**[07:16]** different from the one we originally envisioned.

**[07:17]** envisioned.

**[07:17]** envisioned. That shows that starting with the AI

**[07:19]** That shows that starting with the AI

**[07:19]** That shows that starting with the AI capability and getting that right not

**[07:21]** capability and getting that right not

**[07:21]** capability and getting that right not only means you don't waste time building

**[07:23]** only means you don't waste time building

**[07:23]** only means you don't waste time building something that's not possible, but also

**[07:25]** something that's not possible, but also

**[07:25]** something that's not possible, but also don't waste time building the wrong

**[07:27]** don't waste time building the wrong

**[07:27]** don't waste time building the wrong product.

**[07:29]** product.

**[07:29]** product. We've now taken this and we've been

**[07:31]** We've now taken this and we've been

**[07:31]** We've now taken this and we've been evaluating it on live consultations. Uh

**[07:35]** evaluating it on live consultations. Uh

**[07:35]** evaluating it on live consultations. Uh and um it leads us very nicely to our

**[07:39]** and um it leads us very nicely to our

**[07:39]** and um it leads us very nicely to our first lesson which is resolve AI

**[07:41]** first lesson which is resolve AI

**[07:42]** first lesson which is resolve AI uncertainties early on with evaluations

**[07:43]** uncertainties early on with evaluations

**[07:43]** uncertainties early on with evaluations and tests with real users.

**[07:49]** With that with those live consultations,

**[07:49]** With that with those live consultations, we've been creating uh evaluations which

**[07:51]** we've been creating uh evaluations which

**[07:51]** we've been creating uh evaluations which we've actually published and our first

**[07:53]** we've actually published and our first

**[07:53]** we've actually published and our first one of those even made its way onto the

**[07:55]** one of those even made its way onto the

**[07:55]** one of those even made its way onto the BBC front page.


### [08:00 - 09:00]

**[08:01]** I'm going to take us on to another

**[08:01]** I'm going to take us on to another product now for our second lesson. That

**[08:03]** product now for our second lesson. That

**[08:03]** product now for our second lesson. That product is our AI transcription tool

**[08:05]** product is our AI transcription tool

**[08:05]** product is our AI transcription tool called Minute. And uh the lesson's all

**[08:07]** called Minute. And uh the lesson's all

**[08:07]** called Minute. And uh the lesson's all about going wide with features.

**[08:10]** about going wide with features.

**[08:10]** about going wide with features. There are many use cases in the

**[08:12]** There are many use cases in the

**[08:12]** There are many use cases in the government where secure AI transcription

**[08:15]** government where secure AI transcription

**[08:15]** government where secure AI transcription and summarization could be

**[08:17]** and summarization could be

**[08:17]** and summarization could be transformational.

**[08:19]** transformational.

**[08:19]** transformational. There are many places where frontline

**[08:20]** There are many places where frontline

**[08:20]** There are many places where frontline staff, for example, are spending time

**[08:23]** staff, for example, are spending time

**[08:23]** staff, for example, are spending time away from the job that they want to do

**[08:24]** away from the job that they want to do

**[08:24]** away from the job that they want to do to do uh administration and filling

**[08:27]** to do uh administration and filling

**[08:27]** to do uh administration and filling filling in paperwork and forms, for

**[08:28]** filling in paperwork and forms, for

**[08:28]** filling in paperwork and forms, for example.

**[08:31]** example.

**[08:31]** example. There's also uh very good existing

**[08:34]** There's also uh very good existing

**[08:34]** There's also uh very good existing off-the-shelf solutions

**[08:36]** off-the-shelf solutions

**[08:36]** off-the-shelf solutions such as the AWS and Azure transcription

**[08:38]** such as the AWS and Azure transcription

**[08:38]** such as the AWS and Azure transcription services. So for this product, the

**[08:41]** services. So for this product, the

**[08:41]** services. So for this product, the question was more about how do you

**[08:43]** question was more about how do you

**[08:43]** question was more about how do you create a uh streamlined frictionless

**[08:46]** create a uh streamlined frictionless

**[08:46]** create a uh streamlined frictionless experience for users uh that gives them

**[08:48]** experience for users uh that gives them

**[08:48]** experience for users uh that gives them this capability.

**[08:56]** When we were exploring the possibility

**[08:56]** When we were exploring the possibility of this space, what we found was um we


### [09:00 - 10:00]

**[09:00]** of this space, what we found was um we

**[09:00]** of this space, what we found was um we thought there was lots of ways that AI

**[09:02]** thought there was lots of ways that AI

**[09:02]** thought there was lots of ways that AI could help by developing AI features

**[09:05]** could help by developing AI features

**[09:05]** could help by developing AI features that could um help the user get access

**[09:07]** that could um help the user get access

**[09:07]** that could um help the user get access to this experience. But there was a lot

**[09:09]** to this experience. But there was a lot

**[09:09]** to this experience. But there was a lot of different ways you could do this and

**[09:10]** of different ways you could do this and

**[09:10]** of different ways you could do this and there's a lot that was quite uncertain.

**[09:13]** there's a lot that was quite uncertain.

**[09:13]** there's a lot that was quite uncertain. We also knew that AI could help us build

**[09:15]** We also knew that AI could help us build

**[09:15]** We also knew that AI could help us build those features really quickly with AI

**[09:17]** those features really quickly with AI

**[09:17]** those features really quickly with AI coding assistance and tools. So what we

**[09:19]** coding assistance and tools. So what we

**[09:19]** coding assistance and tools. So what we ended up doing is going extremely wide

**[09:21]** ended up doing is going extremely wide

**[09:21]** ended up doing is going extremely wide and trying quite a lot of features with

**[09:23]** and trying quite a lot of features with

**[09:23]** and trying quite a lot of features with different groups of users and seeing

**[09:24]** different groups of users and seeing

**[09:24]** different groups of users and seeing what worked and what didn't.

**[09:27]** what worked and what didn't.

**[09:27]** what worked and what didn't. The important thing is after that point

**[09:29]** The important thing is after that point

**[09:29]** The important thing is after that point we then stripped back and focused on

**[09:31]** we then stripped back and focused on

**[09:31]** we then stripped back and focused on what actually worked.

**[09:33]** what actually worked.

**[09:33]** what actually worked. One of the benefits of using AI coding

**[09:34]** One of the benefits of using AI coding

**[09:34]** One of the benefits of using AI coding assistants to make those features as

**[09:36]** assistants to make those features as

**[09:36]** assistants to make those features as well is that you don't have the

**[09:37]** well is that you don't have the

**[09:37]** well is that you don't have the sentimental attachment to them. So, it

**[09:39]** sentimental attachment to them. So, it

**[09:39]** sentimental attachment to them. So, it makes it much easier to strip them out

**[09:40]** makes it much easier to strip them out

**[09:40]** makes it much easier to strip them out again afterwards.

**[09:42]** again afterwards.

**[09:42]** again afterwards. I'm going to illustrate that point uh by

**[09:44]** I'm going to illustrate that point uh by

**[09:44]** I'm going to illustrate that point uh by showing an example of what the tool

**[09:46]** showing an example of what the tool

**[09:46]** showing an example of what the tool looked like when it had lots of features

**[09:47]** looked like when it had lots of features

**[09:47]** looked like when it had lots of features and then when we streamlined it down. Uh

**[09:50]** and then when we streamlined it down. Uh

**[09:50]** and then when we streamlined it down. Uh so here the users already recorded their

**[09:52]** so here the users already recorded their

**[09:52]** so here the users already recorded their meeting uh and they've been taken to

**[09:54]** meeting uh and they've been taken to

**[09:54]** meeting uh and they've been taken to this page to uh help them generate the

**[09:56]** this page to uh help them generate the

**[09:56]** this page to uh help them generate the summary of them. You see at the top

**[09:58]** summary of them. You see at the top

**[09:58]** summary of them. You see at the top there's like the ability to choose lots

**[09:59]** there's like the ability to choose lots


### [10:00 - 11:00]

**[10:00]** there's like the ability to choose lots of different templates because we had

**[10:01]** of different templates because we had

**[10:01]** of different templates because we had different users we're experimenting

**[10:02]** different users we're experimenting

**[10:02]** different users we're experimenting with. Some of our users seem seem to

**[10:05]** with. Some of our users seem seem to

**[10:05]** with. Some of our users seem seem to want the the output to follow an agenda

**[10:07]** want the the output to follow an agenda

**[10:07]** want the the output to follow an agenda from the from the meeting. So we gave

**[10:09]** from the from the meeting. So we gave

**[10:09]** from the from the meeting. So we gave them the option of inputting that agenda

**[10:10]** them the option of inputting that agenda

**[10:10]** them the option of inputting that agenda information.

**[10:12]** information.

**[10:12]** information. At the bottom we had two different AI

**[10:14]** At the bottom we had two different AI

**[10:14]** At the bottom we had two different AI features. We had an AI edit button so

**[10:16]** features. We had an AI edit button so

**[10:16]** features. We had an AI edit button so they could use free text to uh edit the

**[10:19]** they could use free text to uh edit the

**[10:19]** they could use free text to uh edit the output of the meeting but we also had AI

**[10:22]** output of the meeting but we also had AI

**[10:22]** output of the meeting but we also had AI chat so they could ask questions of the

**[10:23]** chat so they could ask questions of the

**[10:23]** chat so they could ask questions of the meeting. And this doesn't touch on some

**[10:26]** meeting. And this doesn't touch on some

**[10:26]** meeting. And this doesn't touch on some of the AI that's happening behind the

**[10:27]** of the AI that's happening behind the

**[10:27]** of the AI that's happening behind the scenes, such as automatically predicting

**[10:29]** scenes, such as automatically predicting

**[10:29]** scenes, such as automatically predicting who the speaker names are and also doing

**[10:32]** who the speaker names are and also doing

**[10:32]** who the speaker names are and also doing citations back to the original

**[10:33]** citations back to the original

**[10:33]** citations back to the original transcript.

**[10:35]** transcript.

**[10:35]** transcript. It's no surprise that when we were

**[10:37]** It's no surprise that when we were

**[10:37]** It's no surprise that when we were testing this with a lot of our users,

**[10:38]** testing this with a lot of our users,

**[10:38]** testing this with a lot of our users, they found it a little bit overwhelming

**[10:40]** they found it a little bit overwhelming

**[10:40]** they found it a little bit overwhelming and a little bit complicated. And in

**[10:42]** and a little bit complicated. And in

**[10:42]** and a little bit complicated. And in fact, many of them weren't even using

**[10:43]** fact, many of them weren't even using

**[10:43]** fact, many of them weren't even using these features.

**[10:46]** these features.

**[10:46]** these features. We also found because we were testing

**[10:48]** We also found because we were testing

**[10:48]** We also found because we were testing with different groups, a specific group

**[10:49]** with different groups, a specific group

**[10:50]** with different groups, a specific group that there was quite a lot of value of

**[10:51]** that there was quite a lot of value of

**[10:51]** that there was quite a lot of value of pursuing with, which was the probation

**[10:53]** pursuing with, which was the probation

**[10:53]** pursuing with, which was the probation services use case.

**[10:55]** services use case.

**[10:55]** services use case. So what we did next is we focused in on

**[10:57]** So what we did next is we focused in on

**[10:57]** So what we did next is we focused in on that use case and then we streamlined

**[10:59]** that use case and then we streamlined

**[10:59]** that use case and then we streamlined the app down. And what we ended up with


### [11:00 - 12:00]

**[11:01]** the app down. And what we ended up with

**[11:02]** the app down. And what we ended up with is with this justice transcribe and we

**[11:04]** is with this justice transcribe and we

**[11:04]** is with this justice transcribe and we built this in collaboration with Justice

**[11:06]** built this in collaboration with Justice

**[11:06]** built this in collaboration with Justice AI who's an AI team in the Ministry of

**[11:08]** AI who's an AI team in the Ministry of

**[11:08]** AI who's an AI team in the Ministry of Justice. As you can see, it's a lot

**[11:11]** Justice. As you can see, it's a lot

**[11:11]** Justice. As you can see, it's a lot simpler because we're focusing on one

**[11:13]** simpler because we're focusing on one

**[11:13]** simpler because we're focusing on one set of users. We didn't need to have the

**[11:15]** set of users. We didn't need to have the

**[11:15]** set of users. We didn't need to have the template picking option. These users

**[11:18]** template picking option. These users

**[11:18]** template picking option. These users didn't need the agenda option, so we

**[11:19]** didn't need the agenda option, so we

**[11:19]** didn't need the agenda option, so we could strip it out entirely.

**[11:22]** could strip it out entirely.

**[11:22]** could strip it out entirely. What we found with the AI edit and the

**[11:23]** What we found with the AI edit and the

**[11:23]** What we found with the AI edit and the AI chat feature is an overwhelming

**[11:26]** AI chat feature is an overwhelming

**[11:26]** AI chat feature is an overwhelming amount of pressure to merge them into

**[11:27]** amount of pressure to merge them into

**[11:27]** amount of pressure to merge them into one feature. So, we've taken them out

**[11:29]** one feature. So, we've taken them out

**[11:29]** one feature. So, we've taken them out and we're experimenting heavily so that

**[11:31]** and we're experimenting heavily so that

**[11:31]** and we're experimenting heavily so that there's not that same confusion.

**[11:34]** there's not that same confusion.

**[11:34]** there's not that same confusion. We've been getting extremely positive

**[11:35]** We've been getting extremely positive

**[11:36]** We've been getting extremely positive feedback from users with this and we're

**[11:38]** feedback from users with this and we're

**[11:38]** feedback from users with this and we're currently taking part in an evaluation

**[11:40]** currently taking part in an evaluation

**[11:40]** currently taking part in an evaluation where we're we're being compared to

**[11:42]** where we're we're being compared to

**[11:42]** where we're we're being compared to other uh tools in the space to work out

**[11:44]** other uh tools in the space to work out

**[11:44]** other uh tools in the space to work out which ones are the most impactful.

**[11:47]** which ones are the most impactful.

**[11:47]** which ones are the most impactful. But I hope this illustrates the point

**[11:48]** But I hope this illustrates the point

**[11:48]** But I hope this illustrates the point and the lesson that we're making here,

**[11:50]** and the lesson that we're making here,

**[11:50]** and the lesson that we're making here, which is experiment hard and go wide

**[11:53]** which is experiment hard and go wide

**[11:53]** which is experiment hard and go wide with lots of features. Lean into that

**[11:55]** with lots of features. Lean into that

**[11:55]** with lots of features. Lean into that uncertainty of what is what makes a good

**[11:58]** uncertainty of what is what makes a good

**[11:58]** uncertainty of what is what makes a good AI feature at the moment, but then cut


### [12:00 - 13:00]

**[12:00]** AI feature at the moment, but then cut

**[12:00]** AI feature at the moment, but then cut back and and streamline the app down.

**[12:04]** back and and streamline the app down.

**[12:04]** back and and streamline the app down. I thought you might be interested in in

**[12:06]** I thought you might be interested in in

**[12:06]** I thought you might be interested in in another use case that we were exploring

**[12:08]** another use case that we were exploring

**[12:08]** another use case that we were exploring which was for prime ministerial

**[12:09]** which was for prime ministerial

**[12:09]** which was for prime ministerial meetings. Uh this was actually from a

**[12:11]** meetings. Uh this was actually from a

**[12:11]** meetings. Uh this was actually from a recent meeting which was the first ever

**[12:13]** recent meeting which was the first ever

**[12:13]** recent meeting which was the first ever prime minister meeting where AI was used

**[12:15]** prime minister meeting where AI was used

**[12:15]** prime minister meeting where AI was used to transcribe and summarize the meeting

**[12:17]** to transcribe and summarize the meeting

**[12:17]** to transcribe and summarize the meeting and it was done using our tool.

**[12:24]** For the final lesson I'm going to tell

**[12:24]** For the final lesson I'm going to tell you a little bit about red box and the

**[12:26]** you a little bit about red box and the

**[12:26]** you a little bit about red box and the lesson is all about being ready to

**[12:27]** lesson is all about being ready to

**[12:27]** lesson is all about being ready to pivot.

**[12:29]** pivot.

**[12:29]** pivot. For those of you that don't know, all of

**[12:31]** For those of you that don't know, all of

**[12:31]** For those of you that don't know, all of our government ministers carry around a

**[12:33]** our government ministers carry around a

**[12:33]** our government ministers carry around a big red box which is full of paperwork

**[12:36]** big red box which is full of paperwork

**[12:36]** big red box which is full of paperwork and submissions and important decisions

**[12:38]** and submissions and important decisions

**[12:38]** and submissions and important decisions that they have to make. Their private

**[12:41]** that they have to make. Their private

**[12:41]** that they have to make. Their private offices do a lot of work to summarize,

**[12:43]** offices do a lot of work to summarize,

**[12:43]** offices do a lot of work to summarize, collect, and collect all that

**[12:44]** collect, and collect all that

**[12:44]** collect, and collect all that information to put it in the red box.

**[12:47]** information to put it in the red box.

**[12:47]** information to put it in the red box. Again, this is a prototypical use case

**[12:48]** Again, this is a prototypical use case

**[12:48]** Again, this is a prototypical use case of AI. So, it was no surprise that the

**[12:51]** of AI. So, it was no surprise that the

**[12:51]** of AI. So, it was no surprise that the idea to digitize this red box was the

**[12:53]** idea to digitize this red box was the

**[12:53]** idea to digitize this red box was the winning idea at a hackathon run by one

**[12:56]** winning idea at a hackathon run by one

**[12:56]** winning idea at a hackathon run by one of our sister teams, Evidence House.

**[12:59]** of our sister teams, Evidence House.

**[12:59]** of our sister teams, Evidence House. This became the first incarnation of


### [13:00 - 14:00]

**[13:01]** This became the first incarnation of

**[13:01]** This became the first incarnation of Redbox to digitize the ministerial red

**[13:03]** Redbox to digitize the ministerial red

**[13:03]** Redbox to digitize the ministerial red box.

**[13:06]** box.

**[13:06]** box. We we took this uh winning idea from the

**[13:08]** We we took this uh winning idea from the

**[13:08]** We we took this uh winning idea from the hackathon, built it into a full product.

**[13:11]** hackathon, built it into a full product.

**[13:11]** hackathon, built it into a full product. However, what we found when we actually

**[13:13]** However, what we found when we actually

**[13:13]** However, what we found when we actually tested it with real users is that the

**[13:15]** tested it with real users is that the

**[13:15]** tested it with real users is that the feature that they were most after, the

**[13:17]** feature that they were most after, the

**[13:17]** feature that they were most after, the one that they wanted above all else, and

**[13:19]** one that they wanted above all else, and

**[13:19]** one that they wanted above all else, and that they didn't really care about

**[13:20]** that they didn't really care about

**[13:20]** that they didn't really care about anything else, was just the ability to

**[13:22]** anything else, was just the ability to

**[13:22]** anything else, was just the ability to securely chat with a large language

**[13:23]** securely chat with a large language

**[13:23]** securely chat with a large language model. You see, this was over a year ago

**[13:26]** model. You see, this was over a year ago

**[13:26]** model. You see, this was over a year ago when enterprise uh the ability for

**[13:29]** when enterprise uh the ability for

**[13:29]** when enterprise uh the ability for enterprises to chat with large language

**[13:30]** enterprises to chat with large language

**[13:30]** enterprises to chat with large language models uh was definitely a bit rarer and

**[13:33]** models uh was definitely a bit rarer and

**[13:33]** models uh was definitely a bit rarer and particularly in the civil service. So,

**[13:35]** particularly in the civil service. So,

**[13:35]** particularly in the civil service. So, people were familiar with the value they

**[13:36]** people were familiar with the value they

**[13:36]** people were familiar with the value they could get from things like chat GPT, but

**[13:39]** could get from things like chat GPT, but

**[13:39]** could get from things like chat GPT, but they couldn't put their work information

**[13:40]** they couldn't put their work information

**[13:40]** they couldn't put their work information into it.

**[13:43]** into it.

**[13:43]** into it. This led to the second incarnation of

**[13:44]** This led to the second incarnation of

**[13:44]** This led to the second incarnation of Redbox, which was to be the easiest and

**[13:47]** Redbox, which was to be the easiest and

**[13:47]** Redbox, which was to be the easiest and cheapest way to securely chat to a large

**[13:49]** cheapest way to securely chat to a large

**[13:49]** cheapest way to securely chat to a large language model for civil servants.

**[13:53]** language model for civil servants.

**[13:53]** language model for civil servants. This also gave us an opportunity.

**[13:55]** This also gave us an opportunity.

**[13:55]** This also gave us an opportunity. A lot of our other tools we were

**[13:57]** A lot of our other tools we were

**[13:57]** A lot of our other tools we were experimenting with ways of making

**[13:58]** experimenting with ways of making

**[13:58]** experimenting with ways of making government specific data more accessible


### [14:00 - 15:00]

**[14:01]** government specific data more accessible

**[14:01]** government specific data more accessible and easy to navigate. For example, we

**[14:03]** and easy to navigate. For example, we

**[14:03]** and easy to navigate. For example, we had a product called Parlex which was

**[14:05]** had a product called Parlex which was

**[14:05]** had a product called Parlex which was all about making parliamentary and

**[14:06]** all about making parliamentary and

**[14:06]** all about making parliamentary and legislative data uh more available. But

**[14:10]** legislative data uh more available. But

**[14:10]** legislative data uh more available. But we were developing these as independent

**[14:12]** we were developing these as independent

**[14:12]** we were developing these as independent products with their own user interfaces.

**[14:15]** products with their own user interfaces.

**[14:15]** products with their own user interfaces. The opportunity we saw is to use Redbox

**[14:17]** The opportunity we saw is to use Redbox

**[14:17]** The opportunity we saw is to use Redbox as that interface. why not bring these

**[14:20]** as that interface. why not bring these

**[14:20]** as that interface. why not bring these tools and products into this uh kind of

**[14:22]** tools and products into this uh kind of

**[14:22]** tools and products into this uh kind of chat interface that we were already

**[14:24]** chat interface that we were already

**[14:24]** chat interface that we were already creating and that lots of people already

**[14:26]** creating and that lots of people already

**[14:26]** creating and that lots of people already had access to. That's why our third

**[14:28]** had access to. That's why our third

**[14:28]** had access to. That's why our third incarnation was to be the client to

**[14:30]** incarnation was to be the client to

**[14:30]** incarnation was to be the client to access the incubator for AI's tools and

**[14:32]** access the incubator for AI's tools and

**[14:32]** access the incubator for AI's tools and data.

**[14:34]** data.

**[14:34]** data. It's worth saying after the second one

**[14:36]** It's worth saying after the second one

**[14:36]** It's worth saying after the second one uh the reason that we' validated that

**[14:38]** uh the reason that we' validated that

**[14:38]** uh the reason that we' validated that that was a useful use case, we launched

**[14:40]** that was a useful use case, we launched

**[14:40]** that was a useful use case, we launched it within the cabinet office and within

**[14:41]** it within the cabinet office and within

**[14:41]** it within the cabinet office and within just a matter of weeks we had thousands

**[14:42]** just a matter of weeks we had thousands

**[14:42]** just a matter of weeks we had thousands of users. So that's why we knew it would

**[14:45]** of users. So that's why we knew it would

**[14:45]** of users. So that's why we knew it would be a useful front front end for some of

**[14:47]** be a useful front front end for some of

**[14:47]** be a useful front front end for some of our other tools as well.

**[14:50]** our other tools as well.

**[14:50]** our other tools as well. The next thing that happened were two

**[14:52]** The next thing that happened were two

**[14:52]** The next thing that happened were two important things. The first is that uh

**[14:56]** important things. The first is that uh

**[14:56]** important things. The first is that uh the commercial landscape changed.

**[14:58]** the commercial landscape changed.

**[14:58]** the commercial landscape changed. Microsoft announced that copilot chat


### [15:00 - 16:00]

**[15:00]** Microsoft announced that copilot chat

**[15:00]** Microsoft announced that copilot chat their enterprise version of chat GPT was

**[15:03]** their enterprise version of chat GPT was

**[15:03]** their enterprise version of chat GPT was going to be free for enterprise

**[15:05]** going to be free for enterprise

**[15:05]** going to be free for enterprise Microsoft users and a lot of the

**[15:07]** Microsoft users and a lot of the

**[15:07]** Microsoft users and a lot of the government is an enterprise Microsoft

**[15:09]** government is an enterprise Microsoft

**[15:09]** government is an enterprise Microsoft user.

**[15:11]** user.

**[15:11]** user. The second thing that happened is that

**[15:13]** The second thing that happened is that

**[15:13]** The second thing that happened is that Claude's model context protocol exploded

**[15:16]** Claude's model context protocol exploded

**[15:16]** Claude's model context protocol exploded onto the scene and provided a way of

**[15:18]** onto the scene and provided a way of

**[15:18]** onto the scene and provided a way of providing standardization for being able

**[15:20]** providing standardization for being able

**[15:20]** providing standardization for being able to bring tools and data to models.

**[15:23]** to bring tools and data to models.

**[15:24]** to bring tools and data to models. This meant we had to pivot again. It no

**[15:26]** This meant we had to pivot again. It no

**[15:26]** This meant we had to pivot again. It no longer made sense for us to bank on red

**[15:28]** longer made sense for us to bank on red

**[15:28]** longer made sense for us to bank on red box being the main way that civil

**[15:30]** box being the main way that civil

**[15:30]** box being the main way that civil servants would be accessing secure chat

**[15:32]** servants would be accessing secure chat

**[15:32]** servants would be accessing secure chat with large language models. And it no

**[15:34]** with large language models. And it no

**[15:34]** with large language models. And it no longer made sense for that to be the

**[15:35]** longer made sense for that to be the

**[15:35]** longer made sense for that to be the only way for people to access our tools

**[15:37]** only way for people to access our tools

**[15:37]** only way for people to access our tools and data. So instead we've been

**[15:39]** and data. So instead we've been

**[15:39]** and data. So instead we've been investing hard in using the model

**[15:41]** investing hard in using the model

**[15:41]** investing hard in using the model context protocol to bring our tools and

**[15:44]** context protocol to bring our tools and

**[15:44]** context protocol to bring our tools and data to any client whether it's redbox

**[15:46]** data to any client whether it's redbox

**[15:46]** data to any client whether it's redbox whether it's uh copilot chat whether

**[15:49]** whether it's uh copilot chat whether

**[15:50]** whether it's uh copilot chat whether it's enterprise versions of other tool

**[15:51]** it's enterprise versions of other tool

**[15:51]** it's enterprise versions of other tool like anthropic or chat GPT.

**[15:54]** like anthropic or chat GPT.

**[15:54]** like anthropic or chat GPT. So it's worth stressing that throughout

**[15:56]** So it's worth stressing that throughout

**[15:56]** So it's worth stressing that throughout that time Redbox has been valuable uh

**[15:58]** that time Redbox has been valuable uh

**[15:58]** that time Redbox has been valuable uh and is still valuable. It's still the


### [16:00 - 17:00]

**[16:00]** and is still valuable. It's still the

**[16:00]** and is still valuable. It's still the main way that a lot of people in the

**[16:01]** main way that a lot of people in the

**[16:01]** main way that a lot of people in the cabinet office uh are able to access

**[16:04]** cabinet office uh are able to access

**[16:04]** cabinet office uh are able to access that secure chat with a large language

**[16:06]** that secure chat with a large language

**[16:06]** that secure chat with a large language model. But I hope this lesson shows that

**[16:08]** model. But I hope this lesson shows that

**[16:08]** model. But I hope this lesson shows that things are moving really quickly and

**[16:10]** things are moving really quickly and

**[16:10]** things are moving really quickly and it's really important to evolve and

**[16:12]** it's really important to evolve and

**[16:12]** it's really important to evolve and change with it. Otherwise, you get stuck

**[16:14]** change with it. Otherwise, you get stuck

**[16:14]** change with it. Otherwise, you get stuck on the wrong path.

**[16:16]** on the wrong path.

**[16:16]** on the wrong path. That's why our third lesson is you'll

**[16:18]** That's why our third lesson is you'll

**[16:18]** That's why our third lesson is you'll have to pivot harder and faster than

**[16:20]** have to pivot harder and faster than

**[16:20]** have to pivot harder and faster than ever before.

**[16:24]** ever before.

**[16:24]** ever before. So, let's recap the four lessons we've

**[16:25]** So, let's recap the four lessons we've

**[16:25]** So, let's recap the four lessons we've covered today. And yep, there were four.

**[16:27]** covered today. And yep, there were four.

**[16:27]** covered today. And yep, there were four. Lesson zero, the importance of AI

**[16:30]** Lesson zero, the importance of AI

**[16:30]** Lesson zero, the importance of AI product managers and the fact this is a

**[16:32]** product managers and the fact this is a

**[16:32]** product managers and the fact this is a vital role which requires AI expertise.

**[16:36]** vital role which requires AI expertise.

**[16:36]** vital role which requires AI expertise. Lesson one, evaluate AI early. Resolve

**[16:39]** Lesson one, evaluate AI early. Resolve

**[16:39]** Lesson one, evaluate AI early. Resolve AI uncertainties early on with

**[16:41]** AI uncertainties early on with

**[16:41]** AI uncertainties early on with evaluations and tests with users.

**[16:44]** evaluations and tests with users.

**[16:44]** evaluations and tests with users. Lesson two, go wide with features.

**[16:47]** Lesson two, go wide with features.

**[16:47]** Lesson two, go wide with features. Experiment hard with new features on

**[16:48]** Experiment hard with new features on

**[16:48]** Experiment hard with new features on real users, then cut back.

**[16:51]** real users, then cut back.

**[16:51]** real users, then cut back. And lesson three, be ready to pivot.

**[16:53]** And lesson three, be ready to pivot.

**[16:53]** And lesson three, be ready to pivot. You'll have to pivot harder and faster

**[16:55]** You'll have to pivot harder and faster

**[16:55]** You'll have to pivot harder and faster than ever before.


### [17:00 - 18:00]

**[17:01]** Now, some of you are probably sat there

**[17:01]** Now, some of you are probably sat there thinking, how much of this is really

**[17:03]** thinking, how much of this is really

**[17:03]** thinking, how much of this is really new? And that's a fair question to ask.

**[17:06]** new? And that's a fair question to ask.

**[17:06]** new? And that's a fair question to ask. There's a lot of wisdom within existing

**[17:08]** There's a lot of wisdom within existing

**[17:08]** There's a lot of wisdom within existing product management that feels very

**[17:10]** product management that feels very

**[17:10]** product management that feels very familiar to the stuff we're covering

**[17:11]** familiar to the stuff we're covering

**[17:11]** familiar to the stuff we're covering here. For example, the principle of

**[17:13]** here. For example, the principle of

**[17:13]** here. For example, the principle of resolving your biggest uncertainties

**[17:15]** resolving your biggest uncertainties

**[17:15]** resolving your biggest uncertainties first uh has been around for a long

**[17:17]** first uh has been around for a long

**[17:17]** first uh has been around for a long time, as is putting your users first,

**[17:19]** time, as is putting your users first,

**[17:20]** time, as is putting your users first, listening to them, and testing features

**[17:21]** listening to them, and testing features

**[17:21]** listening to them, and testing features with them.

**[17:23]** with them.

**[17:23]** with them. However, I hope that what these lessons

**[17:24]** However, I hope that what these lessons

**[17:24]** However, I hope that what these lessons have emphasized is that AI really does

**[17:26]** have emphasized is that AI really does

**[17:26]** have emphasized is that AI really does make things different.

**[17:29]** make things different.

**[17:29]** make things different. AI really does uh resolving AI's

**[17:31]** AI really does uh resolving AI's

**[17:31]** AI really does uh resolving AI's uncertainties really is an important

**[17:33]** uncertainties really is an important

**[17:34]** uncertainties really is an important thing you have to do and is something

**[17:35]** thing you have to do and is something

**[17:35]** thing you have to do and is something that is a bit more challenging with the

**[17:37]** that is a bit more challenging with the

**[17:37]** that is a bit more challenging with the extra need for experimentation and

**[17:39]** extra need for experimentation and

**[17:39]** extra need for experimentation and evaluation.

**[17:45]** Uh for lesson two which we had which was

**[17:45]** Uh for lesson two which we had which was uh going wide with features AI really

**[17:48]** uh going wide with features AI really

**[17:48]** uh going wide with features AI really does change the landscape. uh it makes

**[17:50]** does change the landscape. uh it makes

**[17:50]** does change the landscape. uh it makes it easier to go faster with features and

**[17:52]** it easier to go faster with features and

**[17:52]** it easier to go faster with features and have less attachment to them and

**[17:53]** have less attachment to them and

**[17:53]** have less attachment to them and therefore you should be doing that and

**[17:55]** therefore you should be doing that and

**[17:55]** therefore you should be doing that and testing those features and scaling back

**[17:57]** testing those features and scaling back

**[17:57]** testing those features and scaling back as well as AI features being new and

**[17:59]** as well as AI features being new and

**[17:59]** as well as AI features being new and there being more uncertainty around


### [18:00 - 19:00]

**[18:01]** there being more uncertainty around

**[18:01]** there being more uncertainty around exactly what makes a good AI feature.

**[18:04]** exactly what makes a good AI feature.

**[18:04]** exactly what makes a good AI feature. And finally, the AI landscape is

**[18:06]** And finally, the AI landscape is

**[18:06]** And finally, the AI landscape is changing extremely quickly which is why

**[18:08]** changing extremely quickly which is why

**[18:08]** changing extremely quickly which is why pivoting is is more necessary now than

**[18:11]** pivoting is is more necessary now than

**[18:11]** pivoting is is more necessary now than ever before.

**[18:16]** So I hope uh those lessons have been

**[18:16]** So I hope uh those lessons have been useful. I hope that you feel ready to

**[18:19]** useful. I hope that you feel ready to

**[18:19]** useful. I hope that you feel ready to step up into that AI product manage

**[18:21]** step up into that AI product manage

**[18:21]** step up into that AI product manage manager mindset uh that your product

**[18:23]** manager mindset uh that your product

**[18:23]** manager mindset uh that your product needs.

**[18:25]** needs.

**[18:25]** needs. And thank you so much for listening and

**[18:27]** And thank you so much for listening and

**[18:27]** And thank you so much for listening and please do check us out. Uh we're

**[18:28]** please do check us out. Uh we're

**[18:28]** please do check us out. Uh we're currently hiring. Thank you.


