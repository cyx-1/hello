# Cognee - AI Memory for Agents

This example demonstrates **Cognee**, a Python library that provides persistent AI memory capabilities for AI agents. Cognee transforms documents and conversations into structured knowledge graphs that combine vector embeddings with graph-based relationships.

## Overview

Cognee solves the context limitation problem in AI agents by providing:
- **Persistent memory** across sessions
- **Knowledge graph** construction from unstructured data
- **Semantic search** using vector embeddings
- **Graph traversal** for contextual connections

## Requirements

- **Python**: >= 3.10
- **Dependencies**: cognee >= 0.1.0, python-dotenv >= 1.0.0 (auto-installed via inline script metadata)
- **Optional**: OpenAI API key for full functionality (demo mode works without it)

## Running the Example

```bash
uv run main_cognee.py
```

For full functionality with actual API calls:
```bash
export OPENAI_API_KEY='your-api-key-here'
uv run main_cognee.py
```

## Code Structure

### Key Source Code Sections

#### 1. Inline Script Dependencies (Lines 1-7)
```python
# /// script
# requires-python = ">=3.10"
# dependencies = [
#     "cognee>=0.1.0",
#     "python-dotenv>=1.0.0",
# ]
# ///
```
**Purpose**: Specifies dependencies using PEP 723 inline script metadata, enabling `uv` to automatically manage the environment.

---

#### 2. Importing Cognee (Line 25)
```python
import cognee
```
**Purpose**: Import happens inside `main()` after dependencies are installed by uv.

---

#### 3. Adding Data to Memory (Lines 64-74)
```python
for idx, data in enumerate(data_points, 1):
    print(f"  [{idx}] Adding: {data[:60]}...")
    if has_api_key:
        # Line 67: Add data to Cognee's memory system
        try:
            await cognee.add(data)
        except Exception as e:
            print(f"      Error: {e}")
            has_api_key = False
    else:
        print(f"      → Would call: await cognee.add('{data[:40]}...')")
```
**Purpose**: `cognee.add()` ingests text data into the memory system. In demo mode (no API key), shows what would be called.

---

#### 4. Building Knowledge Graph (Lines 96-110)
```python
if has_api_key:
    try:
        # Line 92: Cognify builds the semantic memory structure
        await cognee.cognify()
        print("✓ Knowledge graph built successfully")
    except Exception as e:
        print(f"⚠️  Cognify error: {str(e)[:80]}...")
        has_api_key = False
else:
    print("  → Would call: await cognee.cognify()")
    print("  ℹ  This would:")
    print("     1. Extract entities (e.g., 'Cognee', 'AI agents', 'knowledge graphs')")
    print("     2. Identify relationships (e.g., 'Cognee' -> 'transforms' -> 'documents')")
    print("     3. Create vector embeddings for semantic similarity")
    print("     4. Store in persistent vector + graph databases")
```
**Purpose**: `cognee.cognify()` processes ingested data into a knowledge graph with embeddings. This is the core transformation step.

---

#### 5. Searching Memory (Lines 130-158)
```python
if has_api_key:
    try:
        # Line 121: Search the knowledge graph
        results = await cognee.search(query)

        if results:
            print(f"  Found {len(results)} relevant results:")
            for idx, result in enumerate(results[:3], 1):
                # Line 127: Display search results
                result_text = str(result)[:100]
                print(f"    [{idx}] {result_text}...")
        else:
            print("  No results found")
    except Exception as e:
        print(f"  ⚠️  Search error: {str(e)[:60]}...")
        has_api_key = False
else:
    print(f"  → Would call: await cognee.search('{query}')")
    print("  ℹ  Expected results based on our data:")

    if query_num == 1:
        print("     • 'Cognee is a Python library for building AI memory systems.'")
        print("     • 'Cognee transforms documents into structured knowledge graphs.'")
```
**Purpose**: `cognee.search()` performs semantic search across the knowledge graph, combining vector similarity with graph traversal.

---

## Program Output

### Output Explanation

```
======================================================================
COGNEE AI MEMORY DEMONSTRATION
======================================================================
```
**Annotation**: Program header (generated by main() function lines 27-30)

---

```
⚠️  WARNING: No LLM_API_KEY or OPENAI_API_KEY found in environment
   Running in demonstration mode without actual API calls
   To run fully: export OPENAI_API_KEY='your-key-here'
```
**Annotation**: API key check (lines 40-45) - script runs in demo mode showing what API calls would be made

---

```
STEP 1: Adding data to AI memory
----------------------------------------------------------------------
  [1] Adding: Cognee is a Python library for building AI memory systems....
      → Would call: await cognee.add('Cognee is a Python library for building ...')
  [2] Adding: Cognee transforms documents into structured knowledge graphs...
      → Would call: await cognee.add('Cognee transforms documents into structu...')
  [3] Adding: The library supports vector search and graph-based retrieval...
      → Would call: await cognee.add('The library supports vector search and g...')
  [4] Adding: Cognee was created to solve the context limitation problem i...
      → Would call: await cognee.add('Cognee was created to solve the context ...')
  [5] Adding: AI agents can use Cognee to remember past conversations and ...
      → Would call: await cognee.add('AI agents can use Cognee to remember pas...')
  [6] Adding: Cognee combines embeddings with knowledge graphs for better ...
      → Would call: await cognee.add('Cognee combines embeddings with knowledg...')

ℹ  In actual usage, these would be stored in Cognee's memory
```
**Annotation**: Data ingestion phase (lines 51-81)
- **Lines 55-62**: Define 6 data points about Cognee
- **Lines 64-74**: Loop through data points calling `cognee.add()`
- **Lines 74**: In demo mode, shows API call that would be made
- **Result**: Data prepared for knowledge graph construction

---

```
STEP 2: Building knowledge graph (cognifying)
----------------------------------------------------------------------
  Processing data into knowledge graph...
  - Extracting entities and relationships
  - Creating vector embeddings
  - Building graph connections

  → Would call: await cognee.cognify()
  ℹ  This would:
     1. Extract entities (e.g., 'Cognee', 'AI agents', 'knowledge graphs')
     2. Identify relationships (e.g., 'Cognee' -> 'transforms' -> 'documents')
     3. Create vector embeddings for semantic similarity
     4. Store in persistent vector + graph databases
```
**Annotation**: Knowledge graph construction (lines 86-112)
- **Line 99**: `cognee.cognify()` would process data into knowledge graph
- **Output explanation**: Shows the 4 key operations cognify performs
  1. **Entity extraction**: Identifies key concepts (Cognee, AI agents, etc.)
  2. **Relationship mapping**: Links entities (Cognee transforms documents)
  3. **Vector embeddings**: Creates semantic representations
  4. **Persistence**: Stores in LanceDB (vectors) + Kùzu (graph)

---

```
STEP 3: Querying AI memory with semantic search
----------------------------------------------------------------------

Query 1: 'What is Cognee?'
  ──────────────────────────────────────────────────────────────────
  → Would call: await cognee.search('What is Cognee?')
  ℹ  Expected results based on our data:
     • 'Cognee is a Python library for building AI memory systems.'
     • 'Cognee transforms documents into structured knowledge graphs.'

Query 2: 'How does Cognee help AI agents?'
  ──────────────────────────────────────────────────────────────────
  → Would call: await cognee.search('How does Cognee help AI agents?')
  ℹ  Expected results based on our data:
     • 'AI agents can use Cognee to remember past conversations...'
     • 'Cognee was created to solve the context limitation problem...'

Query 3: 'What technologies does Cognee use?'
  ──────────────────────────────────────────────────────────────────
  → Would call: await cognee.search('What technologies does Cognee use?')
  ℹ  Expected results based on our data:
     • 'The library supports vector search and graph-based retrieval.'
     • 'Cognee combines embeddings with knowledge graphs...'
```
**Annotation**: Semantic search demonstration (lines 117-160)
- **Lines 120-124**: Define 3 test queries
- **Lines 126-158**: Loop through queries calling `cognee.search()`
- **Line 133**: Search API call (in demo mode, shows expected results)
- **Key insight**: Search returns contextually relevant results, not just keyword matches
  - Query 1 returns definitional information
  - Query 2 returns use-case information
  - Query 3 returns technical details
- **How it works**: Combines vector similarity (semantic understanding) with graph traversal (contextual connections)

---

```
STEP 4: Memory persistence
----------------------------------------------------------------------
  Cognee stores data in persistent storage:
  - Vector embeddings in vector database (LanceDB by default)
  - Knowledge graph in graph database (Kùzu by default)
  - Memory persists across Python sessions
  - Can be queried anytime without re-processing

  Additional memory management operations:
  - await cognee.prune.prune_data()  # Clean up old data
  - await cognee.prune.prune_system()  # Reset entire system
  - await cognee.status()  # Check memory status
```
**Annotation**: Persistence layer explanation (lines 165-191)
- **LanceDB**: Vector database for embeddings (enables semantic search)
- **Kùzu**: Graph database for relationships (enables contextual connections)
- **Line 186**: `cognee.prune.prune_data()` cleans up memory
- **Key advantage**: Memory survives application restarts, can be shared across AI agent instances

---

```
======================================================================
SUMMARY: How Cognee Handles AI Memory
======================================================================

1. DATA INGESTION (.add())
   - Accepts text, documents, conversations
   - Chunks and preprocesses content
   - Prepares for knowledge extraction

2. KNOWLEDGE GRAPH BUILDING (.cognify())
   - Extracts entities and relationships
   - Creates vector embeddings for semantic search
   - Builds interconnected knowledge graph
   - Stores in persistent databases

3. MEMORY RETRIEVAL (.search())
   - Semantic search using vector similarity
   - Graph traversal for contextual connections
   - Returns relevant information with context
   - Combines multiple retrieval strategies

4. PERSISTENCE
   - Memory stored in local/remote databases
   - Survives application restarts
   - Can be shared across AI agent instances
   - Supports incremental updates

KEY ADVANTAGES:
✓ Goes beyond simple RAG (Retrieval Augmented Generation)
✓ Understands relationships between information
✓ Provides context-aware memory for AI agents
✓ Scales to large document collections
✓ Enables long-term memory for conversational AI
```
**Annotation**: Summary section (lines 193-221) - High-level overview of Cognee's complete workflow

---

## How Cognee Handles AI Memory

### The Three-Step Process

1. **`.add(data)` - Data Ingestion** (Line 69)
   - Accepts any text: documents, conversations, knowledge
   - Chunks content into manageable pieces
   - Prepares for semantic processing

2. **`.cognify()` - Knowledge Graph Construction** (Line 99)
   - Extracts entities (people, concepts, technologies)
   - Identifies relationships between entities
   - Creates vector embeddings for semantic understanding
   - Stores in dual databases: vectors (LanceDB) + graph (Kùzu)

3. **`.search(query)` - Intelligent Retrieval** (Line 133)
   - Uses vector similarity for semantic matching
   - Traverses graph for contextual connections
   - Returns ranked results with context
   - Combines multiple retrieval strategies

### Key Differentiators

**vs. Traditional RAG (Retrieval Augmented Generation)**:
- RAG: Simple vector similarity search
- Cognee: Vector search + graph relationships = richer context

**vs. Simple Vector Databases**:
- Vector DBs: Find similar text chunks
- Cognee: Understands how concepts relate to each other

**vs. Simple Graph Databases**:
- Graph DBs: Store structured relationships
- Cognee: Combines structure with semantic understanding

## Architecture

```
User Input
    ↓
cognee.add() → Data Chunking → Entity Extraction
                                      ↓
                              Knowledge Graph ←→ Vector Embeddings
                                      ↓
                              LanceDB + Kùzu Databases
                                      ↓
cognee.search() → Hybrid Retrieval (Vector + Graph)
                                      ↓
                              Ranked Results
```

## Use Cases

1. **Conversational AI Agents**: Remember past conversations and context
2. **Document Intelligence**: Build knowledge bases from document collections
3. **Question Answering**: Retrieve contextually relevant information
4. **Research Assistants**: Connect related concepts across documents
5. **Customer Support**: Maintain customer history and preferences

## Additional Resources

- **GitHub**: [github.com/topoteretes/cognee](https://github.com/topoteretes/cognee)
- **PyPI**: [pypi.org/project/cognee](https://pypi.org/project/cognee/)
- **Documentation**: [docs.cognee.ai](https://docs.cognee.ai/)

## Version Requirements

- **Cognee**: Tested with version 0.4.0
- **Python**: Requires 3.10 or higher
- **LanceDB**: Automatically installed as dependency (vector storage)
- **Kùzu**: Automatically installed as dependency (graph storage)
- **LiteLLM**: Used for LLM provider abstraction (supports OpenAI, Anthropic, etc.)
