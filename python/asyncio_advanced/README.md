# Advanced Asyncio: Production-Ready Patterns

This example demonstrates advanced asyncio concepts essential for production applications.

## Topics Covered

1. **Synchronization Primitives** - Lock, Semaphore, Event
2. **Queue-Based Patterns** - Producer/Consumer with asyncio.Queue
3. **Timeouts and Cancellation** - wait_for, cancel, CancelledError
4. **Advanced Task Management** - as_completed, wait with strategies
5. **Async Iteration** - Async generators and async for loops
6. **Blocking Code** - Running blocking operations in executors
7. **Real-World Patterns** - Rate limiting and retry logic

## Running the Example

```bash
uv run python main_asyncio_advanced.py
```

---

## 1. Synchronization Primitives

### 1a. Lock - Protecting Shared Resources

**Source Code (main_asyncio_advanced.py:31-38):**
```python
async def increment_counter(worker_id, iterations):
    global shared_counter
    for i in range(iterations):
        async with counter_lock:  # Line 34: Only one task at a time
            current = shared_counter
            await asyncio.sleep(0.01)  # Line 36: Simulate work
            shared_counter = current + 1
            log_time(f"ğŸ”’ Worker-{worker_id}: Counter = {shared_counter}")
```

**Output:**
```
[08:49:08.869] ğŸ”’ Worker-1: Counter = 1   â† Worker-1 holds lock
[08:49:08.885] ğŸ”’ Worker-2: Counter = 2   â† Worker-2 gets lock after Worker-1 releases
[08:49:08.901] ğŸ”’ Worker-1: Counter = 3   â† They alternate (mutual exclusion)
[08:49:08.917] ğŸ”’ Worker-2: Counter = 4
[08:49:08.933] ğŸ”’ Worker-1: Counter = 5
[08:49:08.949] ğŸ”’ Worker-2: Counter = 6
[08:49:08.949]    Final counter value: 6  â† Correct! (Without lock, would be wrong)
```

**ğŸ’¡ Key Insight:**
- **Line 34:** `async with counter_lock` ensures only one task modifies `shared_counter` at a time
- **Line 36:** Even with simulated work between read and write, the lock prevents race conditions
- **Result:** Counter reaches correct value (6) because updates are atomic

---

### 1b. Semaphore - Limiting Concurrent Operations

**Source Code (main_asyncio_advanced.py:42-48):**
```python
async def download_file(file_id, semaphore):
    async with semaphore:  # Line 44: Only N tasks can be here
        log_time(f"ğŸ“¥ Downloading file-{file_id}...")
        await asyncio.sleep(random.uniform(0.5, 1.0))
        log_time(f"âœ… Downloaded file-{file_id}")
        return f"file-{file_id}.data"
```

**Usage (main_asyncio_advanced.py:70-72):**
```python
semaphore = asyncio.Semaphore(2)  # Line 70: Max 2 concurrent
await asyncio.gather(*[download_file(i, semaphore) for i in range(5)])
```

**Output:**
```
[08:49:08.949] ğŸ“¥ Downloading file-0...  â† First 2 start immediately
[08:49:08.949] ğŸ“¥ Downloading file-1...
[08:49:09.588] âœ… Downloaded file-0      â† file-0 finishes, slot opens
[08:49:09.588] ğŸ“¥ Downloading file-2...  â† file-2 starts (using file-0's slot)
[08:49:09.766] âœ… Downloaded file-1      â† file-1 finishes, slot opens
[08:49:09.766] ğŸ“¥ Downloading file-3...  â† file-3 starts (using file-1's slot)
[08:49:10.501] âœ… Downloaded file-2
[08:49:10.501] ğŸ“¥ Downloading file-4...  â† file-4 starts
[08:49:10.693] âœ… Downloaded file-3
[08:49:11.014] âœ… Downloaded file-4
```

**ğŸ’¡ Key Insight:**
- **Line 70:** `Semaphore(2)` allows max 2 concurrent downloads
- **Notice:** Only 2 "Downloading" messages appear at a time
- **Use Case:** Prevent overwhelming external APIs or system resources

---

### 1c. Event - Coordinating Multiple Tasks

**Source Code (main_asyncio_advanced.py:52-57):**
```python
async def waiter(event, waiter_id):
    log_time(f"â³ Waiter-{waiter_id}: Waiting for signal...")
    await event.wait()  # Line 54: Block until event is set
    log_time(f"ğŸ‰ Waiter-{waiter_id}: Received signal! Proceeding...")
```

**Source Code (main_asyncio_advanced.py:60-64):**
```python
async def signaler(event, delay):
    log_time(f"â° Signaler: Will send signal in {delay}s...")
    await asyncio.sleep(delay)
    event.set()  # Line 63: Wake up all waiters
    log_time(f"ğŸ“¢ Signaler: Signal sent!")
```

**Output:**
```
[08:49:11.014] â³ Waiter-1: Waiting for signal...  â† Line 54: All 3 waiters
[08:49:11.014] â³ Waiter-2: Waiting for signal...  â† block here
[08:49:11.014] â³ Waiter-3: Waiting for signal...
[08:49:11.014] â° Signaler: Will send signal in 1.0s...
[08:49:12.015] ğŸ“¢ Signaler: Signal sent!           â† Line 63: Event set!
[08:49:12.015] ğŸ‰ Waiter-1: Received signal! Proceeding...  â† All wake up
[08:49:12.015] ğŸ‰ Waiter-2: Received signal! Proceeding...  â† simultaneously
[08:49:12.015] ğŸ‰ Waiter-3: Received signal! Proceeding...
```

**ğŸ’¡ Key Insight:**
- **Line 54:** All waiters block at `event.wait()`
- **Line 63:** `event.set()` releases ALL waiting tasks simultaneously
- **Use Case:** Coordinating initialization (e.g., wait for DB connection before processing requests)

---

## 2. Queue-Based Producer/Consumer Pattern

**Source Code - Producer (main_asyncio_advanced.py:92-99):**
```python
async def producer(queue, producer_id, items):
    for i in range(items):
        item = f"Item-{producer_id}-{i}"
        await queue.put(item)  # Line 95: Add to queue
        log_time(f"ğŸ“¦ Producer-{producer_id}: Added {item} (queue size: {queue.qsize()})")
        await asyncio.sleep(random.uniform(0.1, 0.3))
    log_time(f"âœ… Producer-{producer_id}: Finished")
```

**Source Code - Consumer (main_asyncio_advanced.py:102-112):**
```python
async def consumer(queue, consumer_id):
    while True:
        item = await queue.get()  # Line 104: Block until item available
        if item is None:  # Line 105: Poison pill to stop
            queue.task_done()
            log_time(f"ğŸ›‘ Consumer-{consumer_id}: Shutting down")
            break
        log_time(f"ğŸ“¨ Consumer-{consumer_id}: Processing {item}")
        await asyncio.sleep(random.uniform(0.2, 0.4))
        queue.task_done()  # Line 111: Mark item as processed
```

**Output:**
```
[08:49:12.016] ğŸ“¦ Producer-0: Added Item-0-0 (queue size: 1)  â† Added to queue
[08:49:12.016] ğŸ“¦ Producer-1: Added Item-1-0 (queue size: 2)
[08:49:12.016] ğŸ“¨ Consumer-0: Processing Item-0-0             â† Line 104: Consumer gets it
[08:49:12.016] ğŸ“¨ Consumer-1: Processing Item-1-0
[08:49:12.146] ğŸ“¦ Producer-0: Added Item-0-1 (queue size: 1)
[08:49:12.273] ğŸ“¦ Producer-0: Added Item-0-2 (queue size: 2)
[08:49:12.273] ğŸ“¨ Consumer-0: Processing Item-0-1
...
[08:49:12.997] ğŸ“‹ All items processed!                         â† queue.join() completed
[08:49:12.997] ğŸ›‘ Consumer-0: Shutting down                    â† Line 105: Poison pill
[08:49:12.997] ğŸ›‘ Consumer-1: Shutting down
```

**ğŸ’¡ Key Insight:**
- **Line 95:** Producers add items to shared queue
- **Line 104:** `queue.get()` blocks until an item is available
- **Line 111:** `task_done()` is crucial for `queue.join()` to know when all work is complete
- **Line 105:** Poison pill pattern (`None`) gracefully shuts down consumers

---

## 3. Timeouts and Cancellation

### 3a. Timeout with wait_for

**Source Code (main_asyncio_advanced.py:143-147):**
```python
log_time("\nâ±ï¸  Timeout Example (2s timeout for 3s task):")
try:
    result = await asyncio.wait_for(slow_operation(3, "SlowTask"), timeout=2.0)
except asyncio.TimeoutError:
    log_time("â° Task timed out!\n")
```

**Output:**
```
[08:49:12.997] â±ï¸  Timeout Example (2s timeout for 3s task):
[08:49:12.997] ğŸŒ SlowTask: Starting (will take 3s)...
[08:49:15.012] âŒ SlowTask: Was cancelled!  â† After 2s, wait_for cancels it
[08:49:15.012] â° Task timed out!
```

**ğŸ’¡ Key Insight:**
- `wait_for()` automatically cancels the task after timeout
- The cancelled task receives `CancelledError` for cleanup

---

### 3b. Manual Cancellation

**Source Code (main_asyncio_advanced.py:162-169):**
```python
log_time("ğŸ›‘ Manual Cancellation Example:")
task = asyncio.create_task(slow_operation(5, "LongTask"))  # Line 163
await asyncio.sleep(0.5)
task.cancel()  # Line 165: Cancel the task
try:
    await task
except asyncio.CancelledError:
    log_time("ğŸš« Task was successfully cancelled!\n")
```

**Output:**
```
[08:49:16.017] ğŸ›‘ Manual Cancellation Example:
[08:49:16.017] ğŸŒ LongTask: Starting (will take 5s)...
[08:49:16.522] âŒ LongTask: Was cancelled!  â† Line 165: Cancelled after 0.5s
[08:49:16.522] ğŸš« Task was successfully cancelled!
```

**ğŸ’¡ Key Insight:**
- **Line 165:** `task.cancel()` requests cancellation
- Task must `await` something to actually be cancelled
- Always handle `CancelledError` for proper cleanup

---

## 4. Advanced Task Management

### 4a. as_completed - Process Results as They Arrive

**Source Code (main_asyncio_advanced.py:189-197):**
```python
log_time("\nğŸƒ as_completed - Process Results as They Finish:")
tasks = [
    fetch_data("API-A", 1.5),  # Slowest
    fetch_data("API-B", 0.5),  # Fastest
    fetch_data("API-C", 1.0),  # Medium
]

for coro in asyncio.as_completed(tasks):  # Line 195
    result = await coro
    log_time(f"âœ… Received: {result}")
```

**Output:**
```
[08:49:16.522] ğŸƒ as_completed - Process Results as They Finish:
[08:49:17.024] âœ… Received: Data from API-B  â† Fastest finishes first (0.5s)
[08:49:17.537] âœ… Received: Data from API-C  â† Medium next (1.0s)
[08:49:18.035] âœ… Received: Data from API-A  â† Slowest last (1.5s)
```

**ğŸ’¡ Key Insight:**
- **Line 195:** `as_completed()` yields tasks in **completion order**, not creation order
- Use when you want to process results as soon as available (e.g., displaying search results)

---

### 4b. wait with FIRST_COMPLETED

**Source Code (main_asyncio_advanced.py:200-209):**
```python
log_time("\nğŸ¥‡ wait(return_when=FIRST_COMPLETED):")
tasks = {
    asyncio.create_task(fetch_data("Source-1", 2.0)),
    asyncio.create_task(fetch_data("Source-2", 0.8)),  # Fastest
    asyncio.create_task(fetch_data("Source-3", 1.5)),
}

done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)
log_time(f"ğŸ“‹ {len(done)} task(s) completed, {len(pending)} pending")
for task in done:
    log_time(f"âœ… Result: {task.result()}")
```

**Output:**
```
[08:49:18.035] ğŸ¥‡ wait(return_when=FIRST_COMPLETED):
[08:49:18.851] ğŸ“‹ 1 task(s) completed, 2 pending  â† Only fastest completed
[08:49:18.851] âœ… Result: Data from Source-2      â† Got result from fastest
```

**ğŸ’¡ Key Insight:**
- `wait()` returns as soon as **one** task completes
- Returns `(done, pending)` sets for further processing
- Use when you need the first successful result (e.g., racing multiple data sources)

---

## 5. Async Iteration and Generators

**Source Code (main_asyncio_advanced.py:221-227):**
```python
async def async_range(count: int) -> AsyncGenerator[int, None]:
    for i in range(count):
        log_time(f"ğŸ”¢ Generating number: {i}")
        await asyncio.sleep(0.2)  # Line 224: Async work between yields
        yield i  # Line 225: Yield values asynchronously
```

**Usage (main_asyncio_advanced.py:243-245):**
```python
async for num in async_range(4):  # Line 243: Async for loop
    log_time(f"   Received: {num}")
```

**Output:**
```
[08:49:18.851] ğŸ” Async Range Generator:
[08:49:18.856] ğŸ”¢ Generating number: 0  â† Line 224: Generate
[08:49:19.060]    Received: 0           â† Line 225: Yield, Line 243: Consume
[08:49:19.060] ğŸ”¢ Generating number: 1  â† Next iteration
[08:49:19.268]    Received: 1
[08:49:19.268] ğŸ”¢ Generating number: 2
[08:49:19.476]    Received: 2
[08:49:19.476] ğŸ”¢ Generating number: 3
[08:49:19.683]    Received: 3
```

**ğŸ’¡ Key Insight:**
- **Line 224:** Can perform async operations between yields
- **Line 225:** `yield` produces values one at a time
- **Line 243:** `async for` consumes async generators
- **Use Case:** Streaming data (paginated APIs, file reading, websockets)

---

## 6. Running Blocking Code in Executor

**Source Code (main_asyncio_advanced.py:263-268):**
```python
def blocking_io_operation(duration, operation_name):
    """NOT an async function - uses blocking time.sleep"""
    log_time(f"ğŸ”¨ {operation_name}: Starting blocking operation...")
    time.sleep(duration)  # Line 265: BLOCKING (not asyncio.sleep!)
    log_time(f"âœ… {operation_name}: Completed!")
    return f"{operation_name} result"
```

**Usage (main_asyncio_advanced.py:279-286):**
```python
loop = asyncio.get_running_loop()

tasks = [
    loop.run_in_executor(None, blocking_io_operation, 0.5, "FileRead"),     # Line 282
    loop.run_in_executor(None, blocking_io_operation, 0.3, "DatabaseQuery"),
    loop.run_in_executor(None, blocking_io_operation, 0.4, "APICall"),
]
```

**Output:**
```
[08:49:20.598] ğŸ§µ Running 3 blocking operations concurrently in threads:
[08:49:20.604] ğŸ”¨ FileRead: Starting blocking operation...       â† All 3 start
[08:49:20.604] ğŸ”¨ DatabaseQuery: Starting blocking operation...  â† at same time
[08:49:20.605] ğŸ”¨ APICall: Starting blocking operation...        â† in threads!
[08:49:20.905] âœ… DatabaseQuery: Completed!  â† Fastest finishes first
[08:49:21.006] âœ… APICall: Completed!
[08:49:21.104] âœ… FileRead: Completed!
```

**ğŸ’¡ Key Insight:**
- **Line 265:** Regular blocking code (e.g., `time.sleep`, file I/O)
- **Line 282:** `run_in_executor(None, ...)` runs in default thread pool
- **Result:** Blocking operations run concurrently without blocking the event loop
- **Use Case:** Legacy libraries, CPU-bound work, blocking I/O

---

## 7. Real-World Patterns

### 7a. Rate Limiting with Token Bucket

**Source Code (main_asyncio_advanced.py:296-317):**
```python
class RateLimiter:
    def __init__(self, rate: int, per: float):
        self.rate = rate  # Number of operations
        self.per = per    # Per time period (seconds)
        self.allowance = rate
        ...

    async def acquire(self):
        async with self.lock:
            ...
            if self.allowance < 1.0:
                sleep_time = (1.0 - self.allowance) * (self.per / self.rate)
                log_time(f"â¸ï¸  Rate limit: Sleeping for {sleep_time:.2f}s")  # Line 313
                await asyncio.sleep(sleep_time)
                self.allowance = 0.0
            else:
                self.allowance -= 1.0
```

**Usage (main_asyncio_advanced.py:351-353):**
```python
rate_limiter = RateLimiter(rate=2, per=1.0)  # 2 requests per second
await asyncio.gather(*[rate_limited_request(i, rate_limiter) for i in range(5)])
```

**Output:**
```
[08:49:21.104] ğŸš¦ Rate Limiting (2 requests/second):
[08:49:21.104] ğŸŒ Request-0: Sending...  â† First 2 allowed immediately
[08:49:21.104] ğŸŒ Request-1: Sending...
[08:49:21.104] â¸ï¸  Rate limit: Sleeping for 0.50s  â† Line 313: Throttle next batch
[08:49:21.211] âœ… Request-0: Done
[08:49:21.211] âœ… Request-1: Done
[08:49:21.613] ğŸŒ Request-2: Sending...  â† After 0.5s delay
[08:49:21.613] ğŸŒ Request-3: Sending...
[08:49:21.613] â¸ï¸  Rate limit: Sleeping for 0.49s
```

**ğŸ’¡ Key Insight:**
- Token bucket algorithm ensures max 2 requests/second
- **Line 313:** Automatically sleeps when limit exceeded
- **Use Case:** Respecting API rate limits, preventing server overload

---

### 7b. Retry Logic with Exponential Backoff

**Source Code (main_asyncio_advanced.py:336-350):**
```python
async def retry_with_backoff(operation_id, max_retries=3):
    for attempt in range(max_retries):
        try:
            log_time(f"ğŸ”„ Operation-{operation_id}: Attempt {attempt + 1}/{max_retries}")
            result = await unreliable_operation(operation_id)
            log_time(f"âœ… Operation-{operation_id}: {result}")
            return result
        except Exception as e:
            if attempt == max_retries - 1:
                log_time(f"âŒ Operation-{operation_id}: All retries failed")
                raise
            backoff = 2**attempt  # Line 347: Exponential: 1s, 2s, 4s
            log_time(f"âš ï¸  Operation-{operation_id}: Failed, retrying in {backoff}s...")
            await asyncio.sleep(backoff)
```

**Output:**
```
[08:49:22.220] ğŸ” Retry with Exponential Backoff:
[08:49:22.220] ğŸ”„ Operation-1: Attempt 1/3
[08:49:22.220] âš ï¸  Operation-1: Failed, retrying in 1s...   â† Line 347: 2^0 = 1s
[08:49:23.229] ğŸ”„ Operation-1: Attempt 2/3
[08:49:23.229] âš ï¸  Operation-1: Failed, retrying in 2s...   â† Line 347: 2^1 = 2s
[08:49:25.242] ğŸ”„ Operation-1: Attempt 3/3
[08:49:25.242] âŒ Operation-1: All retries failed           â† All attempts exhausted
```

**ğŸ’¡ Key Insight:**
- **Line 347:** Backoff delays: 1s, 2s, 4s (exponential growth)
- Reduces load on failing services
- **Use Case:** Network requests, database operations, external APIs

---

## Summary Table

| Concept | Use Case | Key Benefit |
|---------|----------|-------------|
| **Lock** | Protect shared state | Prevents race conditions |
| **Semaphore** | Limit concurrency | Control resource usage |
| **Event** | Coordinate tasks | Synchronize multiple waiters |
| **Queue** | Producer/Consumer | Decouple producers from consumers |
| **wait_for** | Timeouts | Prevent hanging forever |
| **as_completed** | Process ASAP | Handle results as they arrive |
| **wait(FIRST_COMPLETED)** | Race patterns | Use fastest result |
| **Async generators** | Streaming data | Memory-efficient iteration |
| **run_in_executor** | Blocking code | Don't block event loop |
| **Rate limiting** | API throttling | Respect rate limits |
| **Retry with backoff** | Fault tolerance | Gracefully handle transient failures |

## When to Use These Patterns

âœ… **Use Lock when:**
- Multiple tasks modify shared state
- Need mutual exclusion

âœ… **Use Semaphore when:**
- Need to limit concurrent access (e.g., DB connections, API calls)

âœ… **Use Event when:**
- Need to signal multiple waiters simultaneously
- Coordinating initialization or shutdown

âœ… **Use Queue when:**
- Implementing producer/consumer patterns
- Need backpressure control with bounded queues

âœ… **Use as_completed when:**
- Want to process results immediately as they arrive
- Order doesn't matter

âœ… **Use Executor when:**
- Working with blocking libraries (requests, legacy code)
- CPU-bound work in limited amounts

âœ… **Use Rate Limiting when:**
- External APIs have rate limits
- Need to control load on services

âœ… **Use Retry Logic when:**
- Dealing with unreliable external services
- Transient failures are expected
